{"posts":[{"title":"MLA -- collaborative filtering","content":"&quot;Collaborative filtering can be divided into users or items filtering. With its excellent speed and robustness, collaborative filtering is hot in the global Internet field. ğŸ˜ƒğŸ˜ƒ&quot; [toc] In general speaking, Collaborative Filtering is to use some behavior information from a group of people who has similar interests and common experience to recommend new information that one user in the group may be interested in. Individuals give a response to the information (such as scoring) through the cooperative mechanism and record it to acheive the purpose of filtering and then help others to filter the information. Collaborative filtering can be divided into users or items filtering. With its excellent speed and robustness, collaborative filtering is hot in the global Internet field. ğŸ˜ƒğŸ˜ƒ I. User-Based CF The user-based collaborative filtering algorithm is to discover the user's preference of the product or content based on the user's historical behavior data (such as product purchase, collection, content review or sharing), and measure or score to quantize these preferences. According to the attitudes and preferences of different users towards the same product or content, the relationship between users can be calculated. Then we can recommend products or contents among users with similar preference. To be simiply, if user A and user B all purchased books &quot;x&quot;, &quot;y&quot; and &quot;z&quot;, and also all gave them 5 stars comments. Then user A and user B should belong to a same group. And the book &quot;w&quot; that user A read and like could be recommended to the user B. (This is the benifit of user-based CF.) 1. Find users with similar preferences Let's simulate a situation that 5 users score 2 products. The score here may indicate a real purchase, or it may be a quantitative indicator of the user's different behaviors of the product. For example, the number of times you browse products, recommend products to friends, bookmark, share, or comment. These behaviors can indicate the user's attitude and preference to the product. Product 1 Product 2 User 1 3.3 6.5 User 2 5.8 2.6 User 3 3.6 6.3 User 4 3.4 5.8 User 5 5.2 3.1 From the data in the table above, it is a bit hard to figure out the relationship among these five users. However, if we plot all these five points in a scatter chart, the conclusion is obvious. User 1, 3 and 4 is one group, and User 2 and 5 is another group. # Python code for drawing the scatter plot above import matplotlib.pyplot as plt import numpy as np x = [3.3, 5.8, 3.6, 3.4, 5.2] y = [6.5, 2.6, 6.3, 5.8, 3.1] colors = np.random.rand(5) plt.scatter(x,y,c=colors,alpha=0.8) plt.xlim(0,7); plt.xlabel(&quot;Product 1&quot;) plt.ylim(0,7); plt.ylabel(&quot;Product 2&quot;) for i in range(5): plt.annotate(&quot;User &quot;+str(i+1), xy=(x[i],y[i]), xytext = (x[i]+0.1, y[i]+0.0)) # è¿™é‡Œxyæ˜¯éœ€è¦æ ‡è®°çš„åæ ‡ï¼Œxytextæ˜¯å¯¹åº”çš„æ ‡ç­¾åæ ‡ plt.show() 2. Similarity Calculation Although the scatter plot is intuitive, it cannot be put into production. Therefore, we need to accurately measure the relationship of users through real numbers, and complete the recommendation of products based on these relationship conclusions. 2.1. Euclidean distance evaluation Euclidean distance is a relatively simple method to evaluate the relationship among users. The principle is to calculate the distance of each two points in the scatter chart. Distance Reciprocal User 1 &amp; 2 4.63 0.22 User 1 &amp; 3 0.36 2.77 User 1 &amp; 4 0.71 1.41 User 1 &amp; 5 3.89 0.26 User 2 &amp; 3 4.30 0.23 User 2 &amp; 4 4.00 0.25 User 2 &amp; 5 0.78 1.28 User 3 &amp; 4 0.54 1.86 User 3 &amp; 5 3.58 0.28 User 4 &amp; 5 3.24 0.31 From the calculation above, if we defined a threshold, we can easily cluster these users. 2.2. Pearson correlation evaluation Pearson correlation evaluation is another method to calculate the relationship between users. It is a bit more complicated than the calculation of Euclidean distance, but Pearson correlation evaluation can give a better result when the score data is not standardized. The formula of Pearson correlation coefficient between variable x and y is: Ïxy=cov(x,y)ÏƒxÏƒy=E[(xâˆ’Î¼x)(yâˆ’Î¼y)]ÏƒxÏƒy\\begin{aligned} \\rho_{xy} &amp;= \\frac{cov(x, y)}{\\sigma_x \\sigma_y} \\\\ &amp;= \\frac{E[(x-\\mu_x)(y-\\mu_y)]}{\\sigma_x \\sigma_y} \\end{aligned}Ïxyâ€‹â€‹=Ïƒxâ€‹Ïƒyâ€‹cov(x,y)â€‹=Ïƒxâ€‹Ïƒyâ€‹E[(xâˆ’Î¼xâ€‹)(yâˆ’Î¼yâ€‹)]â€‹â€‹ Î¼x\\mu_xÎ¼xâ€‹ and Î¼y\\mu_yÎ¼yâ€‹ are the mean value of variable x and variable y. Ïxy\\rho_{xy}Ïxyâ€‹ is tne overall correlation coefficient. If we estimate the covariance and standard deviation of the sample, we can also get the sample's Pearson correlation coefficient &quot;r&quot;. r=âˆ‘i=1n(Xiâˆ’Xâ€¾)(Yiâˆ’Yâ€¾)âˆ‘i=1n(Xiâˆ’Xâ€¾)2âˆ‘i=1n(Yiâˆ’Yâ€¾)2=1nâˆ’1âˆ—âˆ‘i=1n(Xiâˆ’Xâ€¾)(Yiâˆ’Yâ€¾)ÏƒXÏƒY=1nâˆ’1âˆ—âˆ‘i=1n[(Xiâˆ’Xâ€¾ÏƒX)(Yiâˆ’Yâ€¾ÏƒY)]\\begin{aligned} r &amp;= \\frac{\\sum_{i=1}^n(X_i - \\overline{X})(Y_i - \\overline{Y})} {\\sqrt{\\sum_{i=1}^n(X_i-\\overline{X})^2}\\sqrt{\\sum_{i=1}^n(Y_i-\\overline{Y})^2}} \\\\ &amp;= \\frac{1}{n-1} * \\frac{\\sum_{i=1}^n(X_i - \\overline{X})(Y_i - \\overline{Y})}{\\sigma_X \\sigma_Y} \\\\ &amp;= \\frac{1}{n-1} * \\sum_{i=1}^n \\left[ \\left(\\frac{X_i-\\overline{X}}{\\sigma_X}\\right) \\left(\\frac{Y_i-\\overline{Y}}{\\sigma_Y}\\right) \\right] \\end{aligned}râ€‹=âˆ‘i=1nâ€‹(Xiâ€‹âˆ’X)2â€‹âˆ‘i=1nâ€‹(Yiâ€‹âˆ’Y)2â€‹âˆ‘i=1nâ€‹(Xiâ€‹âˆ’X)(Yiâ€‹âˆ’Y)â€‹=nâˆ’11â€‹âˆ—ÏƒXâ€‹ÏƒYâ€‹âˆ‘i=1nâ€‹(Xiâ€‹âˆ’X)(Yiâ€‹âˆ’Y)â€‹=nâˆ’11â€‹âˆ—i=1âˆ‘nâ€‹[(ÏƒXâ€‹Xiâ€‹âˆ’Xâ€‹)(ÏƒYâ€‹Yiâ€‹âˆ’Yâ€‹)]â€‹ (Xiâˆ’Xâ€¾ÏƒX)\\left(\\frac{X_i-\\overline{X}}{\\sigma_X}\\right)(ÏƒXâ€‹Xiâ€‹âˆ’Xâ€‹) is the standard score (Z) of sample variable X. The Pearson correlation coefficient always falls in -1 and 1. The Pearson coefficient is symmetrical: corr(X,Y) = corr(Y,X). An important mathematical characteristic of the Pearson correlation coefficient is that any change of the position and scale of the two variables will not cause the change of the coefficient. That is, if we move X to a+bX, and move Y to c+dY, (a,b,c,d are all constants), the correlation coefficient of X and Y doesn't change. Î¼x=E(X)\\mu_x = E(X) Î¼xâ€‹=E(X) Ïƒx2=E[(Xâˆ’E(X))2]=E[(X2âˆ’2E(X)X+E2(X))]=E(X2)âˆ’2E2(X)+E2(X)=E(X2)âˆ’E2(X)=E(X2)âˆ’Î¼X2\\begin{aligned} \\sigma_x^2 &amp;= E[(X-E(X))^2] \\\\ &amp;= E[(X^2-2E(X)X+E^2(X))] \\\\ &amp;= E(X^2)-2E^2(X)+E^2(X) \\\\ &amp;= E(X^2)-E^2(X) \\\\ &amp;= E(X^2)-\\mu_X^2 \\end{aligned}Ïƒx2â€‹â€‹=E[(Xâˆ’E(X))2]=E[(X2âˆ’2E(X)X+E2(X))]=E(X2)âˆ’2E2(X)+E2(X)=E(X2)âˆ’E2(X)=E(X2)âˆ’Î¼X2â€‹â€‹ E[(Xâˆ’E(X))(Yâˆ’E(Y))]=E(XY)âˆ’E(X)E(Y)âˆ’E(X)E(Y)+E(X)E(Y)=E(XY)âˆ’E(X)E(Y)\\begin{aligned} &amp;\\quad\\ E[(X-E(X))(Y-E(Y))] \\\\ &amp;= E(XY)-E(X)E(Y)-E(X)E(Y)+E(X)E(Y) \\\\ &amp;= E(XY)-E(X)E(Y) \\end{aligned}â€‹ E[(Xâˆ’E(X))(Yâˆ’E(Y))]=E(XY)âˆ’E(X)E(Y)âˆ’E(X)E(Y)+E(X)E(Y)=E(XY)âˆ’E(X)E(Y)â€‹ Therefore, the Pearson correlation coefficient can be also writen as: Ïxy=E(XY)âˆ’E(X)E(Y)E(X2)âˆ’E2(X)E(Y2)âˆ’E2(Y)\\rho_{xy} = \\frac{E(XY)-E(X)E(Y)}{\\sqrt{E(X^2)-E^2(X)}\\sqrt{E(Y^2)-E^2(Y)}} Ïxyâ€‹=E(X2)âˆ’E2(X)â€‹E(Y2)âˆ’E2(Y)â€‹E(XY)âˆ’E(X)E(Y)â€‹ And the sample's correlation coefficient is: r=âˆ‘i=1nxiyiâˆ’nxË‰yË‰(nâˆ’1)sxsy=n2[âˆ‘xiyinâˆ’âˆ‘xiâˆ‘yin2]n2âˆ‘xi2nâˆ’(âˆ‘xin)2âˆ‘yi2nâˆ’(âˆ‘yin)2=nâˆ‘xiyiâˆ’âˆ‘xiâˆ‘yinâˆ‘xi2âˆ’(âˆ‘xi)2nâˆ‘yi2âˆ’(âˆ‘yi)2\\begin{aligned} r &amp;= \\frac{\\sum_{i=1}^nx_iy_i - n\\bar{x}\\bar{y}}{(n-1)s_xs_y} \\\\ &amp;= \\frac{n^2 \\left[\\frac{\\sum x_iy_i}{n} - \\frac{\\sum x_i\\sum y_i}{n^2} \\right]} {n^2 \\sqrt{\\frac{\\sum x_i^2}{n} - \\left(\\frac{\\sum x_i}{n}\\right)^2} \\sqrt{\\frac{\\sum y_i^2}{n} - \\left(\\frac{\\sum y_i}{n}\\right)^2}} \\\\ &amp;= \\frac{n \\sum x_iy_i - \\sum x_i \\sum y_i} {\\sqrt{n \\sum x_i^2 - (\\sum x_i)^2} \\sqrt{n \\sum y_i^2 - (\\sum y_i)^2}} \\end{aligned}râ€‹=(nâˆ’1)sxâ€‹syâ€‹âˆ‘i=1nâ€‹xiâ€‹yiâ€‹âˆ’nxË‰yË‰â€‹â€‹=n2nâˆ‘xi2â€‹â€‹âˆ’(nâˆ‘xiâ€‹â€‹)2â€‹nâˆ‘yi2â€‹â€‹âˆ’(nâˆ‘yiâ€‹â€‹)2â€‹n2[nâˆ‘xiâ€‹yiâ€‹â€‹âˆ’n2âˆ‘xiâ€‹âˆ‘yiâ€‹â€‹]â€‹=nâˆ‘xi2â€‹âˆ’(âˆ‘xiâ€‹)2â€‹nâˆ‘yi2â€‹âˆ’(âˆ‘yiâ€‹)2â€‹nâˆ‘xiâ€‹yiâ€‹âˆ’âˆ‘xiâ€‹âˆ‘yiâ€‹â€‹â€‹ Suppose X and Y are the variables that represents various rating data to a same set of products from User X and User Y. As we all know, different users has different attitudes, someone is conservative and someone is aggresive to their rating. A good thing of Pearson correlation coefficient is that it could remove these difference and standardize variable X and Y. And the coefficient measures how does Y change when X increase? increase or decrease? Exactly the same change means 1, and completely opposite change means -1. Give a example, which is closer to the real case. Product 1 Product 2 Product 3 Product 4 Product 5 User A 3.3 6.5 2.8 3.4 5.5 User B 3.5 5.8 3.1 3.6 5.1 User C 5.6 3.3 4.5 5.2 3.2 User D 5.4 2.8 4.1 4.9 2.8 User E 5.2 3.1 4.7 5.3 3.1 We calculated the similarity data between users by calculating the ratings of 5 products by 5 users above. Here you can see that users A&amp;B, C&amp;D, C&amp;E and D&amp;E have a high similarity. Next, we can recommend products to users based on similarity. Similarity User A&amp;B 0.9998 User A&amp;C -0.8478 User A&amp;D -0.8418 User A&amp;E -0.9152 User B&amp;C -0.8417 User B&amp;D -0.8353 User B&amp;E -0.9100 User C&amp;D 0.9990 User C&amp;E 0.9763 User D&amp;E 0.9698 3. Recommend products for users Continue the above example, if we want to recommend some new products to User C. We can find out the most similar user of him or her at first, that is, user D at above table. Then we can browse and screen out those products that User D likes but User C doesn't try before, and then recomemnd to User C. This is a very intuitive way, however, in real case, there might be some more complicated calculation to weight and sort these new products, then choose the best one product to recommend. For example, find out 2 or 3 most similar users and combine their rating records to weight new products to recommend. 4. Pros and cons of the Algorithm Data sparsity. A large-scale e-commerce recommendation system usually has a lot of items, and users may buy less than 1% of the items. The overlap of items bought by different users is low, resulting in the algorithm unable to find a user's neighbors, that is, similar preferences Users. Algorithm scalability. The calculation amount of the nearest neighbor algorithm increases with the increase of the number of users and items, and is not suitable for use in a large amount of data. 5. Code Example (Python) Dataset Example: There are 138493 users' records of rating to the different movies they have watched. Try to use User-Based CF Algorithm to recommend movies to any user. userId movieId rating 1 2 3.5 1 29 3.5 1 32 3.5 1 47 3.5 1 50 3.5 ... ... ... 138493 68319 4.5 138493 68954 4.5 138493 69526 4.5 138493 69644 3.0 138493 70286 5.0 138493 71619 2.5 Solution: https://github.com/ZL-Wu/python-code-pool/blob/master/collaborative_filtering.ipynb II. Item-Based CF Item-Based CF's principle is basically the same as that of User-Based CF. In User-Based CF, consider the User as Item, and Item as User. According to the various rating data from various users to several product, we can calculate the similarity between each two products. Then for each user, this algorithm can recommend new and most similar product based on those products he or she used before. 1. Advantages Can filter information that the machine is difficult to analyze automatically, such as artwork, music, etc. Share the experience of others, avoid incomplete or inaccurate content analysis, and can filter based on some complex and difficult to express concepts (such as information quality, personal taste). The ability to recommend new information. It can be found that the content is completely dissimilar, and the content of the recommended information is not expected by the user in advance. You can discover the user's potential interest preferences that you have not yet discovered. Recommend personalization and high degree of automation. Can effectively use the feedback information of other similar users. Accelerate the speed of personalized learning. 2. Disadvantages New User Problem (New User Problem) The quality of the recommendation at the beginning of the system is poor. New Item Problem The quality depends on the historical data set. Sparsity System scalability (Scalability). III. Conclusion According to the different data source, Recommendation Engines can be can be divided into three categories: Demographic-based Recommendation Content-based Recommendation Collaborative Filtering-based Recommendation (IBM's introduction of recommendation engines) Content-based Recommendation is based on the metadata of item or content to find the relation among them. For example, we define various feature of movies, such as category, length and so on, then build a model to group similar movies. Finally, recommend users new movies by looking for similar movies of the user's favorite movies. Collaborative Filtering-based Recommendation can also be divided into three categories: User-based CF: User A likes Items 1,2,3. User C likes Items 1,2. And User A and User C are similar. Therefore, recommend Item 3 to User C. Item-based CF: User A likes Items 1,2,3. User C likes Item 1,2. And Item 1 and Item 3 are similar. Therefore, recommend Item3 to User C. Model-based CF: Based on the sample user preference information, train a recommendation model, and then make prediction recommendations based on real-time user preference information. Content-based Recommendation needs to know the contents and details of items or products. However, CF Recommendation is totally a statistical model. We don't need to know the details about the product and the content. What we did is only research user's behavior. IV. Reference https://www.zhihu.com/question/19971859 https://www.jianshu.com/p/d15ba37755d1 https://baike.baidu.com/item/ååŒè¿‡æ»¤/4732213?fr=aladdin https://wiki.mbalib.com/wiki/é•¿å°¾ç†è®º https://baike.baidu.com/item/çš®å°”é€Šç›¸å…³ç³»æ•°/12712835?fr=aladdin https://baike.baidu.com/item/åæ–¹å·® ","link":"https://zl-wu.github.io/post/mla-collaborative-filtering/"},{"title":"MLA -- Decision Tree","content":"Decision Tree is one of classical algorithms in machine learning. It can be used as both a classification model and a regression model. It is also suitable as a ensemble model, such as Random Forest. The history of Desicion Tree has three stages: ID3, C4.5 and CART [toc] 1. The Information Theory Foundation of Decision Tree ID3 It all originated from a simple &quot;if...else...&quot; statment that every programmer almost uses every day. Data researchers want to use a certain condition (if...else...) to split dataset into two distinct subsets. Then there are two questions we need to consider: A dataset usually has lots of features. So how to choose the feature that we need to use first in &quot;if...else...&quot;? And second, third features? How to quantitatively evaluate the quality of a certain binary division on the feature? In 1970s, a genius Ross Quinlan invented a method to guide and evaluate the process of decision tree by using entropy in information theory. As soon as the methods came out, its simplicity and efficiency cause a sensation. Quinlan called it ID3 algorithm. Entropy measures the uncertainty of things, the more uncertain things, the greater the entropy of it. Specifically, the expression of the entropy of a random discrete variable X is as follows: H(X)=âˆ’âˆ‘i=1npilog(pi)H(X) = - \\sum_{i=1}^np_ilog(p_i) H(X)=âˆ’i=1âˆ‘nâ€‹piâ€‹log(piâ€‹) n represents the &quot;n&quot; kinds of discrete values. (counts of unique value of X) pip_ipiâ€‹ is the probability that X takes the value &quot;i&quot;. log usually is the logarithm based on 2 or e. For example, if X only has two kind of values, the entropy is the largest when the probabilities of this two values are 1/2, which means X has the largest uncertainty. H(X) = -(1/2*log(1/2) + 1/2*log(1/2)) = log(2) if the probabilities of this two values are 1/3 and 2/3, H(X) = -(1/3*log(1/3) + 2/3*log(2/3)) = log(3) - 2/3*log(2) &lt; log(2) Then multivariable entropy: H(X,Y)=âˆ’âˆ‘i=1np(xi,yi)log(p(xi,yi))H(X,Y) = - \\sum_{i=1}^n p(x_i,y_i)log(p(x_i,y_i)) H(X,Y)=âˆ’i=1âˆ‘nâ€‹p(xiâ€‹,yiâ€‹)log(p(xiâ€‹,yiâ€‹)) And conditional entropy H(X|Y), which is the uncertainty of X after knowing the uncertainty of Y: H(Xâˆ£Y)=âˆ’âˆ‘i=1np(xi,yi)log(p(xiâˆ£yi))=âˆ‘j=1np(yj)H(Xâˆ£yj)\\begin{aligned} H(X|Y) &amp;= - \\sum_{i=1}^n p(x_i,y_i)log(p(x_i|y_i)) \\\\ &amp;= \\sum_{j=1}^n p(y_j)H(X|y_j) \\end{aligned} H(Xâˆ£Y)â€‹=âˆ’i=1âˆ‘nâ€‹p(xiâ€‹,yiâ€‹)log(p(xiâ€‹âˆ£yiâ€‹))=j=1âˆ‘nâ€‹p(yjâ€‹)H(Xâˆ£yjâ€‹)â€‹ H(X) represents the uncertainty of X. H(X|Y) represents the left uncertainty of X after knowing the Y. Therfore, [H(X) - H(X|Y)] represents the degree of reduction in uncertainty of X after knowing the Y. It is also called mutual information in information theory, which is wrote as I(X,Y). (äº’ä¿¡æ¯) In decision tree ID3 algorithm, mutual info is called information gain (ä¿¡æ¯å¢ç›Š). ID3 algorithm uses information gain to determin what feature should be used in current node to build the decidion tree. The larger the information gain, the better it is for classification in current node. From the graph above, we can easily figure out the relationship among them. The ellipse on the left represents H(X) [uncertainty of X]. And the ellipse on the left represents H(Y). The overlapping section in the middle is the mutual information (or information gain) I(x,y). The left section of left ellipse H(X|Y) The union of two ellipse is H(X,Y) If Y is &quot;a&quot;, almost all X is &quot;b&quot;. This means when Y is &quot;a&quot;, the uncertainty of X is very low (H(X|Y) is very small, I(X,Y) is large). Because the randomness of the X value is very small when Y is &quot;a&quot;. Then X is suitabale as a feature of classification of Y. 2. Decision Tree ID3 Algorithm Principle Take an example for ID3 algorithm to see how it uses information gain to build a decision tree model. Suppose there are 15 samples data D, the output is 0 or 1, and 9 of them are 1, 6 of them are 0. There is a feature A in the sample, the values are A1, A2 or A3. When A is A1, the output has 3 &quot;1&quot; and 2 &quot;0&quot; When A is A2, the output has 2 &quot;1&quot; and 3 &quot;0&quot; When A is A3, the output has 4 &quot;1&quot; and 1 &quot;0&quot; The entropy of sample D is: H(D)=âˆ’(915log2915+615log2615)=0.971H(D) = - (\\frac{9}{15}log_2\\frac{9}{15} + \\frac{6}{15}log_2\\frac{6}{15}) = 0.971 H(D)=âˆ’(159â€‹log2â€‹159â€‹+156â€‹log2â€‹156â€‹)=0.971 The conditional entropy of sample D in the feature A is: H(Dâˆ£A)=515H(DA1)+515H(DA2)+515H(DA3)=âˆ’515(35log235+25log225)âˆ’515(25log225+35log235)âˆ’515(45log245+15log215)=0.888\\begin{aligned} H(D|A) &amp;= \\frac{5}{15}H(D_{A1}) + \\frac{5}{15}H(D_{A2}) + \\frac{5}{15}H(D_{A3}) \\\\ &amp;= -\\frac{5}{15}(\\frac{3}{5}log_2\\frac{3}{5}+\\frac{2}{5}log_2\\frac{2}{5}) -\\frac{5}{15}(\\frac{2}{5}log_2\\frac{2}{5}+\\frac{3}{5}log_2\\frac{3}{5}) -\\frac{5}{15}(\\frac{4}{5}log_2\\frac{4}{5}+\\frac{1}{5}log_2\\frac{1}{5}) \\\\ &amp;= 0.888 \\end{aligned} H(Dâˆ£A)â€‹=155â€‹H(DA1â€‹)+155â€‹H(DA2â€‹)+155â€‹H(DA3â€‹)=âˆ’155â€‹(53â€‹log2â€‹53â€‹+52â€‹log2â€‹52â€‹)âˆ’155â€‹(52â€‹log2â€‹52â€‹+53â€‹log2â€‹53â€‹)âˆ’155â€‹(54â€‹log2â€‹54â€‹+51â€‹log2â€‹51â€‹)=0.888â€‹ Then the information gain H(D) - H(D|A) = 0.971 - 0.888 = 0.083 The specific algorithm process looks like: Input is &quot;mâ€ samples, the sample output set is &quot;D&quot;. Each sample has &quot;n&quot; discrete features, the feature set is &quot;A&quot;. The final output of ID3 algorithm is a decision tree &quot;T&quot; The process is: Initialize the threshold of information gain Ïµ\\epsilonÏµ Read the output set D. If all output value are same &quot;Di&quot;, return a single node tree T, marked as category &quot;Di&quot;. Read the feature set A. If A is null, return a single node tree T, marked as the category that has the largest counts number in D. [argmax(counts(Di))] Traverse and Calculate the information gain of each feature in A (n features). Select the feature &quot;AgA_gAgâ€‹&quot; which has the largest information gain. If the information gain of &quot;AgA_gAgâ€‹&quot; is less than the threshold Ïµ\\epsilonÏµ, return a single node tree T, marked as the category that has the largest counts number in D. [argmax(counts(Di))] If not (else), according to the different values in AgA_gAgâ€‹, split the total sample into several different categories subset DjD_jDjâ€‹. Each category is a child node. And return the tree T with multiple nodes. For each child nodes, let D=Dj,A=Aâˆ’{Ag}D=D_j, A=A-\\{A_g\\}D=Djâ€‹,A=Aâˆ’{Agâ€‹}, then recursively call the step 2-6 to get and return the subtree TiT_iTiâ€‹. 3. Deficiency of decision tree ID3 algorithm Althogh ID3 algorithm proposed new ideas, there are still many areas worthy of improvement. (1) ID3 doesn't consider continuous features, such as length, density or other continuous features. This greatly limits the use of ID3. (2) ID3 uses the features of large information gain to preferentially establish the nodes of the decision tree. However, under the same conditions, the feature with more kinds of values has larger information gain. For example, if the feature A has 2 kinds of values, each of them is 1/2, H(A)=log(2); if the feature A has 3 kinds of values, each of them is 1/3, H(A)=log(3). How to correct this problem? (3) ID3 doesn't consider the condition of missing values. (4) ID3 doesn't consider the overfitting problem. Ross Quinlan has improved the ID3 algorithm based on the above deficiencies. This is C4.5 algorithm. The reason that why the new algorithm wasn't named ID4 or IDn: Decision tree was too popular when it came out, then lots of people started the second innovation and occupied ID4 and ID5 soon. So Quinlan took a new path and named it the C4.0 algorithm. And later, the advanced version was C4.5 algorithm. 4. Improvement of the Decision Tree C4.5 algorithm According to the 4 deficiencies of ID3 above, C4.5 improved them through the following: (1) Cannot handle continuous features: The idea of C4.5 is to discretize continuous features. For example, the feature A of m samples has m values, sort from small to large as a1,a2,...,ama_1, a_2, ..., a_ma1â€‹,a2â€‹,...,amâ€‹. C4.5 take the average value between two neighbor values as a dividing point, then there are (m-1) dividing points. The i-th dividing point TiT_iTiâ€‹ is Ti=ai+ai+12T_i=\\frac{a_i+a_{i+1}}{2}Tiâ€‹=2aiâ€‹+ai+1â€‹â€‹. For these (m-1) dividing points, C4.5 calculates the information gain using each dividding point as the binary classification point. Finally, select the point with the largest information gain as the binary discrete classification point for the continuous feature. Pay attention: unlike the discrete attribute, if the current node is a continuous attribute, then this attribute can also participate in the generation and selection process of child nodes. (2) Bias of features with more kinds of values: C4.5 inroduces a new variable of information gain ratio IR(X,Y)I_R(X,Y)IRâ€‹(X,Y). It is the ratio of information gain and feature entropy. IR(D,A)=I(A,D)HA(D)I_R(D,A) = \\frac{I(A,D)}{H_A(D)} IRâ€‹(D,A)=HAâ€‹(D)I(A,D)â€‹ D is the output set of samples, A is the feature set. And the feature entropy is: HA(D)=âˆ’âˆ‘i=1nâˆ£Diâˆ£âˆ£Dâˆ£log2âˆ£Diâˆ£âˆ£Dâˆ£H_A(D) = -\\sum_{i=1}^n\\frac{|D_i|}{|D|}log_2\\frac{|D_i|}{|D|} HAâ€‹(D)=âˆ’i=1âˆ‘nâ€‹âˆ£Dâˆ£âˆ£Diâ€‹âˆ£â€‹log2â€‹âˆ£Dâˆ£âˆ£Diâ€‹âˆ£â€‹ n is the number of categories of feature A. DiD_iDiâ€‹ is the number of samples corresponding to the i-th value of feature A. D is the total number of all samples. The feature with more kinds of values has a larger feature entropy. It serves as a denominator to correct the problem that information gain tends to be biased toward features with more values. (3) Problem of missing values: There are two sub problems needed to be solved: a. How to choose the feature to build chind node when some features of the sample is missing? b. If the feature is selected, how to deal with the samples with missing values on this feature? a. Feature Choosing with missing value For a featur A with missing values, C4.5 set a weight for each sample (including those with missing value in A), the initial weight could be 1. Then C4.5 splits the data into 2 subsets, one is the data D1 without missing value, the other one is the data D2 with missing value. For no missing value data D1, calculate the information gain ratio with weight, and then multiply by a coefficient, which is the ratio of weighted samples with no feature A missing and weighted total samples. b. Data Spliting with missing value in A C4.5 can divide the samples with missing value A into all child nodes at the same time. But the weight of this sample is reassigned according to the proportion of the number of samples of each child node. For example, suppose there is a sample &quot;ms&quot; with missing value in feature A. The feature A has 3 kinds of value: A1, A2 and A3, and the number of samples are respectively 2,3,4, that is, the proportion of A1, A2 and A3 are 2/9, 3/9 and 4/9. Then the corresponding weights of missing value sample are adjusted to 2/9, 3/9 and 4/9. (4) Overfitting problem: C4.5 introduced regularization coefficients for preliminary pruning, which will be discussed in detail later. 5. Deficiency of decision tree C4.5 algorithm Althogh C4.5 algorithm improves ID3 a lot, there are still some areas worthy of improvement. (1) ID3 and C4.5 algorithms generate a multi-fork tree. Discrete feature with more than 2 kinds of value leads multiple child nodes. In many cases, the binary tree model in the computer will be more efficient than the multi-tree operation. Binary tree can improve efficiency. (2) C4.5 can only be used for classification. If the decision tree can be also used for regression, its scope of use can be expanded. (3) C4.5 uses the entropy model, there are lots of time-consuming logarithmic operations. If it is continuous feature, there is also a time-consuming sorting operation. It would be better if the model simplification can reduce the computational intensity without sacrificing too much accuracy. (4) Decision tree algorithm is very easy to overfit, the generated decision tree must be pruned. C4.5's pruning method still has room for optimization. There are two main ideas for pruning: pre-pruning, which is to decide whether to pruning when a decision tree is generated. post-pruning, that is, the decision tree is generated first, and then pruned tree through cross-validation. In the next section when we talk about the CART tree, we will specifically introduce the idea of reducing the branch of the decision tree, which mainly uses post-pruning plus cross-validation to select the most suitable decision tree. These 4 problems has been improved in CART algorithm. So if not consider integrated learning at present, in the ordinary decision tree algorithm, the CART algorithm is considered to be the better algorithm. 6. CART Classification Tree Algorithm -- Gini Coefficient Let's review at first, as we all know now: ID3 uses information gain to select features. I(D,A)=H(D)âˆ’H(Dâˆ£A)I(D,A) = H(D)-H(D|A)I(D,A)=H(D)âˆ’H(Dâˆ£A) C4.5 uses information gain ratio to select features. IR(D,A)=I(A.D)HA(D)I_R(D,A)=\\frac{I(A.D)}{H_A(D)}IRâ€‹(D,A)=HAâ€‹(D)I(A.D)â€‹ Both of them are entropy models based on the information theory, H(X)=âˆ’âˆ‘i=1npiâˆ—log(pi)H(X) = -\\sum_{i=1}^n p_i*log(p_i)H(X)=âˆ’âˆ‘i=1nâ€‹piâ€‹âˆ—log(piâ€‹), which has lots of logarithmic computation and decrease the efficiency a lot. Is there any method we can simplify the model to increase the efficiency but without sacrificing too much accuracy? Yes, It is Gini Coefficient of CART. The Gini Coefficient represents the impureness of the node. The smaller the Gini, the lower the unpurification, the better classfication. This is opposite to Information Gain (Ratio) Specifically, in a classification problem, supposed there are K categories, and the probability of i-th category is pip_ipiâ€‹. Then the Gini coefficient is: Gini(p)=âˆ‘i=1Kpi(1âˆ’pi)=1âˆ’âˆ‘i=1Kpi2Gini(p) = \\sum_{i=1}^K p_i(1-p_i) = 1-\\sum_{i=1}^Kp_i^2 Gini(p)=i=1âˆ‘Kâ€‹piâ€‹(1âˆ’piâ€‹)=1âˆ’i=1âˆ‘Kâ€‹pi2â€‹ If there is a binary classification, and the probability of first category is p, the Gini Coefficient is super easy: Gini(p)=2p(1âˆ’p)Gini(p) = 2p(1-p)Gini(p)=2p(1âˆ’p) For a sample D, if it has K categories, and the counts of i-th category is âˆ£Ciâˆ£|C_i|âˆ£Ciâ€‹âˆ£, and the total number of D is |D|, then the Gini Coefficient of sample D is: Gini(D)=1âˆ’âˆ‘i=1K(âˆ£Ciâˆ£âˆ£Dâˆ£)2Gini(D) = 1 - \\sum_{i=1}^K \\left(\\frac{|C_i|}{|D|}\\right)^2 Gini(D)=1âˆ’i=1âˆ‘Kâ€‹(âˆ£Dâˆ£âˆ£Ciâ€‹âˆ£â€‹)2 And if the feature A (binary discrete or continuous) split the data into two subsets D1 and D2 by a certain value a of A. Then in the condition of feature A, the Gini Coefficient of D is: Gini(D,A)=âˆ£D1âˆ£âˆ£Dâˆ£Gini(D1)+âˆ£D2âˆ£âˆ£Dâˆ£Gini(D2)Gini(D,A) = \\frac{|D_1|}{|D|}Gini(D_1) + \\frac{|D_2|}{|D|}Gini(D_2) Gini(D,A)=âˆ£Dâˆ£âˆ£D1â€‹âˆ£â€‹Gini(D1â€‹)+âˆ£Dâˆ£âˆ£D2â€‹âˆ£â€‹Gini(D2â€‹) Comparing with entropy model formulas, the Quadratic computation of Gini Coefficient is easier a lot than logrithmic computation, especially in the binary classification. And so, Compared with the entropy model, how does the Gini coefficient perform? Take a look at the plot below. As we can see from the plot, the curves of Gini and Entropy (scaled) are very close, and the error is only slightly larger near the angle of 45 degrees. Therefore, the Gini can be used as an approximate substitute for the entropy model. In fact, the CART use Gini to select features of decision tree. And for further simplification, CART only divides each node to binary child nodes but not multi-nodes, so that the CART classification tree algorithm builds a binary tree instead of a multi-tree. In this way, the calculation of the Gini coefficient can be further simplified, and a more elegant binary tree model can be established. 7. CART Algorithm on continuous features and discrete features continuous features The idea of CART on continuous features is same with C4.5. Suppose the sample m has m values in continous feature A, CART sorts them from small to large, a1,a2,...,ama_1,a_2,...,a_ma1â€‹,a2â€‹,...,amâ€‹ and finds out (m-1) dividing points, which is the average value of each pair of neighbor points. For example, the i-th dividing point TiT_iTiâ€‹ is ai+ai+12\\frac{a_i+a_{i+1}}{2}2aiâ€‹+ai+1â€‹â€‹. CART calculates the Gini Coefficient value of each one of the dividing points, and selects the point with the lowest Gini Coefficient value. Pay attention: Unlike ID3, if the current node is the continuous feature, it will be still used in the following steps to create other child nodes. discrete features Unlike ID3 and C4.5, CART uses a non-stop binary classification, no matter how many kinds of values the feature has. For example, if the feature A has A1, A2, A3 three kinds of values, ID3 or C4.5 will build three child nodes {A1},{A2} and {A3}. But CART will consider 3 binary child nodes conditions: {A1} and {A2,A3}, {A2} and {A1,A3}, {A3} and {A1,A2}, then select the condition with lowest Gini Coefficient. And if CART selects {A2} and {A1,A3}, due to the value of feature A is not completely separated this time, CART will have the opportunity to continue to select feature A to divide A1 and A3 in the child node. Pay attention: In ID3 or C4.5, discrete feature will only participate in the establishment of a node once, because they builds multi-division tree. Unlike them, CART will reuse each discrete feature. Regardless of continuous features or discrete features, after the current node uses this feature to build a subtree, CART will still use this feature in the future subtree establishment. 8. CART classification tree establishment algorithm specific process The input of CART algorithm are training set D, threshold of Gini Coefficient, threshold of number of samples The outpuf of CART is the decision tree T CART algorithm starts from the root node, and uses the training set to recursively build the CART tree: For the dataset D of current node, if the number of records is smaller than the threshold number of samples, or there are no features, then return the decision subtree T, and current node stops recursive. Calculate the Gini Coefficient of dataset D of current node, Gini(D)Gini(D)Gini(D). If the Gini Coefficient is smaller than the threshold, then return the decision subtree T, and current node stops recursive. Calculate the Gini Coefficient of each feature value of the current node on the data set D, Gini(D,A)Gini(D,A)Gini(D,A). The processing of missing values is the same as that described in the C4.5 algorithm. Among all calculated Gini Coefficients of the pair of each feature and each feature's possible dividing point, choose the feature with the appropriate dividing point value that has smallest Gini Coefficient. According to this optimal feature and optimal feature value (dividing point), the dataset of current node is divided into two nodes D1 and D2, and the left and right nodes of the current node are established at the same time, the dataset D of the left node is D1, and the dataset D of the right node is D2. Steps 1-4 are recursively called on each of the left and right child nodes to generate a decision tree. When doing the prediction on the generated decision tree, if the sample &quot;P&quot; in prediction set falls into a certain leaf node, and there are multiple training samples in each leaf node, then the category prediction of sample &quot;P&quot; is the category with the highest probability in this leaf node. 9. CART regression tree building algorithm One advantage of CART is that it can be used not only as a classification model but also as a regression model. If the output of sample is the discrete value, we should train a classification tree. However, if the output of sample is the continuous value, we should train a regression tree. The algorithms for building CART regression trees and CART classification trees are mostly similar, so here we only discuss the differences between the algorithms for building CART regression trees and CART classification trees. The main difference between the establishment and prediction of CART regression tree and CART classification tree: Different methods for processing features. Different ways of making predictions after the decision tree is established. In feature selection and division, CART classification tree uses the Gini Coefficient to measure the pros and cons of each division node, which is suitable for classification problem. However, for the regression problem, we use variance measurement methods. The goal of the CART regression tree is that: For the data sets D1 and D2 divided on both sides of the arbitrary division feature &quot;A&quot; and the division point &quot;s&quot; Find the feature and feature division point corresponding to the minimum mean square deviation of each set of D1 and D2, and the minimum sum of mean square errors of D1 and D2. minâ¡A,s[minâ¡c1âˆ‘xiâˆˆD1(A,s)(yiâˆ’c1)2+minâ¡c2âˆ‘xiâˆˆD2(A,s)(yiâˆ’c2)2]\\min_{A,s}\\left[\\min_{c_1} \\sum_{x_i \\in D_1(A,s)}(y_i-c_1)^2 + \\min_{c_2} \\sum_{x_i \\in D_2(A,s)}(y_i-c_2)^2 \\right] A,sminâ€‹â£â¡â€‹c1â€‹minâ€‹xiâ€‹âˆˆD1â€‹(A,s)âˆ‘â€‹(yiâ€‹âˆ’c1â€‹)2+c2â€‹minâ€‹xiâ€‹âˆˆD2â€‹(A,s)âˆ‘â€‹(yiâ€‹âˆ’c2â€‹)2â¦â¤â€‹ (A,s) is the optimal feature and optimal division point of optimal feature. This is what we need in building decision tree. c1c_1c1â€‹ and c2c_2c2â€‹ are the average output value of dataset D1 and D2. (A,s) should minimize the above formula (Loss Function) In the prediction after the decision tree is established, the output of the regression tree is not a category. It uses the mean or median of the output value in final leaves to predict the output. Except for the above, there is no difference between CART regression tree and CART classification tree building algorithm and prediction. 10. Pruning of CART tree algorithm Since the decision tree algo is easy to overfitting after training, resulting in poor generalization ability. In order to preventing the overfitting problem, we need to prune the CART tree, that is, similar to regularization of the linear regression to increase the generalization ability. The pruning algorithm of the CART tree can be summarized in two steps: Generate various pruned decision tree from the original decision tree. Use cross-validation to test the prediction ability for all pruned tree. And the tree with the best generalization prediction ability is selected as the final CART tree. a. loss function of decision tree The pruning strategies of the CART regression tree and the CART classification tree are that one uses the mean square error and one uses the Gini coefficient when measuring the loss. There is a Classification tree T, |T| is the number of leaf nodes in the tree. &quot;t&quot; is one of leaf node of tree T: NtN_tNtâ€‹ is the number of samples in leaf node &quot;t&quot;, Ht(T)H_t(T)Htâ€‹(T) is the entropy of leaf node &quot;t&quot;. In leaf node &quot;t&quot;, the number of k-th category samples is NtkN_{tk}Ntkâ€‹, k=1,2,...,K. (There are K categories in the nod) Î±â‰¥0\\alpha \\ge 0Î±â‰¥0 is the regularization coefficient Then the loss function of this classification decision tree CÎ±(T)C_{\\alpha}(T)CÎ±â€‹(T) is: CÎ±(T)=âˆ‘t=1âˆ£Tâˆ£NtHt(T)+Î±âˆ£Tâˆ£C_{\\alpha}(T) = \\sum_{t=1}^{|T|}N_tH_t(T) + \\alpha|T| CÎ±â€‹(T)=t=1âˆ‘âˆ£Tâˆ£â€‹Ntâ€‹Htâ€‹(T)+Î±âˆ£Tâˆ£ The entropy of node &quot;t&quot;, Ht(T)H_t(T)Htâ€‹(T) is: Ht(T)=âˆ’âˆ‘k=1KNtkNtlog(NtkNt)H_t(T) = - \\sum_{k=1}^K \\frac{N_{tk}}{N_t} log(\\frac{N_{tk}}{N_t}) Htâ€‹(T)=âˆ’k=1âˆ‘Kâ€‹Ntâ€‹Ntkâ€‹â€‹log(Ntâ€‹Ntkâ€‹â€‹) We defined C(T) as the prediction error of the model on the training data, which can also represents the degree of fitting between the model and the training data. C(T)=âˆ‘t=1âˆ£Tâˆ£NtHt(T)=âˆ’âˆ‘t=1âˆ£Tâˆ£âˆ‘k=1KNtkâˆ—log(NtkNt)\\begin{aligned} C(T) &amp;= \\sum_{t=1}^{|T|}N_tH_t(T) \\\\ &amp;= - \\sum_{t=1}^{|T|} \\sum_{k=1}^K N_{tk}*log(\\frac{N_{tk}}{N_t}) \\end{aligned}C(T)â€‹=t=1âˆ‘âˆ£Tâˆ£â€‹Ntâ€‹Htâ€‹(T)=âˆ’t=1âˆ‘âˆ£Tâˆ£â€‹k=1âˆ‘Kâ€‹Ntkâ€‹âˆ—log(Ntâ€‹Ntkâ€‹â€‹)â€‹ Then the loss function CÎ±(T)C_{\\alpha}(T)CÎ±â€‹(T) can be written as: CÎ±(T)=C(T)+Î±âˆ£Tâˆ£C_{\\alpha}(T) = C(T) + \\alpha|T| CÎ±â€‹(T)=C(T)+Î±âˆ£Tâˆ£ Whether it is Classification Tree (CT) or Regression Tree (RT), their loss function formula is same: $ C_{\\alpha}(T) = C(T) + \\alpha|T| $. The only difference is the calculation of prediction error C(T), which uses entroy or Gini coefficient in CT, and mean squared error in RT. Emphasize again, the loss function of decision tree: CÎ±(T)=C(T)+Î±âˆ£Tâˆ£C_{\\alpha}(T) = C(T) + \\alpha|T| CÎ±â€‹(T)=C(T)+Î±âˆ£Tâˆ£ C(T) is the prediction error of the decision tree, or the degree of fitting between training data and the tree model. |T| is the number of leaf nodes in the tree, which can represent the complexity of the tree model. So we can easily find that, C(T) and |T| are two controdictory values. A very small C(T) means that the degree of fitting between the model and the training data is very high, and the prediction result of the training set is very accurate (but the performance of test data is hard to say). Then complexity |T| should be very large. Similarly, a simple tree with low |T| (low complexity) has large C(T) (high prediction error in training set). The goal is to balance the accuracy and complexity of the model so that the combined loss function of the two is minimal. Î±â‰¥0\\alpha \\ge 0Î±â‰¥0 is also an important coefficient in the loss function. Î±\\alphaÎ± is large =&gt; prompt to choose a simpler tree (small |T|) Î±\\alphaÎ± is small =&gt; prompt to choose a more complex tree (large |T|) Î±\\alphaÎ± is 0 =&gt; No pruning, current tree is the optimal. Only consider the fitting between model and data, and ignore the model complexity. (easily cause overfitting) Î±\\alphaÎ± is +âˆ+\\infty+âˆ =&gt; All pruning, only the root node is left. So pruning means when Î±\\alphaÎ± is determined, select a Tree model with the least loss function value CÎ±(T)C_{\\alpha}(T)CÎ±â€‹(T). General speaking, the larger the Î±\\alphaÎ± is, the stronger the pruning is, and the smaller the optimal tree is (compared with the original decision tree) For a fixed Î±\\alphaÎ±, there must be a unique subtree that minimizes the loss function CÎ±(T)C_{\\alpha}(T)CÎ±â€‹(T). b. idea of pruning All above is the method of measuring the loss function of pruning tree. And the next is the idea of pruning. For any subtree TtT_tTtâ€‹ at the node t, if no pruning, its original loss is: CÎ±(Tt)=C(Tt)+Î±âˆ£Ttâˆ£C_{\\alpha}(T_t) = C(T_t) + \\alpha|T_t| CÎ±â€‹(Ttâ€‹)=C(Ttâ€‹)+Î±âˆ£Ttâ€‹âˆ£ âˆ£Ttâˆ£|T_t|âˆ£Ttâ€‹âˆ£ is the total number of leaf nodes of the node &quot;t&quot;. If prune the node &quot;t&quot; and only the root node is left, its loss after pruning is: CÎ±(t)=C(t)+Î±C_{\\alpha}(t) = C(t) + \\alpha CÎ±â€‹(t)=C(t)+Î± Since, only the root node as one leaf node is left after pruning. Î±âˆ£tâˆ£=Î±\\alpha|t| = \\alphaÎ±âˆ£tâˆ£=Î± Subtree &quot;TtT_tTtâ€‹&quot; is more complex than subtree &quot;t&quot;, the error C(Tt)â‰¤C(t)C(T_t) \\le C(t)C(Ttâ€‹)â‰¤C(t). So, if Î±\\alphaÎ± is 0 or very small, CÎ±(Tt)â‰¤CÎ±(t)C_{\\alpha}(T_t) \\le C_{\\alpha}(t)CÎ±â€‹(Ttâ€‹)â‰¤CÎ±â€‹(t). When Î±\\alphaÎ± increases to a certain degree, it will meet: CÎ±(Tt)=CÎ±(t)C_{\\alpha}(T_t) = C_{\\alpha}(t) CÎ±â€‹(Ttâ€‹)=CÎ±â€‹(t) If Î±\\alphaÎ± continues to increase, then CÎ±(Tt)â‰¥CÎ±(t)C_{\\alpha}(T_t) \\ge C_{\\alpha}(t)CÎ±â€‹(Ttâ€‹)â‰¥CÎ±â€‹(t). In other words, the critical value of Î±\\alphaÎ± derived from the equality before and after pruning is: C(Tt)+Î±âˆ£Tâˆ£=C(t)+Î±Î±=C(t)âˆ’C(Tt)âˆ£Tâˆ£âˆ’1\\begin{aligned} C(T_t) + \\alpha|T| &amp;= C(t) + \\alpha \\\\ \\alpha &amp;= \\frac{C(t)-C(T_t)}{|T|-1} \\end{aligned}C(Ttâ€‹)+Î±âˆ£Tâˆ£Î±â€‹=C(t)+Î±=âˆ£Tâˆ£âˆ’1C(t)âˆ’C(Ttâ€‹)â€‹â€‹ In the pruning of node &quot;t&quot; Before pruning, lost of &quot;t&quot;: CÎ±(Tt)C_{\\alpha}(T_t)CÎ±â€‹(Ttâ€‹) After pruning, lost of &quot;t&quot;: CÎ±(t)C_{\\alpha}(t)CÎ±â€‹(t) There are 3 conditions of loss value after pruning: increase, unchange or decrease. If the loss value doesn't increase after pruning, that is, if CÎ±(Tt)â‰¥CÎ±(t)C_{\\alpha}(T_t) \\ge C_{\\alpha}(t)CÎ±â€‹(Ttâ€‹)â‰¥CÎ±â€‹(t), then pruning the subtree is better. It shows that complexity plays a key role, and the loss function plays a small role. In simple terms, the leaf nodes before pruning do not improve the accuracy but bring more complicated trees. c. CART pruning algorithm process Since, for a fixed Î±\\alphaÎ±, there must be a unique subtree that minimizes the loss function CÎ±(T)C_{\\alpha}(T)CÎ±â€‹(T). We can mark this subtree as TÎ±T_{\\alpha}TÎ±â€‹ Breiman has proved that the tree can be pruned recursively. Increase Î±\\alphaÎ± from small to large, a0&lt;a1&lt;...&lt;an&lt;+âˆa_0 &lt; a_1 &lt; ... &lt; a_n &lt; +\\inftya0â€‹&lt;a1â€‹&lt;...&lt;anâ€‹&lt;+âˆ, producing a series of intervals [ai,ai+1)[a_i,a_{i+1})[aiâ€‹,ai+1â€‹), i=0,1,2,...,n. The optimal subtree sequence obtained by pruning is {T0,T1,...,TnT_0,T_1,...,T_nT0â€‹,T1â€‹,...,Tnâ€‹} Then in the optimal subtree sequence {T0,T1,...,TnT_0,T_1,...,T_nT0â€‹,T1â€‹,...,Tnâ€‹}, select the optimal subtree TÎ±T_{\\alpha}TÎ±â€‹ through cross-validation. The CART pruning algorithm: Input: the original decision tree T0T_0T0â€‹ obtained by the CART tree algorithm in section 8. Output: Optimal decision subtree TÎ±T_{\\alpha}TÎ±â€‹ The algorithm process: Initialize Î±min=+âˆ\\alpha_{min}=+\\inftyÎ±minâ€‹=+âˆ, Set of optimal subtree w={T0}w = \\{T_0\\}w={T0â€‹} Calculate CÎ±(Tt),âˆ£Ttâˆ£,Î±C_{\\alpha}(T_t), |T_t|, \\alphaCÎ±â€‹(Ttâ€‹),âˆ£Ttâ€‹âˆ£,Î± Calculate the training error loss function CÎ±(Tt)C_{\\alpha}(T_t)CÎ±â€‹(Ttâ€‹) of each internal node &quot;t&quot; from the leaf node from bottom to top. (The regression tree is the mean square error, and the classification tree is the Gini coefficient). Calculate the total number of leaf nodes of &quot;t&quot;, âˆ£Ttâˆ£|T_t|âˆ£Ttâ€‹âˆ£, and Calculate the threshold of regularization cofficient Î±=minâ¡{C(t)âˆ’C(Tt)âˆ£Ttâˆ£âˆ’1,Î±min}\\alpha= \\min \\left\\{\\frac{C(t)-C(T_t)}{|T_t|-1}, \\alpha_{min} \\right\\}Î±=min{âˆ£Ttâ€‹âˆ£âˆ’1C(t)âˆ’C(Ttâ€‹)â€‹,Î±minâ€‹} Update the Î±min=Î±\\alpha_{min} = \\alphaÎ±minâ€‹=Î± Get the set M of Î±\\alphaÎ± values for all nodes. Chosse the smallest regularization coefficient value Î±k\\alpha_kÎ±kâ€‹ from the set M, then access the internal nodes &quot;t&quot; from top to bottom. If C(t)âˆ’C(Tt)âˆ£Ttâˆ£âˆ’1â‰¤Î±k\\frac{C(t)-C(T_t)}{|T_t|-1} \\le \\alpha_{k}âˆ£Ttâ€‹âˆ£âˆ’1C(t)âˆ’C(Ttâ€‹)â€‹â‰¤Î±kâ€‹, pruning is performed. And determine the value of the leaf node t. If it is a classification tree, it is the category with the highest probability; if it is a regression tree, it is the average of all sample outputs. The optimal subtree corresponding to the regularization coefficient Î±k\\alpha_{k}Î±kâ€‹ is obtained TkT_kTkâ€‹ Update the optimal subtree set w=wâˆªTkw = w \\cup T_kw=wâˆªTkâ€‹, and regularization coefficient set M=Mâˆ’{Î±k}M=M-\\{\\alpha_k\\}M=Mâˆ’{Î±kâ€‹} If www is not null, back to step 4. Else, all optimal subtrees with different Î±\\alphaÎ± have been obtained in set www. Use cross-validation to test the prediction accuracy for all pruned tree in optimal subtree set www. And the tree with the best generalization prediction ability is returned as the final CART tree. 11. Summary of CART algorithm Algorithms Model Support Tree Structure Feature Selection Continuous Feature Missing Value Pruning ID3 Classification General Tree (Multitree) Information Gain Not Support Not Support Not Support C4.5 Classification General Tree (Multitree) Information Gain Ratio Support Support Support CART Classification &amp; Regression Binary Tree Gini Coefficient; Mean Square Error Support Support Support The CART algorithm still has some shortcomings: Whether it is ID3, C4.5 or CART, when making feature selection, they all choose the best one feature to build the decision tree node. However, in some case, the classification decision should not be determined by only one certain feature, but should be determined by a set of features. The decision tree obtained in this way is more accurate, which is called a multi-variate decision tree. When selecting the optimal feature, the multivariate decision tree does not select one certain optimal feature, but selects an optimal linear combination of features to make a decision. The representative of multi-variate decision tree algorithm is &quot;OC1&quot;. If the sample changes a little bit, it will cause a dramatic change in the tree structure. This can be solved by ensemble models, such as random forest in integrated learning. 12. Summary of Decision Tree Advantages of Decision Tree: The generated decision tree is very simple and intuitive. Basically no preprocessing is needed, such as normalization in advance, and missing values preprocessing. The cost in prediction of decision tree is O(log2m)O(log_2m)O(log2â€‹m), m is the number of samples. Both discrete and continuous values can be processed. Many algorithms only focus on discrete values or continuous values. It can deal with multi categories classification problem. Compared with the black box classification model such as neural network, the decision tree can be well explained logically. Cross-validated pruning can be used to filter the model, thereby improving the generalization ability. High tolerance for some abnormal points. Disadvantages of Decision Tree: Decision tree algorithm is very easy to overfit, resulting in weak generalization ability. It can be improved by setting the minimum sample number of nodes and limiting the depth of decision tree. The decision tree structure will change dramatically when sample changes a little bit. This can be solved by ensemble models such as random forest. Finding the optimal decision tree is an NP-hard problem. We usually get into the local optimal by heuristic method. It can be improved by methods such as integrated learning. For some more complex relationships, decision trees are difficult to learn, such as XOR. There is no way for this. Generally, this relationship can be solved by using neural network classification methods. If the sample ratio of certain features is too large, generating decision trees tends to favor these features. This can be improved by adjusting the sample weights. ","link":"https://zl-wu.github.io/post/mla_decision_tree/"},{"title":"MLA -- Logistic Regression (sklearn instruction)","content":"This is a summary of using logistic regression libraries in sklearn. Focus on the matters that should be paid attention to in the tuning. Reference: sklearn's linear model Sklearn-LR code example In the previous article Logistic Regression Principle, it summarized the principle of logistic regression. Here is a summary of using logistic regression libraries in sklearn. Focus on the matters that should be paid attention to in the tuning. 1. Overview There are mainly 3 Class of logistic regression: LogisticRegression LogisticRegressionCV logistic_regression_path The main difference between LogisticRegression and LogisticRegressionCV is that LogisticRegressionCV uses cross-validation to select the regularization coefficient C. LogisticRegression needs to specify a regularization coefficient each time. Except this coefficient C, LogisticRegression and LogisticRegressionCV are basically used in the same way. The logistic_regression_path class is special. After fitting the data, it cannot directly make predictions, and can only select the appropriate logistic regression coefficient and regularization coefficient for the fitted data. It is mainly used in model selection. This class is generally not used. 2. Regularization Parameter: Penalty LogisticRegression and LogisticRegressionCV have regularization terms by default. Parameter penalty can be 'l1','l2','elasticnet','none'. Default value is 'l2'. l1l_1l1â€‹: minâ¡w,câˆ¥wâˆ¥1+Câˆ‘i=1mlog(exp(âˆ’yi(XiTw+c))+1)\\min_{w,c}\\|w\\|_1 + C\\sum_{i=1}^mlog(exp(-y_i(X_i^Tw+c))+1) w,cminâ€‹âˆ¥wâˆ¥1â€‹+Ci=1âˆ‘mâ€‹log(exp(âˆ’yiâ€‹(XiTâ€‹w+c))+1) l2l_2l2â€‹: minâ¡w,c12wTw+Câˆ‘i=1mlog(exp(âˆ’yi(XiTw+c))+1)\\min_{w,c}\\frac{1}{2}w^Tw + C\\sum_{i=1}^mlog(exp(-y_i(X_i^Tw+c))+1) w,cminâ€‹21â€‹wTw+Ci=1âˆ‘mâ€‹log(exp(âˆ’yiâ€‹(XiTâ€‹w+c))+1) elasticnet: a combination of L1 and L2, and minimizes the following cost function: minâ¡w,c1âˆ’Ï2wTw+Ïâˆ¥wâˆ¥1+Câˆ‘i=1mlog(exp(âˆ’yi(XiTw+c))+1)\\min_{w,c} \\frac{1-\\rho}{2}w^Tw + \\rho\\|w\\|_1 + C\\sum_{i=1}^mlog(exp(-y_i(X_i^Tw+c))+1) w,cminâ€‹21âˆ’Ïâ€‹wTw+Ïâˆ¥wâˆ¥1â€‹+Ci=1âˆ‘mâ€‹log(exp(âˆ’yiâ€‹(XiTâ€‹w+c))+1) When tuning the parameters, if the main purpose is to solve the overfitting, it is generally enough to choose L2 regularization for the penalty. However, if L2 regularization is still overfitting, that is, if the prediction performance is poor with L2, then L1 regularization can be considered. In addition, if the model has lots of features, we hope that some unimportant features' coefficients be zeroed, so that the model coefficients can be sparse, L1 regularization can also be used in this case. The choice of penalty parameter will affect the choice of loss function optimization algorithm (solver parameter): If penalty=&quot;l2l_2l2â€‹&quot; (Ridge Regression), there are 4 optional algorithms (solver): &quot;newton-cg&quot; &quot;lbfgs&quot; &quot;liblinear&quot; &quot;sag&quot; If penalty=&quot;l1l_1l1â€‹&quot; (Lasso Regression), there are only 1 optional algorithms (solver): solver=&quot;liblinear&quot;. Because the loss function with L1 regularization is not derivable, only &quot;liblinear&quot; can solve it. the other three methods [&quot;newton-cg&quot;, &quot;lbfgs&quot;, &quot;sag&quot;] requires the first or second continuous derivative of the loss function. 3. Optimization Algorithm Parameter: Solver There are 5 algorithms can be choosed to optimize Logistic Regression's Loss Function: &quot;newton-cg&quot;: A type of Newton's method family, iteratively optimizes the loss function by using the second derivative matrix of the loss function, the Hessian matrix. &quot;lbfgs&quot;: A kind of quasi-Newton method, iteratively optimizes the loss function by using the second derivative matrix of the loss function, the Hessian matrix. &quot;liblinear&quot;: Coordinate Axis Descent method &quot;sag&quot;: the random average gradient descent, a variant of the gradient descent method. The difference from the ordinary gradient descent method is that only a part of the samples are used to calculate the gradient in each iteration, which is suitable when there are many sample data. (like Mini-Batch Gradient Descent) &quot;saga&quot;: The â€œsagâ€ solver uses Stochastic Average Gradient descent 6. It is faster than other solvers for large datasets, when both the number of samples and the number of features are large. The â€œsagaâ€ solver 7 is a variant of â€œsagâ€ that also supports the non-smooth penalty=&quot;l1&quot;. This is therefore the solver of choice for sparse multinomial logistic regression. It is also the only solver that supports penalty=&quot;elasticnet&quot;. &quot;sag&quot; uses only a part of the samples, so don't choose it when the sample size is small. And if the sample size is very large, such as greater than 100,000, &quot;sag&quot; is the first choice. But sag cannot be used for L1 regularization, so when you have a large number of samples and need L1 regularization, you have to make a trade-off. Either reduce the sample size by sampling the samples, or return to L2 regularization. Note that â€˜sagâ€™ and â€˜sagaâ€™ fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing. Algorithm to use in the optimization problem. For small datasets, â€˜liblinearâ€™ is a good choice, whereas â€˜sagâ€™ and â€˜sagaâ€™ are faster for large ones. For multiclass problems, only â€˜newton-cgâ€™, â€˜sagâ€™, â€˜sagaâ€™ and â€˜lbfgsâ€™ handle multinomial loss; â€˜liblinearâ€™ is limited to one-versus-rest schemes. â€˜newton-cgâ€™, â€˜lbfgsâ€™, â€˜sagâ€™ and â€˜sagaâ€™ handle L2 or no penalty â€˜liblinearâ€™ and â€˜sagaâ€™ also handle L1 penalty â€˜sagaâ€™ also supports â€˜elasticnetâ€™ penalty â€˜liblinearâ€™ does not support setting penalty='none' References L-BFGS-B â€“ Software for Large-scale Bound-constrained Optimization Ciyou Zhu, Richard Byrd, Jorge Nocedal and Jose Luis Morales. http://users.iems.northwestern.edu/~nocedal/lbfgsb.html LIBLINEAR â€“ A Library for Large Linear Classification https://www.csie.ntu.edu.tw/~cjlin/liblinear/ SAG â€“ Mark Schmidt, Nicolas Le Roux, and Francis Bach Minimizing Finite Sums with the Stochastic Average Gradient https://hal.inria.fr/hal-00860051/document SAGA â€“ Defazio, A., Bach F. &amp; Lacoste-Julien S. (2014). SAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives https://arxiv.org/abs/1407.0202 Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent methods for logistic regression and maximum entropy models. Machine Learning 85(1-2):41-75. https://www.csie.ntu.edu.tw/~cjlin/papers/maxent_dual.pdf 4. Classification Type Parameter: Multi_class There are three values can be choose of the parameter multi_class: &quot;ovr&quot;: one-vs-rest(OvR) &quot;multinomial&quot;: many-vs-many(MvM) &quot;auto&quot; If the option chosen is â€˜ovrâ€™, then a binary problem is fit for each label. For â€˜multinomialâ€™ the loss minimised is the multinomial loss fit across the entire probability distribution, even when the data is binary. â€˜multinomialâ€™ is unavailable when solver=â€™liblinearâ€™. â€˜autoâ€™ selects â€˜ovrâ€™ if the data is binary, or if solver=â€™liblinearâ€™, and otherwise selects â€˜multinomialâ€™. The idea of OvR is very simple. No matter how many catogeries in logistic regression classification model, we can treat them as many binary logistic regression. For example, if there are K categories, we view each one of K categories as postive and the rest are negative. Finally we get K-1 classifiers. (like cross validation) The idea of MvM is relatively complicated. For example, if there are T categories, we pick two categories's data from the samples each time, and noted them as T1 and T2 classes (there are CT2C_T^2CT2â€‹ ways). Use T1 as a positive class, and T2 as a negative class to perform binary logistic regression to obtain model parameters. Finally, We need $T(T-1) / 2 $ classifications in total. As we can see, OvR is relatively simple, but the classification performance is relatively poor.(here refers to the distribution of most samples, OvR may be better under certain sample distributions). The MvM classification is relatively accurate, but the classification speed is not as fast as OvR. If choose &quot;ovr&quot;, all 5 solvers can be chose: liblinear, newton-cg, lbfgs, sag, saga. If choose &quot;multinomial&quot;, except &quot;liblinear&quot;, we can use all other 4 solvers. 5. Type Weight Parameter: class_weight class_weight: dict or â€˜balancedâ€™, default=None The class_weight parameter is used to indicate the various categories' weights in the classification model. If None, all categories' weights are the same. Or we can input the weights of each category manually. For a binary model of 0 and 1 as an example, we can define the class_weight = {0: 0.9, 1: 0.1}, so that the weight of type 0 is 90%, and the weight of type 1 is 10%. If class_weight=&quot;balanced&quot;, then the library will calculate the weight based on the training sample size. The larger the sample size of a certain type, the lower the weight, and the smaller the sample size, the higher the weight. So what does class_weight do? In the classification model, we often encounter two types of problems: cost of misclassification. For example, it is very expensive to classify legal users and illegal users and classify illegal users as legal users. We prefer to classify legal users as illegal users. At this time, we can manually re-screen, but we do not want to classify illegal users as legal users . At this time, we can appropriately increase the weight of illegal users. the sample is highly unbalanced. For example, we have 10,000 binary sample data of legal users and illegal users. There are 9995 legal users and only 5 illegal users. If we do nâ€™t consider the weight, we can divide all Of the test sets are predicted as legitimate users, so the prediction accuracy rate is 99.95% in theory, but it does not make any sense. At this time, we can choose balanced to let the class library automatically increase the weight of illegal user samples. And for the second type of sample imbalance, we can also consider using the sample weight parameter mentioned in the next section: sample_weight instead of class_weight. 6. sample_weight Due to the sample imbalance, the sample is not an unbiased estimate of the overall sample, which may lead to a decline in our model's predictive ability. In this case, we can try to solve this problem by adjusting the sample weight. There are two ways to adjust the sample weight. The first is to use balanced in class_weight. The second is to adjust the weight of each sample by sample_weight when calling the fit function. When doing logistic regression in scikit-learn, if the above two methods are used, then the real weight of the sample is class_weight * sample_weight. ","link":"https://zl-wu.github.io/post/mla-logistic-regression-sklearn-instruction/"},{"title":"MLA -- Regularization Lasso Regression","content":"&quot;What is the lasso regression? Add L2 norm into loss function.&quot; Norm is a commonly used concept in mathematics, which is also often encountered in machine learning. The first thing that needs to be clear is that Norm is a function. We usually use it to measure the value of the vector in machine learning. The norm is defined as: âˆ¥xâˆ¥p=(âˆ‘i=1mâˆ£xiâˆ£p)1/p\\|x\\|_p = \\left(\\sum_{i=1}^m |x_i|^p\\right)^{1/p} âˆ¥xâˆ¥pâ€‹=(i=1âˆ‘mâ€‹âˆ£xiâ€‹âˆ£p)1/p Common Norm: L2L^2L2 Norm: When p is 2, L2L^2L2 Norm is also called Euclidean norm. It represents the distance from the original to the points determined by the vector x. It is applied very frequently in machine learning. âˆ¥xâˆ¥2=(âˆ‘i=1mâˆ£xiâˆ£2)1/2\\|x\\|_2 = \\left(\\sum_{i=1}^m |x_i|^2\\right)^{1/2} âˆ¥xâˆ¥2â€‹=(i=1âˆ‘mâ€‹âˆ£xiâ€‹âˆ£2)1/2 Square L2L^2L2 Norm: It is square of L2L^2L2 norm, $ |x|_2^2$. The advantage is that it is obviously easier to calculate, which can be simply calculated by the dot product of XTXX^TXXTX. L1L^1L1 Norm: In some case, L2L^2L2 Norm is not very popular, because it grows very slowly near the origin. Sometimes, it is important to distinguish elements that happen to be zero and non-zero but have very small value. In this case, we can use L1L^1L1 Norm: âˆ¥xâˆ¥1=âˆ‘i=1mâˆ£xiâˆ£\\|x\\|_1 = \\sum_{i=1}^m |x_i| âˆ¥xâˆ¥1â€‹=i=1âˆ‘mâ€‹âˆ£xiâ€‹âˆ£ LâˆL^\\inftyLâˆ Norm: It is also called Maximum norm, which is the absolute value of the element with largest amplitude in the vector: âˆ£âˆ£xâˆ£âˆ£âˆ=maxâˆ£xiâˆ£||x||_\\infty = max|x_i| âˆ£âˆ£xâˆ£âˆ£âˆâ€‹=maxâˆ£xiâ€‹âˆ£ Regularization in Regression 1. Linear Regression Review The norm form of linear regression: hÎ¸(X)=XÎ¸h_\\theta(X) = X\\theta hÎ¸â€‹(X)=XÎ¸ The loss function that we need to minimize: J(Î¸)=12(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)J(\\theta) = \\frac{1}{2}(X\\theta - Y)^T(X\\theta - Y) J(Î¸)=21â€‹(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y) Gradient Descent:Î¸=Î¸âˆ’Î²XT(XÎ¸âˆ’Y)\\theta = \\theta - \\beta X^T(X\\theta - Y) Î¸=Î¸âˆ’Î²XT(XÎ¸âˆ’Y) Least Square:Î¸=(XTX)âˆ’1XTY\\theta = (X^TX)^{-1}X^TY Î¸=(XTX)âˆ’1XTY 2. Ridge Regression Review Since applying linear regression directly may produce verfitting problem, we need to add the regularization term. When L2L^2L2 Norm is added, it is called Ridge Regression. J(Î¸)=12(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)+12Î±âˆ¥Î¸âˆ¥22J(\\theta) = \\frac{1}{2}(X\\theta - Y)^T(X\\theta - Y) + \\frac{1}{2}\\alpha\\|\\theta\\|_2^2 J(Î¸)=21â€‹(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)+21â€‹Î±âˆ¥Î¸âˆ¥22â€‹ Î±\\alphaÎ± is the constant coeffient, which is used to adjust the weights of linear regression term and regularization term. âˆ¥Î¸âˆ¥2\\|\\theta\\|_2âˆ¥Î¸âˆ¥2â€‹ is the L2 norm of Î¸\\thetaÎ¸ vector. Ridge Regression is very simialr to normal linear regression. Gradient Descent: Î¸=Î¸âˆ’Î²(XT(XÎ¸âˆ’Y)+Î±Î¸)=Î¸(1âˆ’Î±Î²)âˆ’Î²(XT(XÎ¸âˆ’Y))\\begin{aligned} \\theta &amp;= \\theta - \\beta(X^T(X\\theta-Y)+\\alpha\\theta) \\\\ &amp;=\\theta(1-\\alpha\\beta) - \\beta(X^T(X\\theta-Y)) \\end{aligned} Î¸â€‹=Î¸âˆ’Î²(XT(XÎ¸âˆ’Y)+Î±Î¸)=Î¸(1âˆ’Î±Î²)âˆ’Î²(XT(XÎ¸âˆ’Y))â€‹ Least Square: Î¸=(XTX+Î±E)âˆ’1XTY\\theta = (X^TX + \\alpha E)^{-1}X^TY Î¸=(XTX+Î±E)âˆ’1XTY Ridge regression reduces the regression coefficients without abandoning any variables. When the coefficient is close to 0, it is equivalent to weakening the significance of its feature. But this model still has a lot of variables, and the model is poorly interpretable. Is there a compromise? That is, it can prevent overfitting and overcome the shortcomings of the Ridge regression model with many variables? Yes, this is the Lasso regression mentioned below. 2. Lasso Regression Similar as Ridge Regreesion, Lasso Regression also adds a Norm term in the loss function to try to avoid overfitting. When L1L^1L1 Norm is added, it is called Lasso Regression. J(Î¸)=12m(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)+Î±âˆ¥Î¸âˆ¥1J(\\theta) = \\frac{1}{2m}(X\\theta - Y)^T(X\\theta - Y) + \\alpha\\|\\theta\\|_1 J(Î¸)=2m1â€‹(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)+Î±âˆ¥Î¸âˆ¥1â€‹ m is the count of sample data. Î±\\alphaÎ± is the constant coeffient, which is used to adjust the weights of linear regression term and regularization term. It needs to be tuned. âˆ¥Î¸âˆ¥1\\|\\theta\\|_1âˆ¥Î¸âˆ¥1â€‹ is the L1 norm of Î¸\\thetaÎ¸ vector. Lasso regression makes some coefficients smaller, and even some coefficients with smaller absolute values directly become 0, so it is especially suitable for the reduction of the number of parameters and the selection of parameters, so it is used to estimate the linear model of sparse parameters. However, there is a big problem with Lasso regression. Its loss function is not continuous and differentiable. Since the L1 norm uses the sum of absolute values, the loss function is not derivative. That is to say, Least Square method, Gradient Descent method, Newton method and Quasi-Newton method all failed in this case. So how can we find the minimum value of the loss function with this L1 norm? There are two new methods to get extreme value: Coordinate Descent Least Angle Regression, LARS 3. Coordinate Descent method for Lasso Regression As the name suggests, Coordinate Descent is the descent in the direction of the coordinate axis, different from the gradient direction in the gradient descent. But both are iterative methods in a heuristic way. Algorithm Process: Intialize Î¸\\thetaÎ¸ as Î¸(0)\\theta^{(0)}Î¸(0). 0 represents the current iteration is 0. In k-th iteration, we calculate Î¸i(k)\\theta_i^{(k)}Î¸i(k)â€‹ started from Î¸1(k)\\theta_1^{(k)}Î¸1(k)â€‹ to Î¸n(k)\\theta_n^{(k)}Î¸n(k)â€‹: Î¸i(k)=arg minâ¡Î¸iJ(Î¸1(k),Î¸2(k),...,Î¸iâˆ’1(k),Î¸i,Î¸i+1(kâˆ’1),...,Î¸n(kâˆ’1))\\theta_i^{(k)}=\\argmin_{\\theta_i} J(\\theta_1^{(k)},\\theta_2^{(k)},...,\\theta_{i-1}^{(k)},\\theta_{i},\\theta_{i+1}^{(k-1)},...,\\theta_{n}^{(k-1)} ) Î¸i(k)â€‹=Î¸iâ€‹argminâ€‹J(Î¸1(k)â€‹,Î¸2(k)â€‹,...,Î¸iâˆ’1(k)â€‹,Î¸iâ€‹,Î¸i+1(kâˆ’1)â€‹,...,Î¸n(kâˆ’1)â€‹) &gt;In this case, $J(\\theta)$ only has one variable $\\theta_i$, and others are all constant. Hence, the minimum value of $J(\\theta)$ can be easily obtained by differentiation. Let's be more specific, in k-th iteration: Î¸1(k)âˆˆarg minâ¡Î¸1J(Î¸1,Î¸2(kâˆ’1),...,Î¸n(kâˆ’1))Î¸2(k)âˆˆarg minâ¡Î¸2J(Î¸1(k),Î¸2,Î¸3(kâˆ’1)...,Î¸n(kâˆ’1))...Î¸n(k)âˆˆarg minâ¡Î¸nJ(Î¸1(k),Î¸2(k),...,Î¸nâˆ’1(k),Î¸n)\\begin{aligned} \\theta_1^{(k)} &amp;\\in \\argmin_{\\theta_1}J(\\theta_1, \\theta_2^{(k-1)},...,\\theta_n^{(k-1)}) \\\\ \\theta_2^{(k)} &amp;\\in \\argmin_{\\theta_2}J(\\theta_1^{(k)}, \\theta_2, \\theta_3^{(k-1)}...,\\theta_n^{(k-1)}) \\\\ ... \\\\ \\theta_n^{(k)} &amp;\\in \\argmin_{\\theta_n}J(\\theta_1^{(k)}, \\theta_2^{(k)}, ...,\\theta_{n-1}^{(k)},\\theta_n) \\end{aligned} Î¸1(k)â€‹Î¸2(k)â€‹...Î¸n(k)â€‹â€‹âˆˆÎ¸1â€‹argminâ€‹J(Î¸1â€‹,Î¸2(kâˆ’1)â€‹,...,Î¸n(kâˆ’1)â€‹)âˆˆÎ¸2â€‹argminâ€‹J(Î¸1(k)â€‹,Î¸2â€‹,Î¸3(kâˆ’1)â€‹...,Î¸n(kâˆ’1)â€‹)âˆˆÎ¸nâ€‹argminâ€‹J(Î¸1(k)â€‹,Î¸2(k)â€‹,...,Î¸nâˆ’1(k)â€‹,Î¸nâ€‹)â€‹ Comparing the Î¸(k)\\theta^{(k)}Î¸(k) vector with Î¸(kâˆ’1)\\theta^{(k-1)}Î¸(kâˆ’1) vector, if the changes are small enough, then Î¸(k)\\theta^{(k)}Î¸(k) is the final return. Otherwise, jumping to Step 2 and continuing (k+1)-th iteration. 4. Least Angle Regression method for Lasso Regression Before introducing Least Angle Regression, let â€™s look at two preliminary algorithms: (Unfinished) 4.1 Forward Selection Algorithm 4.2 Forward Stagewise Algorithm 4.3 Least Angle Regression Algorithm (LARS) 5. Conclusion Reference: LEAST ANGLE REGRESSION By BRADLEY EFRON [web]( ","link":"https://zl-wu.github.io/post/mla-regularization-lasso-regression/"},{"title":"MLA -- Logistic Regression","content":"&quot;Logistic Regression is a kind of very classical and basic classification algorithm.&quot; Logistic Regression is a kind of classification algorithm, it can implement binary classification and multiple classification. It is also a supervised learning algorithm, it implements a mapping from a given data set to 0 and 1 in binary case. Although it is a classification model, the principle of regression still remains in the model. 1. From Linear Regression to Logistic Regression In Linear Regression model, the linear relationship between output vector Y and input sample matrix X is: $ Y = X\\theta $. In this case, Y is continuous, hence, it is a regression model. If we want the output Y is the descrete value (for classification), one method is to do a second transformation on Y, g(Y). Through the function g(Y), all continous value can be mapped to descrete value. For example, Y belongs to category A when it is in a real number interval, and category B when it is in another real number interval. 2. Binary Logistic Regression model In Logistic Regression, we usually use a special function g(Y) to transform continous value Y: g(z)=11+eâˆ’zg(z) = \\frac{1}{1+e^{-z}} g(z)=1+eâˆ’z1â€‹ This function has some very good properties, which are suitable for classification probability model: g(z)âˆˆ(0,1)g(z) \\in (0,1)g(z)âˆˆ(0,1) When z tends to positive infinity +âˆ+\\infty+âˆ, g(z) tends to 1. When z tends to negative infinity âˆ’âˆ-\\inftyâˆ’âˆ, g(z) tends to 0. A good derivative propertiy:gâ€²(z)=g(z)(1âˆ’g(z))g&#x27;(z) = g(z)(1-g(z)) gâ€²(z)=g(z)(1âˆ’g(z)) If z=xÎ¸z=x\\thetaz=xÎ¸, the general form of logistic regression model is: hÎ¸(x)=11+eâˆ’xÎ¸h_\\theta(x) = \\frac{1}{1+e^{-x\\theta}} hÎ¸â€‹(x)=1+eâˆ’xÎ¸1â€‹ x is one 1xn data vector to be predicted. (n features) Î¸\\thetaÎ¸ is a nx1 parameters vector. xÎ¸x\\thetaxÎ¸ is a linear regression scalar. hÎ¸(x)h_\\theta(x)hÎ¸â€‹(x) can be understood as the probability of one certain category. We have this correspondence with our binary sample output y (assuming 0 and 1): If hÎ¸(x)h_\\theta(x)hÎ¸â€‹(x) &gt; 0.5 (xÎ¸x\\thetaxÎ¸ &gt; 0), predict y = 1. If hÎ¸(x)h_\\theta(x)hÎ¸â€‹(x) &lt; 0.5 (xÎ¸x\\thetaxÎ¸ &lt; 0), predict y = 0. The smaller the value of hÎ¸(x)h_\\theta(x)hÎ¸â€‹(x), the higher the probability of being classified as 0. Conversely, the larger the value of hÎ¸(x)h_\\theta(x)hÎ¸â€‹(x), the higher the probability of being classified as 1. If it is close to the critical point (0.5), the classification accuracy will decrease. In matrix expression: hÎ¸(X)=11+eâˆ’XÎ¸h_\\theta(X) = \\frac{1}{1+e^{-X\\theta}} hÎ¸â€‹(X)=1+eâˆ’XÎ¸1â€‹ hÎ¸(X)h_\\theta(X)hÎ¸â€‹(X) is the output of logistic regression model. mx1 dimensions. X is the input sample data features matrix. mxn dimensions. Î¸\\thetaÎ¸ is the model coefficients for classification. nx1 dimensions. After understanding the Logistic Regression model of binary classification, we have to look at the loss function of the model, our goal is to minimize the loss function to get the corresponding model coefficients Î¸\\thetaÎ¸. 3. Loss Function of Binary Logistic Regression Since the linear regression model is continuous, its loss function is Square Sum of Error. However, the logistic funtion is not continuous, SSE is not feasible in this case (will prove it later in the article). Now, we can use Maximum Likelihood Method to derive the loss function. Suppose the output sample is two value: 0 or 1, then it follows Bernoulli distribution. P(y=1âˆ£x,Î¸)=hÎ¸(x)P(y=0âˆ£x,Î¸)=1âˆ’hÎ¸(x)\\begin{aligned} &amp;P(y=1|x,\\theta) = h_\\theta(x) \\\\ &amp;P(y=0|x,\\theta) = 1- h_\\theta(x) \\end{aligned} â€‹P(y=1âˆ£x,Î¸)=hÎ¸â€‹(x)P(y=0âˆ£x,Î¸)=1âˆ’hÎ¸â€‹(x)â€‹ Combine above two formula, the probability distribution function is: P(yâˆ£x,Î¸)=hÎ¸(x)y(1âˆ’hÎ¸(x))1âˆ’yP(y|x,\\theta) = h_\\theta(x)^y(1-h_\\theta(x))^{1-y} P(yâˆ£x,Î¸)=hÎ¸â€‹(x)y(1âˆ’hÎ¸â€‹(x))1âˆ’y yâˆˆ{0,1}y \\in \\{0,1\\}yâˆˆ{0,1} Through likelihood function maxmization, we can derive the model coefficient parameters Î¸\\thetaÎ¸ that we need. Assume that the samples are independent and identically distributed, Likelihood Function is: L(Î¸)=âˆi=1m(hÎ¸(x(i)))y(i)(1âˆ’hÎ¸(x(i)))1âˆ’y(i) L(\\theta) = \\prod_{i=1}^m (h_\\theta(x^{(i)}))^{y^{(i)}} (1 - h_\\theta(x^{(i)}))^{1-y^{(i)}} L(Î¸)=i=1âˆmâ€‹(hÎ¸â€‹(x(i)))y(i)(1âˆ’hÎ¸â€‹(x(i)))1âˆ’y(i) m is the counts of sample The function that inverts the logarithmization of the likelihood function, that is, the loss function is: J(Î¸)=âˆ’ln(L(Î¸))=âˆ’âˆ‘i=1m(y(i)ln(hÎ¸(x(i)))+(1âˆ’y(i))ln(1âˆ’hÎ¸(x(i))))\\begin{aligned} J(\\theta) &amp;= -ln(L(\\theta)) \\\\ &amp;=-\\sum_{i=1}^m (y^{(i)}ln(h_\\theta(x^{(i)})) + (1-y^{(i)})ln(1-h_\\theta(x^{(i)}))) \\end{aligned} J(Î¸)â€‹=âˆ’ln(L(Î¸))=âˆ’i=1âˆ‘mâ€‹(y(i)ln(hÎ¸â€‹(x(i)))+(1âˆ’y(i))ln(1âˆ’hÎ¸â€‹(x(i))))â€‹ In Matrix Expression: J(Î¸)=âˆ’YTln(hÎ¸(X))âˆ’(Eâˆ’Y)Tln(Eâˆ’hÎ¸(X))J(\\theta) = -Y^Tln(h_\\theta(X)) - (E-Y)^Tln(E-h_\\theta(X)) J(Î¸)=âˆ’YTln(hÎ¸â€‹(X))âˆ’(Eâˆ’Y)Tln(Eâˆ’hÎ¸â€‹(X)) E is an all 1 vector. 4. Optimization method of Loss Function There are lots of method to minimize the loss function of Logistic Regression model. Most common methods include gradient descent, coordinate descent, and Newton's method. Only each iteration's formula of gradient descent method is derived here. 4.1 Algebraic Expression J(Î¸)=âˆ’âˆ‘i=1m(y(i)ln(hÎ¸(x(i)))+(1âˆ’y(i))ln(1âˆ’hÎ¸(x(i))))J(\\theta) = -\\sum_{i=1}^m (y^{(i)}ln(h_\\theta(x^{(i)})) + (1-y^{(i)})ln(1-h_\\theta(x^{(i)}))) J(Î¸)=âˆ’i=1âˆ‘mâ€‹(y(i)ln(hÎ¸â€‹(x(i)))+(1âˆ’y(i))ln(1âˆ’hÎ¸â€‹(x(i)))) âˆ‚âˆ‚Î¸jJ(Î¸)=âˆ’âˆ‚âˆ‘i=1m(y(i)ln(hÎ¸(x(i)))+(1âˆ’y(i))ln(1âˆ’hÎ¸(x(i))))âˆ‚Î¸j=âˆ’âˆ‘i=1my(i)hÎ¸(x(i))âˆ‚hÎ¸(x(i))âˆ‚Î¸jâˆ’1âˆ’y(i)1âˆ’hÎ¸(x(i))âˆ‚hÎ¸(x(i))âˆ‚Î¸j=âˆ’âˆ‘i=1m(y(i)hÎ¸(x(i))âˆ’1âˆ’y(i)1âˆ’hÎ¸(x(i)))âˆ‚hÎ¸(x(i))âˆ‚Î¸j=âˆ’âˆ‘i=1my(i)âˆ’hÎ¸(x(i))hÎ¸(x(i))(1âˆ’hÎ¸(x(i)))hÎ¸â€²(x(i))âˆ‚XÎ¸âˆ‚Î¸j=âˆ’âˆ‘i=1my(i)âˆ’hÎ¸(x(i))hÎ¸(x(i))(1âˆ’hÎ¸(x(i)))hÎ¸(x(i))(1âˆ’hÎ¸(x(i)))xj(i)=âˆ’âˆ‘i=1m(y(i)âˆ’hÎ¸(x(i)))xj(i)=âˆ‘i=1m(hÎ¸(x(i))âˆ’y(i))xj(i)\\begin{aligned} \\frac{\\partial}{\\partial\\theta_j}J(\\theta) &amp;= -\\frac{\\partial\\sum_{i=1}^m (y^{(i)}ln(h_\\theta(x^{(i)})) + (1-y^{(i)})ln(1-h_\\theta(x^{(i)})))}{\\partial\\theta_j} \\\\ &amp;= - \\sum_{i=1}^m \\frac{y^{(i)}}{h_\\theta(x^{(i)})} \\frac{\\partial h_\\theta(x^{(i)})}{\\partial\\theta_j} - \\frac{1-y^{(i)}}{1-h_\\theta(x^{(i)})} \\frac{\\partial h_\\theta(x^{(i)})}{\\partial\\theta_j} \\\\ &amp;= - \\sum_{i=1}^m (\\frac{y^{(i)}}{h_\\theta(x^{(i)})} - \\frac{1-y^{(i)}}{1-h_\\theta(x^{(i)})}) \\frac{\\partial h_\\theta(x^{(i)})}{\\partial\\theta_j} \\\\ &amp;= - \\sum_{i=1}^m \\frac{y^{(i)} - h_\\theta(x^{(i)})}{h_\\theta(x^{(i)})(1-h_\\theta(x^{(i)}))} h&#x27;_\\theta(x^{(i)})\\frac{\\partial X\\theta}{\\partial\\theta_j} \\\\ &amp;= - \\sum_{i=1}^m \\frac{y^{(i)} - h_\\theta(x^{(i)})}{h_\\theta(x^{(i)})(1-h_\\theta(x^{(i)}))} h_\\theta(x^{(i)})(1-h_\\theta(x^{(i)})) x_j^{(i)} \\\\ &amp;= - \\sum_{i=1}^m (y^{(i)} - h_\\theta(x^{(i)}))x_j^{(i)} \\\\ &amp;= \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} \\end{aligned} âˆ‚Î¸jâ€‹âˆ‚â€‹J(Î¸)â€‹=âˆ’âˆ‚Î¸jâ€‹âˆ‚âˆ‘i=1mâ€‹(y(i)ln(hÎ¸â€‹(x(i)))+(1âˆ’y(i))ln(1âˆ’hÎ¸â€‹(x(i))))â€‹=âˆ’i=1âˆ‘mâ€‹hÎ¸â€‹(x(i))y(i)â€‹âˆ‚Î¸jâ€‹âˆ‚hÎ¸â€‹(x(i))â€‹âˆ’1âˆ’hÎ¸â€‹(x(i))1âˆ’y(i)â€‹âˆ‚Î¸jâ€‹âˆ‚hÎ¸â€‹(x(i))â€‹=âˆ’i=1âˆ‘mâ€‹(hÎ¸â€‹(x(i))y(i)â€‹âˆ’1âˆ’hÎ¸â€‹(x(i))1âˆ’y(i)â€‹)âˆ‚Î¸jâ€‹âˆ‚hÎ¸â€‹(x(i))â€‹=âˆ’i=1âˆ‘mâ€‹hÎ¸â€‹(x(i))(1âˆ’hÎ¸â€‹(x(i)))y(i)âˆ’hÎ¸â€‹(x(i))â€‹hÎ¸â€²â€‹(x(i))âˆ‚Î¸jâ€‹âˆ‚XÎ¸â€‹=âˆ’i=1âˆ‘mâ€‹hÎ¸â€‹(x(i))(1âˆ’hÎ¸â€‹(x(i)))y(i)âˆ’hÎ¸â€‹(x(i))â€‹hÎ¸â€‹(x(i))(1âˆ’hÎ¸â€‹(x(i)))xj(i)â€‹=âˆ’i=1âˆ‘mâ€‹(y(i)âˆ’hÎ¸â€‹(x(i)))xj(i)â€‹=i=1âˆ‘mâ€‹(hÎ¸â€‹(x(i))âˆ’y(i))xj(i)â€‹â€‹ In gradient descent iteration: Î¸j=Î¸jâˆ’Î±âˆ‘i=1m(hÎ¸(x(i))âˆ’y(i))xj(i)\\theta_j = \\theta_j - \\alpha\\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})x_j^{(i)} Î¸jâ€‹=Î¸jâ€‹âˆ’Î±i=1âˆ‘mâ€‹(hÎ¸â€‹(x(i))âˆ’y(i))xj(i)â€‹ j = 0,1,2,...,n 4.2 Matrix Expression J(Î¸)=âˆ’YTln(hÎ¸(X))âˆ’(Eâˆ’Y)Tln(Eâˆ’hÎ¸(X))J(\\theta) = -Y^Tln(h_\\theta(X)) - (E-Y)^Tln(E-h_\\theta(X)) J(Î¸)=âˆ’YTln(hÎ¸â€‹(X))âˆ’(Eâˆ’Y)Tln(Eâˆ’hÎ¸â€‹(X)) âˆ‚âˆ‚Î¸J(Î¸)=XT[1hÎ¸(X)âŠ™hÎ¸(X)âŠ™(Eâˆ’hÎ¸(X)âŠ™(âˆ’Y))]+XT[1Eâˆ’hÎ¸(X)âŠ™hÎ¸(X)âŠ™(Eâˆ’hÎ¸(X)âŠ™(Eâˆ’Y))]=XT(hÎ¸(X)âˆ’Y)\\begin{aligned} \\frac{\\partial}{\\partial\\theta}J(\\theta) &amp;= X^T \\left[\\frac{1}{h_\\theta(X)} \\odot h_\\theta(X) \\odot (E-h_\\theta(X) \\odot (-Y)) \\right] + X^T \\left[\\frac{1}{E-h_\\theta(X)} \\odot h_\\theta(X) \\odot (E-h_\\theta(X) \\odot (E-Y)) \\right] \\\\ &amp;= X^T(h_\\theta(X) - Y) \\end{aligned} âˆ‚Î¸âˆ‚â€‹J(Î¸)â€‹=XT[hÎ¸â€‹(X)1â€‹âŠ™hÎ¸â€‹(X)âŠ™(Eâˆ’hÎ¸â€‹(X)âŠ™(âˆ’Y))]+XT[Eâˆ’hÎ¸â€‹(X)1â€‹âŠ™hÎ¸â€‹(X)âŠ™(Eâˆ’hÎ¸â€‹(X)âŠ™(Eâˆ’Y))]=XT(hÎ¸â€‹(X)âˆ’Y)â€‹ It used the chain rules of vector differentiation: âˆ‚âˆ‚Xlog(X)=1/X\\frac{\\partial}{\\partial X}log(X)=1/Xâˆ‚Xâˆ‚â€‹log(X)=1/X âˆ‚âˆ‚zg(z)=g(z)(1âˆ’g(z))\\frac{\\partial}{\\partial z}g(z) = g(z)(1-g(z))âˆ‚zâˆ‚â€‹g(z)=g(z)(1âˆ’g(z)), [g(z) is the sigmoid function] âˆ‚XÎ¸âˆ‚Î¸=X\\frac{\\partial X\\theta}{\\partial \\theta}= Xâˆ‚Î¸âˆ‚XÎ¸â€‹=X The iteration formula of Î¸\\thetaÎ¸ is : Î¸=Î¸âˆ’Î±XT(hÎ¸(X)âˆ’Y)\\theta = \\theta - \\alpha X^T(h_\\theta(X)-Y) Î¸=Î¸âˆ’Î±XT(hÎ¸â€‹(X)âˆ’Y) 5. Regularization of Logistic Regression In order to avoiding overfitting, we need to consider regularization. Most common methods are L1 and L2 regularization. L1L_1L1â€‹ regularization J(Î¸)=âˆ’YTln(hÎ¸(X))âˆ’(Eâˆ’Y)Tln(Eâˆ’hÎ¸(X))+Î±âˆ¥Î¸âˆ¥1J(\\theta) = -Y^Tln(h_\\theta(X)) - (E-Y)^Tln(E-h_\\theta(X)) + \\alpha\\|\\theta\\|_1 J(Î¸)=âˆ’YTln(hÎ¸â€‹(X))âˆ’(Eâˆ’Y)Tln(Eâˆ’hÎ¸â€‹(X))+Î±âˆ¥Î¸âˆ¥1â€‹ This L1 loss function is not derivable, we can find the parameters that minimize funtion based on two methods: Coordinate Descent or Least Angle Regression L2L_2L2â€‹ regularization J(Î¸)=âˆ’YTln(hÎ¸(X))âˆ’(Eâˆ’Y)Tln(Eâˆ’hÎ¸(X))+12Î±âˆ¥Î¸âˆ¥22J(\\theta) = -Y^Tln(h_\\theta(X)) - (E-Y)^Tln(E-h_\\theta(X)) + \\frac{1}{2}\\alpha\\|\\theta\\|_2^2 J(Î¸)=âˆ’YTln(hÎ¸â€‹(X))âˆ’(Eâˆ’Y)Tln(Eâˆ’hÎ¸â€‹(X))+21â€‹Î±âˆ¥Î¸âˆ¥22â€‹ The optimization method of L2 loss function is similar to ordinary logistic regression. 6. Promotion of binary : Multiple Logistic Regression Binary Case P(y=1âˆ£x,Î¸)=hÎ¸(x)=11+eâˆ’xÎ¸=exÎ¸1+exÎ¸P(y=0âˆ£x,Î¸)=1âˆ’hÎ¸(x)=11+exÎ¸\\begin{aligned} &amp;P(y=1|x,\\theta) = h_\\theta(x) = \\frac{1}{1+e^{-x\\theta}} = \\frac{e^{x\\theta}}{1+e^{x\\theta}} \\\\ &amp;P(y=0|x,\\theta) = 1-h_\\theta(x) = \\frac{1}{1+e^{x\\theta}} \\end{aligned} â€‹P(y=1âˆ£x,Î¸)=hÎ¸â€‹(x)=1+eâˆ’xÎ¸1â€‹=1+exÎ¸exÎ¸â€‹P(y=0âˆ£x,Î¸)=1âˆ’hÎ¸â€‹(x)=1+exÎ¸1â€‹â€‹ y can only be 0 or 1, then: ln(P(y=1âˆ£x,Î¸)P(y=0âˆ£x,Î¸))=xÎ¸ln\\left(\\frac{P(y=1|x,\\theta)}{P(y=0|x,\\theta)}\\right) = x\\theta ln(P(y=0âˆ£x,Î¸)P(y=1âˆ£x,Î¸)â€‹)=xÎ¸ Suppose there is a K classification model, the value of the sample output y is 1,2,...,K. According to the experience of binary classification, we get: ln(P(y=1âˆ£x,Î¸)P(y=Kâˆ£x,Î¸))=xÎ¸1ln(P(y=2âˆ£x,Î¸)P(y=Kâˆ£x,Î¸))=xÎ¸2...ln(P(y=Kâˆ’1âˆ£x,Î¸)P(y=Kâˆ£x,Î¸))=xÎ¸Kâˆ’1\\begin{aligned} &amp;ln\\left(\\frac{P(y=1|x,\\theta)}{P(y=K|x,\\theta)}\\right) = x\\theta_1 \\\\ &amp;ln\\left(\\frac{P(y=2|x,\\theta)}{P(y=K|x,\\theta)}\\right) = x\\theta_2 \\\\ &amp;... \\\\ &amp;ln\\left(\\frac{P(y=K-1|x,\\theta)}{P(y=K|x,\\theta)}\\right) = x\\theta_{K-1} \\\\ \\end{aligned} â€‹ln(P(y=Kâˆ£x,Î¸)P(y=1âˆ£x,Î¸)â€‹)=xÎ¸1â€‹ln(P(y=Kâˆ£x,Î¸)P(y=2âˆ£x,Î¸)â€‹)=xÎ¸2â€‹...ln(P(y=Kâˆ£x,Î¸)P(y=Kâˆ’1âˆ£x,Î¸)â€‹)=xÎ¸Kâˆ’1â€‹â€‹ There are K-1 equations above, and the sum of all probability is 1: âˆ‘i=1KP(y=iâˆ£x,Î¸)=1\\sum_{i=1}^KP(y=i|x,\\theta) = 1 i=1âˆ‘Kâ€‹P(y=iâˆ£x,Î¸)=1 Then there are K equations now. Solving this K linear equations, the probability distribution of K logistic regression is as follows: P(y=kâˆ£x,Î¸)=exÎ¸k1+âˆ‘t=1Kâˆ’1exÎ¸tk=1,2,...,Kâˆ’1P(y=Kâˆ£x,Î¸)=11+âˆ‘t=1Kâˆ’1exÎ¸t\\begin{aligned} &amp;P(y=k|x,\\theta) = \\frac{e^{x\\theta_k}}{1+\\sum_{t=1}^{K-1}e^{x\\theta_t}} &amp;k=1,2,...,K-1 \\\\ &amp;P(y=K|x,\\theta) = \\frac{1}{1+\\sum_{t=1}^{K-1}e^{x\\theta_t}} \\end{aligned} â€‹P(y=kâˆ£x,Î¸)=1+âˆ‘t=1Kâˆ’1â€‹exÎ¸tâ€‹exÎ¸kâ€‹â€‹P(y=Kâˆ£x,Î¸)=1+âˆ‘t=1Kâˆ’1â€‹exÎ¸tâ€‹1â€‹â€‹k=1,2,...,Kâˆ’1 The loss function derivation and optimization of multiple logistic regression is similar to that of binary logistic regression. 7. Conclusion Logistic regression, especially binary logistic regression, is a very common model. The training speed is very fast. Although it is not as mainstream as the support vector machine (SVM), it is enough to solve normal classification problems. The training speed is also faster than SVM. Question: For logistic regression, why is the Square Sum of Error non-convex and not suitable as the loss function? Suppose we use SSE as logistic regression's loss function: J(Î¸)=12âˆ‘i=1m(y^iâˆ’yi)2J(\\theta) = \\frac{1}{2}\\sum_{i=1}^m(\\hat{y}_i - y_i)^2 J(Î¸)=21â€‹i=1âˆ‘mâ€‹(y^â€‹iâ€‹âˆ’yiâ€‹)2 y^i=11+eâˆ’xiÎ¸\\hat{y}_i = \\frac{1}{1+e^{-x_i\\theta}} y^â€‹iâ€‹=1+eâˆ’xiâ€‹Î¸1â€‹ To determine whether J is a convex function, it depends on whether its second derivative is greater than 0. âˆ‚âˆ‚Î¸jJ(Î¸)=âˆ‘i=1m(y^iâˆ’yi)âˆ‚y^iâˆ‚Î¸j=âˆ‘i=1m(y^iâˆ’yi)y^i(1âˆ’y^i)xj(i)=âˆ‘i=1m(âˆ’y^i3+(yi+1)y^i2âˆ’yiy^i)xj(i)\\begin{aligned} \\frac{\\partial}{\\partial\\theta_j}J(\\theta) &amp;= \\sum_{i=1}^m(\\hat{y}_i - y_i)\\frac{\\partial\\hat{y}_i}{\\partial\\theta_j} \\\\ &amp;= \\sum_{i=1}^m(\\hat{y}_i - y_i)\\hat{y}_i(1-\\hat{y}_i)x_j^{(i)} \\\\ &amp;= \\sum_{i=1}^m(-\\hat{y}_i^3 + (y_i+1)\\hat{y}_i^2 - y_i\\hat{y}_i)x_j^{(i)} \\end{aligned} âˆ‚Î¸jâ€‹âˆ‚â€‹J(Î¸)â€‹=i=1âˆ‘mâ€‹(y^â€‹iâ€‹âˆ’yiâ€‹)âˆ‚Î¸jâ€‹âˆ‚y^â€‹iâ€‹â€‹=i=1âˆ‘mâ€‹(y^â€‹iâ€‹âˆ’yiâ€‹)y^â€‹iâ€‹(1âˆ’y^â€‹iâ€‹)xj(i)â€‹=i=1âˆ‘mâ€‹(âˆ’y^â€‹i3â€‹+(yiâ€‹+1)y^â€‹i2â€‹âˆ’yiâ€‹y^â€‹iâ€‹)xj(i)â€‹â€‹ âˆ‚2âˆ‚Î¸jJ(Î¸)=âˆ‘i=1m(âˆ’3y^i2+2(yi+1)y^iâˆ’yi)xj(i)âˆ‚y^âˆ‚Î¸j=âˆ‘i=1m[âˆ’3y^i2+2(yi+1)y^iâˆ’yi]y^i(1âˆ’y^i)(xj(i))2\\begin{aligned} \\frac{\\partial^2}{\\partial\\theta_j}J(\\theta) &amp;= \\sum_{i=1}^m(-3\\hat{y}_i^2 + 2(y_i+1)\\hat{y}_i - y_i)x_j^{(i)}\\frac{\\partial\\hat{y}}{\\partial\\theta_j} \\\\ &amp;= \\sum_{i=1}^m\\left[-3\\hat{y}_i^2 + 2(y_i+1)\\hat{y}_i - y_i\\right]\\hat{y}_i(1-\\hat{y}_i)(x_j^{(i)})^2 \\end{aligned} âˆ‚Î¸jâ€‹âˆ‚2â€‹J(Î¸)â€‹=i=1âˆ‘mâ€‹(âˆ’3y^â€‹i2â€‹+2(yiâ€‹+1)y^â€‹iâ€‹âˆ’yiâ€‹)xj(i)â€‹âˆ‚Î¸jâ€‹âˆ‚y^â€‹â€‹=i=1âˆ‘mâ€‹[âˆ’3y^â€‹i2â€‹+2(yiâ€‹+1)y^â€‹iâ€‹âˆ’yiâ€‹]y^â€‹iâ€‹(1âˆ’y^â€‹iâ€‹)(xj(i)â€‹)2â€‹ y^âˆˆ(0,1)\\hat{y} \\in (0,1)y^â€‹âˆˆ(0,1), hence, y^i(1âˆ’y^i)(xj(i))2\\hat{y}_i(1-\\hat{y}_i)(x_j^{(i)})^2y^â€‹iâ€‹(1âˆ’y^â€‹iâ€‹)(xj(i)â€‹)2 &gt; 0. Therefore, the positive and negative property of the second derivative of J is determined by the term [âˆ’3y^i2+2(yi+1)y^iâˆ’yi][-3\\hat{y}_i^2 + 2(y_i+1)\\hat{y}_i - y_i][âˆ’3y^â€‹i2â€‹+2(yiâ€‹+1)y^â€‹iâ€‹âˆ’yiâ€‹] And yiâˆˆ{0,1}y_i \\in \\{0,1\\}yiâ€‹âˆˆ{0,1} when yi=0y_i=0yiâ€‹=0, the term is [âˆ’3y^i2+2y^i][-3\\hat{y}_i^2 + 2\\hat{y}_i][âˆ’3y^â€‹i2â€‹+2y^â€‹iâ€‹]. The condition of this term being greater than 0 is y^&lt;2/3\\hat{y}&lt;2/3y^â€‹&lt;2/3 when yi=1y_i=1yiâ€‹=1, the term is [âˆ’3y^i2+4y^iâˆ’1]=âˆ’(3y^iâˆ’1)(y^iâˆ’1)[-3\\hat{y}_i^2 + 4\\hat{y}_i - 1]=-(3\\hat{y}_i-1)(\\hat{y}_i-1)[âˆ’3y^â€‹i2â€‹+4y^â€‹iâ€‹âˆ’1]=âˆ’(3y^â€‹iâ€‹âˆ’1)(y^â€‹iâ€‹âˆ’1). The condition of this term being greater than 0 is y^&lt;1/3\\hat{y}&lt;1/3y^â€‹&lt;1/3 As we can see, only when y^âˆˆ(0,13)\\hat{y} \\in (0,\\frac{1}{3})y^â€‹âˆˆ(0,31â€‹), we are sure the second derivative is greater than 0. The second derivative of J is not strictly greater than 0, so J is not a convex function. And J (SSE) is not suitable as Loss Function. ","link":"https://zl-wu.github.io/post/mla-logistic-regression/"},{"title":"MLA -- Linear Regression Principle","content":"&quot;Linear Regression is the beginning and the most basic algorithm.&quot; Linear Regression is the most basic question in Machine Learning. Here is a simple summary of Linear Regression Algorithm principle. 1. Linear Regression Question If we have m sample data, each sample has n features and one result value: (x1(1),x2(1),...,xn(1),y1),(x1(2),x2(2),...,xn(2),y2),...,(x1(m),x2(m),...,xn(m),ym)(x^{(1)}_1,x^{(1)}_2,...,x^{(1)}_n, y_1), (x^{(2)}_1,x^{(2)}_2,...,x^{(2)}_n, y_2), ..., (x^{(m)}_1,x^{(m)}_2,...,x^{(m)}_n, y_m)(x1(1)â€‹,x2(1)â€‹,...,xn(1)â€‹,y1â€‹),(x1(2)â€‹,x2(2)â€‹,...,xn(2)â€‹,y2â€‹),...,(x1(m)â€‹,x2(m)â€‹,...,xn(m)â€‹,ymâ€‹) Now question is if we get a new data with only n features: $ (x{(a)}_1,x{(a)}_2,...,x^{(a)}_n) $, how can we predict its result value $ y_a $? And what is it? If $ y_a $ is the continuous value, it is a regression question. And if $ y_a $ is the discrete value, it is a classification question. 2. Linear Regression Model If we decide to solve this question with linear regression, then we assume the data model is in this form: $ h_\\theta(x_0,x_1,..,x_n) = \\theta_0 + \\theta_1x_1 + ... + \\theta_nx_n $ Î¸i\\theta_iÎ¸iâ€‹ (i=0,1,...,n) is the coefficient of each feature, which is also the parameter of the model we need to estimate. If we assume x0=1x_0=1x0â€‹=1, then model can be wrote in a simpler way: $ h_\\theta(x_0,x_1,..,x_n) = \\sum_{i=0}^n \\theta_ix_i $ If we use matrix representation, Model will become more simple and elegant: $ h_\\theta(X) = X\\theta $ X is a mÃ—nm \\times nmÃ—n matrix (m records and n features). Î¸\\thetaÎ¸ is a nÃ—1n \\times 1nÃ—1 vector (n coefficients of n features). hÎ¸(X)h_\\theta(X)hÎ¸â€‹(X) is a mÃ—1m\\times 1mÃ—1 vector (m prediction y value of m sample records) Once we have determined the model prototype, we need to calculate the Loss Function. Generally, we use Mean Square Error as the loss function for linear regression model. The algebratic representation of the loss function is as follows: J(Î¸0,Î¸1,...,Î¸n)=âˆ‘i=1m(hÎ¸(x0(i),x1(i),..,xn(i))âˆ’yi)2J(\\theta_0,\\theta_1,...,\\theta_n) = \\sum_{i=1}^m (h_\\theta(x_0^{(i)},x_1^{(i)},..,x_n^{(i)}) - y_i)^2 J(Î¸0â€‹,Î¸1â€‹,...,Î¸nâ€‹)=i=1âˆ‘mâ€‹(hÎ¸â€‹(x0(i)â€‹,x1(i)â€‹,..,xn(i)â€‹)âˆ’yiâ€‹)2 In Matix Representation: J(Î¸)=12(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)J(\\theta) = \\frac{1}{2} (X\\theta - Y)^T(X\\theta - Y) J(Î¸)=21â€‹(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y) Y is a mÃ—1m\\times 1mÃ—1 vector (m actual y value of m sample records) 3. Linear Regression Algorithm Once the loss function is known, our goal is to find out the parameter Î¸\\thetaÎ¸ that could minimize the value of loss function. There are two methods: Gradient Descent method Least Square method If we choose Gradient Descent method, the iteration formula of Î¸\\thetaÎ¸ is: Î¸=Î¸âˆ’Î±XT(XÎ¸âˆ’Y)\\theta = \\theta - \\alpha X^T(X\\theta-Y) Î¸=Î¸âˆ’Î±XT(XÎ¸âˆ’Y) If we choose Least Square method, the formula of Î¸\\thetaÎ¸ is: Î¸=(XTX)âˆ’1XTY\\theta = (X^TX)^{-1}X^TY Î¸=(XTX)âˆ’1XTY 4.1. Generalization of linear regression: Polynomial Regression If the model prototype exists not only to the first power, but also to the second power, n-th power, the model becomes Polynomial Regression. For example, if the sample data has 2 features: (x1(1),x2(1),y1),(x1(2),x2(2),y2),...,(x1(m),x2(m),ym)(x_1^{(1)}, x_2^{(1)}, y_1), (x_1^{(2)}, x_2^{(2)}, y_2),...,(x_1^{(m)}, x_2^{(m)}, y_m) (x1(1)â€‹,x2(1)â€‹,y1â€‹),(x1(2)â€‹,x2(2)â€‹,y2â€‹),...,(x1(m)â€‹,x2(m)â€‹,ymâ€‹) Assume the model is in this form: hÎ¸(x1,x2)=Î¸0+Î¸1x1+Î¸2x2+Î¸3x12+Î¸4x22+Î¸5x1x2h_\\theta(x_1,x_2) = \\theta_0+\\theta_1x_1+\\theta_2x_2 + \\theta_3x_1^2 + \\theta_4x_2^2 + \\theta_5x_1x_2 hÎ¸â€‹(x1â€‹,x2â€‹)=Î¸0â€‹+Î¸1â€‹x1â€‹+Î¸2â€‹x2â€‹+Î¸3â€‹x12â€‹+Î¸4â€‹x22â€‹+Î¸5â€‹x1â€‹x2â€‹ If we define: x0=1,x1=x1,x2=x2,x3=x12,x4=x22,x5=x1x2x_0=1, x_1=x_1, x_2=x_2, x_3=x_1^2, x_4=x_2^2, x_5=x_1x_2x0â€‹=1,x1â€‹=x1â€‹,x2â€‹=x2â€‹,x3â€‹=x12â€‹,x4â€‹=x22â€‹,x5â€‹=x1â€‹x2â€‹, then the Polynomial model is back to linear regression: hÎ¸(x1,x2)=Î¸0+Î¸1x1+Î¸2x2+Î¸3x3+Î¸4x4+Î¸5x5h_\\theta(x_1,x_2) = \\theta_0+\\theta_1x_1+\\theta_2x_2 + \\theta_3x_3 + \\theta_4x_4 + \\theta_5x_5 hÎ¸â€‹(x1â€‹,x2â€‹)=Î¸0â€‹+Î¸1â€‹x1â€‹+Î¸2â€‹x2â€‹+Î¸3â€‹x3â€‹+Î¸4â€‹x4â€‹+Î¸5â€‹x5â€‹ Therefore, the solution is to build a 5 features sample data (x1,x2,x12,x22,x1x2)(x_1, x_2, x_1^2, x_2^2, x_1x_2)(x1â€‹,x2â€‹,x12â€‹,x22â€‹,x1â€‹x2â€‹) for the 2 features sample data (x1,x2)(x_1,x_2)(x1â€‹,x2â€‹). Then we use this 5 features data to train the linear regression model. 4.2. Generalization of linear regression: Generalized Linear Regression In 4.1 section, we generized the feature side of the sample data. Now we try to generize the y value of the sample data. For example, if the Y does not have a linear relationship X, but ln(Y) does: ln(Y)=XÎ¸ln(Y) = X\\theta ln(Y)=XÎ¸ In this case, use ln(y) instead of y, we can still deal with the problem with linear regression model. We generalize In(y), assuming this function is a monotonically differentiable function ğ  (.), Then the generalized generalized linear regression form is: g(Y)=XÎ¸g(Y) = X\\theta g(Y)=XÎ¸ 5. Regularization of linear regression In order to preventing overfitting of the model, we often add regularization terms when building the linear model. There are generally L1 regularization and L2 regularization. 5.1 L1 regularization L1 regularization of linear regression is usually called Lasso Regression. The difference between it and general linear regression is that an L1 regularization term is added to the loss function. The L1 regularized term has a constant coefficient Î±\\alphaÎ± to adjust the weight of mean square error term and the regularized term of the loss function: J(Î¸)=12(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)+Î±âˆ£âˆ£Î¸âˆ£âˆ£1J(\\theta) = \\frac{1}{2}(X\\theta-Y)^T(X\\theta-Y) + \\alpha||\\theta||_1 J(Î¸)=21â€‹(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)+Î±âˆ£âˆ£Î¸âˆ£âˆ£1â€‹ Î±\\alphaÎ± is a constant coefficient and needs to be tuned. âˆ£âˆ£Î¸âˆ£âˆ£1||\\theta||_1âˆ£âˆ£Î¸âˆ£âˆ£1â€‹ is the L1 norm. Lasso regression can make the coefficients of some features smaller, or even some coefficients with smaller absolute values directly become 0. Enhance the generalization ability of the model. The solution methods of Lasso regression are generally: Coordinate Descent Least Angle Regression Please check Regularization of Regression-Summary of Lasso Regression 5.2 L2 regularization L2 regularization of linear regression is usually called Ridge Regression. It adds an L2 regularization term to the loss function: J(Î¸)=12(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)+12Î±âˆ£âˆ£Î¸âˆ£âˆ£22J(\\theta) = \\frac{1}{2}(X\\theta-Y)^T(X\\theta-Y) + \\frac{1}{2}\\alpha||\\theta||_2^2 J(Î¸)=21â€‹(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)+21â€‹Î±âˆ£âˆ£Î¸âˆ£âˆ£22â€‹ Î±\\alphaÎ± is a constant coefficient and needs to be tuned. âˆ£âˆ£Î¸âˆ£âˆ£2||\\theta||_2âˆ£âˆ£Î¸âˆ£âˆ£2â€‹ is the L2 norm. (not equal to L1 norm) Ridge regression reduces the regression coefficient without abandoning any feature, making the model relatively stable, but compared with Lasso regression, this will leave the model with a lot of features and poor interpretability. The solution of Ridge regression is relatively simple, and the least square method is generally used. Here is a matrix derivation form using least squares, which is similar to ordinary linear regression. Let the derivative of J(Î¸)J(\\theta)J(Î¸) be 0 and get the following formula: XT(XÎ¸âˆ’Y)+Î±Î¸=0X^T(X\\theta - Y) + \\alpha\\theta = 0 XT(XÎ¸âˆ’Y)+Î±Î¸=0 Then: Î¸=(XTX+Î±E)âˆ’1XTY\\theta = (X^TX + \\alpha E)^{-1} X^TY Î¸=(XTX+Î±E)âˆ’1XTY E is the Identity matrix ","link":"https://zl-wu.github.io/post/mla-linear-regression-principle/"},{"title":"MLA -- Least Square method","content":"&quot;A standard approach in regression analysis to approximate the solution of overdetermined systems.&quot; The method of least squares is a standard approach in regression analysis to approximate the solution of overdetermined systems (sets of equations in which there are more equations than unknowns) by minimizing the sum of the squares of the residuals made in the results of every single equation. It is used to do model fitting and find the extreme value of the loss function. 1. Least Square principle The general form of least squares is simple: f=âˆ‘(yâˆ’y^)2f = \\sum (y - \\widehat{y})^2 f=âˆ‘(yâˆ’yâ€‹)2 f is the objective function y is the observation value (actual value) y^\\widehat{y}yâ€‹ is the theoretical value predicted from the model The objective function is also the loss function commonly used in the machine learning. Our goal is to get a fitting model when the objective function is minimized. Give a simple example of the simplest linear regression, we have m samples with only one feature: (x1,y1)(x2,y2),...,(xm,ym)(x_1,y_1)(x_2,y_2),...,(x_m,y_m)(x1â€‹,y1â€‹)(x2â€‹,y2â€‹),...,(xmâ€‹,ymâ€‹) Hypothesis model is: hÎ¸(x)=Î¸0+Î¸1xh_\\theta(x) = \\theta_0 + \\theta_1x hÎ¸â€‹(x)=Î¸0â€‹+Î¸1â€‹x Loss function is: J(Î¸0,Î¸1)=âˆ‘i=1m(yiâˆ’hÎ¸(xi))2=âˆ‘i=1m(yiâˆ’Î¸0âˆ’Î¸1xi)2\\begin{aligned} J(\\theta_0,\\theta_1) &amp;= \\sum_{i=1}^{m}(y_i - h_\\theta(x_i))^2 \\\\ &amp;= \\sum_{i=1}^{m}(y_i - \\theta_0 - \\theta_1x_i)^2 \\end{aligned} J(Î¸0â€‹,Î¸1â€‹)â€‹=i=1âˆ‘mâ€‹(yiâ€‹âˆ’hÎ¸â€‹(xiâ€‹))2=i=1âˆ‘mâ€‹(yiâ€‹âˆ’Î¸0â€‹âˆ’Î¸1â€‹xiâ€‹)2â€‹ Least Square method needs to get (Î¸0,Î¸1)(\\theta_0,\\theta_1)(Î¸0â€‹,Î¸1â€‹) that minimizes the value of J(Î¸0,Î¸1)J(\\theta_0,\\theta_1)J(Î¸0â€‹,Î¸1â€‹) 2. Least Squre solution 2.1 Algebraic way If we need to minimumize J(Î¸0,Î¸1)J(\\theta_0,\\theta_1)J(Î¸0â€‹,Î¸1â€‹), our method is to calculate the partial derivatives of Î¸0\\theta_0Î¸0â€‹ and Î¸1\\theta_1Î¸1â€‹ respectively, and make their partial derivatives all 0 to form a linear equation set for two variables. Partial derivation of J(Î¸0,Î¸1)J(\\theta_0,\\theta_1)J(Î¸0â€‹,Î¸1â€‹) to Î¸0\\theta_0Î¸0â€‹: âˆ’2âˆ‘i=1m(yiâˆ’Î¸0âˆ’Î¸1xi)=0-2\\sum_{i=1}^{m}(y_i-\\theta_0-\\theta_1x_i) = 0 âˆ’2i=1âˆ‘mâ€‹(yiâ€‹âˆ’Î¸0â€‹âˆ’Î¸1â€‹xiâ€‹)=0 Partial derivation of J(Î¸0,Î¸1)J(\\theta_0,\\theta_1)J(Î¸0â€‹,Î¸1â€‹) to Î¸1\\theta_1Î¸1â€‹: âˆ’2âˆ‘i=1m(yiâˆ’Î¸0âˆ’Î¸1xi)xi=0-2\\sum_{i=1}^{m}(y_i-\\theta_0-\\theta_1x_i)x_i = 0 âˆ’2i=1âˆ‘mâ€‹(yiâ€‹âˆ’Î¸0â€‹âˆ’Î¸1â€‹xiâ€‹)xiâ€‹=0 Now: {âˆ‘i=1m(yiâˆ’Î¸0âˆ’Î¸1xi)=0âˆ‘i=1m(yiâˆ’Î¸0âˆ’Î¸1xi)xi=0\\begin{cases} \\sum_{i=1}^{m}(y_i-\\theta_0-\\theta_1x_i) = 0\\\\ \\sum_{i=1}^{m}(y_i-\\theta_0-\\theta_1x_i)x_i = 0\\\\ \\end{cases} {âˆ‘i=1mâ€‹(yiâ€‹âˆ’Î¸0â€‹âˆ’Î¸1â€‹xiâ€‹)=0âˆ‘i=1mâ€‹(yiâ€‹âˆ’Î¸0â€‹âˆ’Î¸1â€‹xiâ€‹)xiâ€‹=0â€‹ ={âˆ‘i=1myiâˆ’mÎ¸0âˆ’Î¸1âˆ‘i=1mxi=0âˆ‘i=1myixiâˆ’Î¸0âˆ‘i=1mxiâˆ’Î¸1âˆ‘i=1mxi2=0=\\begin{cases} \\sum_{i=1}^{m}y_i - m\\theta_0-\\theta_1\\sum_{i=1}^{m}x_i = 0\\\\ \\sum_{i=1}^{m}y_ix_i -\\theta_0\\sum_{i=1}^{m}x_i-\\theta_1\\sum_{i=1}^{m}x_i^2 = 0\\\\ \\end{cases} ={âˆ‘i=1mâ€‹yiâ€‹âˆ’mÎ¸0â€‹âˆ’Î¸1â€‹âˆ‘i=1mâ€‹xiâ€‹=0âˆ‘i=1mâ€‹yiâ€‹xiâ€‹âˆ’Î¸0â€‹âˆ‘i=1mâ€‹xiâ€‹âˆ’Î¸1â€‹âˆ‘i=1mâ€‹xi2â€‹=0â€‹ Then: Î¸0=âˆ‘xi2Ã—âˆ‘yiâˆ’âˆ‘xiÃ—âˆ‘xiyimâˆ‘xi2âˆ’(âˆ‘xi)2 \\theta_0 = \\frac {\\sum x_i^2 \\times \\sum y_i - \\sum x_i \\times \\sum x_iy_i} {m\\sum x_i^2-(\\sum x_i)^2} Î¸0â€‹=mâˆ‘xi2â€‹âˆ’(âˆ‘xiâ€‹)2âˆ‘xi2â€‹Ã—âˆ‘yiâ€‹âˆ’âˆ‘xiâ€‹Ã—âˆ‘xiâ€‹yiâ€‹â€‹ Î¸1=mâˆ‘xiyiâˆ’âˆ‘xiÃ—âˆ‘yimâˆ‘xi2âˆ’(âˆ‘xi)2 \\theta_1 = \\frac { m\\sum x_iy_i - \\sum x_i \\times \\sum y_i} {m\\sum x_i^2-(\\sum x_i)^2} Î¸1â€‹=mâˆ‘xi2â€‹âˆ’(âˆ‘xiâ€‹)2mâˆ‘xiâ€‹yiâ€‹âˆ’âˆ‘xiâ€‹Ã—âˆ‘yiâ€‹â€‹ If the sample has more than 1 features, which is Multiple Linear Regression. We still use the rule that partial derivatives equal to 0 to form parametric equation set, then calculate these unknown parameters. The principle remains the same. 2.2 Matrix way The matrix expression is more concise than the algebra expression, and it can also replace loops (In essence, the nature of computing has not changed). So many books and machine learning libraries now use the matrix method to do the least square. Here we use the above multiple linear regression example to describe the matrix method solution. hÎ¸(x1,x2,...,xn)=Î¸0+Î¸1x1+...+Î¸nxnh_\\theta(x_1,x_2,...,x_n)=\\theta_0+\\theta_1x_1+...+\\theta_nx_nhÎ¸â€‹(x1â€‹,x2â€‹,...,xnâ€‹)=Î¸0â€‹+Î¸1â€‹x1â€‹+...+Î¸nâ€‹xnâ€‹. If in matrix expression: hÎ¸(X)=XÎ¸h_\\theta(X) = X\\theta hÎ¸â€‹(X)=XÎ¸ X is a mÃ—nm \\times nmÃ—n matrix (m records and n features). Î¸\\thetaÎ¸ is a nÃ—1n \\times 1nÃ—1 vector (n coefficients of n features). hÎ¸(X)h_\\theta(X)hÎ¸â€‹(X) is a mÃ—1m\\times 1mÃ—1 vector (m prediction y value of m sample records) The loss function is: J(Î¸)=12(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)J(\\theta) = \\frac{1}{2}(X\\theta-Y)^T(X\\theta-Y) J(Î¸)=21â€‹(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y) Y is a mÃ—1m\\times 1mÃ—1 vector (m actual y value of m sample records) 1/2 is mainly to facilitate the calculation of later derivatives. Let the derivative to be 0: âˆ‚âˆ‚Î¸J(Î¸)=XT(XÎ¸âˆ’Y)=0\\frac{\\partial}{\\partial\\theta}J(\\theta) = X^T(X\\theta-Y) = 0 âˆ‚Î¸âˆ‚â€‹J(Î¸)=XT(XÎ¸âˆ’Y)=0 It based on two Matrix derivative chain rule formula: Formula 1: âˆ‚âˆ‚X(XTX)=2X\\frac{\\partial}{\\partial X}(X^TX) = 2Xâˆ‚Xâˆ‚â€‹(XTX)=2X Formula 2: $ \\nabla_xf(AX+B) = A^T $ Then: XTXÎ¸=XTYÎ¸=(XTX)âˆ’1XTY\\begin{array}{cc} X^TX\\theta = X^TY\\\\\\\\ \\theta = (X^TX)^{-1}X^TY \\end{array} XTXÎ¸=XTYÎ¸=(XTX)âˆ’1XTYâ€‹ (XTX)âˆ’1XTY(X^TX)^{-1}X^TY(XTX)âˆ’1XTY is our answer. 3. Limitations and applicable scenarios of least square method Least Square answer is simple and efficient, it has no iterations camparing with gradient descent. But it still has some limitations when we use it: Least Square needs to calculate the inverse matrix of XTXX^TXXTX, however, it is possible that inverse matrix does not exist. In this case, there is no way to use Least Square directly, but Gradient Descent. Or, we can also try to remove redundant features by clean the sample data. Let the determinant of XTXX^TXXTX not be 0, and then continue to use least squares. When the features n of sample is very large, the calculating the inverse matrix of XTXX^TXXTX is a very time-consuming work, even not feasible. In this case, it's better to use Gradient Descent. (If n &gt; 1000, suggest not use Least Square). Or, we can also use Principal Component Analysis (PCA) to reduce the dimension of features and then use the least square method. If the fitting function (objective model) is not linear, Least Square cannot be used. But Gradient Descent can still be used. Or, we can convert the fitting function to linearity through some techniques before Least Square can be used. There are some special situation: When the sample size m is small and less than the feature number n, then the fitting equation is underdetermined, and the commonly used optimization methods cannot fit the data. When the sample size m is equal to the feature number n, it can be solved by the equation system. When the sample size m is greater than n, the fitting equation is overdetermined, which is the scenario where we usually use least squares. ","link":"https://zl-wu.github.io/post/mla-least-square-method/"},{"title":"MLA -- Gradient Descent method","content":"When improving the model parameters of machine learning algorithms, that is, unconstrained optimalization problem. Gradient Descent method is one of most common used methods. The other one is the least square method. Here is a complete summary of the gradient descent method. 1. What is gradient? In calculus, Gradient is to find the partial derivatives of the parameters of the multivariate function, and write all partial derivative of the obtained parameters in the form of one vector. For the function f(x, y) as an example, finding the partial derivatives of x and y, then the gradient vector is $ (\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y})^T $, AKA grad f(x, y) or $ \\nabla f(x,y)$ The specific gradient vector value at point (x0, y0) is $ (\\frac{\\partial f}{\\partial x_0}, \\frac{\\partial f}{\\partial y_0})^T $ or $ \\nabla f(x_0,y_0)$ If there are three parameters, then gradient vector is $ (\\frac{\\partial f}{\\partial x}, \\frac{\\partial f}{\\partial y}, \\frac{\\partial f}{\\partial z})^T $, and so on. In geometrically speaking, the meaning of gradient is the direction where the function f(x,y) changes fastest. At point (x0, y0), the direction of gradient vector $(\\frac{\\partial f}{\\partial x_0}, \\frac{\\partial f}{\\partial y_0})^T $ is where f(x,y) changes fastest. If we keep following the gradient vector direction, we will reach the maximum or minimum point of function faster and easier. 2. Gradient Descent Assume we are somewhere on a large mountain, because we donâ€™t know how to go down the mountain, so we decided to take one step at a time. That is, we can take a step down from the current position's steepest direction, and then continue to calculate the gradient of the new position and take a step toward the position where the step is located at the steepest and easiest to descend. Going on like this step by step until we feel that we have reached the foot of the mountain. Of course, if we go on like this, we may not be able to reach the foot of the mountain, but to a certain foot in a local part of the mountain. As can be seen from the above explanation, gradient descent may not necessarily find the global optimal solution, but may be a local optimal solution. Of course, if the loss function is convex, the solution obtained by the gradient descent method must be the global optimal solution. 3. Concepts of gradient descent Learining Rate: The step size determines the length of each step in the negative direction of the gradient during the gradient descent iteration. Feature: Refers to the input part of the sample data. (x0(1),x1(1),...,xn(1),y1)(x_0^{(1)},x_1^{(1)},...,x_n^{(1)},y_1)(x0(1)â€‹,x1(1)â€‹,...,xn(1)â€‹,y1â€‹) Hypothesis Function: In supervised learning, the hypothesis function used to fit the input samples, denoted as hÎ¸(X)h_\\theta(X)hÎ¸â€‹(X). For example, the linear regression hypothesis model is hÎ¸(x1,x2,...,xn)=Î¸0+Î¸1x1+Î¸2x2+...+Î¸nxnh_\\theta(x_1,x_2,...,x_n) = \\theta_0+\\theta_1x_1+\\theta_2x_2+...+\\theta_nx_nhÎ¸â€‹(x1â€‹,x2â€‹,...,xnâ€‹)=Î¸0â€‹+Î¸1â€‹x1â€‹+Î¸2â€‹x2â€‹+...+Î¸nâ€‹xnâ€‹ Loss Function: In order to evaluate how well the model fits the data, a loss function is usually used to measure the degree of fit. The minimization of the loss function means that the degree of fitting is the best and the corresponding model parameters are the optimal parameters. In linear regression model, the loss function usually squares the difference between the sample output (yi) and the hypothesis function output (y hat). If there is a linear regression model for m samples: (x1i,x2i,...,xni,yi),i=(1,2,...,m)(x_1^{i},x_2^{i},...,x_n^{i},y_i),i=(1,2,...,m)(x1iâ€‹,x2iâ€‹,...,xniâ€‹,yiâ€‹),i=(1,2,...,m), the loss function is: J(Î¸0,Î¸1,...,Î¸n)=âˆ‘i=1m(hÎ¸(x1(i),x2(i),...,xn(i))âˆ’yi)2J(\\theta_0,\\theta_1,...,\\theta_n) = \\sum_{i=1}^m(h_\\theta(x_1^{(i)},x_2^{(i)},...,x_n^{(i)})-y_i)^2 J(Î¸0â€‹,Î¸1â€‹,...,Î¸nâ€‹)=i=1âˆ‘mâ€‹(hÎ¸â€‹(x1(i)â€‹,x2(i)â€‹,...,xn(i)â€‹)âˆ’yiâ€‹)2 x(i)x^{(i)}x(i) is the feature of the i-th sample data. yiy_iyiâ€‹ is the output of the i-th sample data. hÎ¸(x1(i),x2(i),...,xn(i))h_\\theta(x_1^{(i)},x_2^{(i)},...,x_n^{(i)})hÎ¸â€‹(x1(i)â€‹,x2(i)â€‹,...,xn(i)â€‹) is the Hypothesis Function. (== y^\\widehat{y}yâ€‹) 4. Gradient Descent Algorithm The algorithm of gradient descent method can have two expressions: algebraic method and matrix method (also called vector method). 4.1 Algebraic Expression 1. Prerequite: Set Hypothesis Function and Loss Function of the optimization model. Assume Hypothesis Function is the linear regression model. Then the loss function is: J(Î¸0,Î¸1,...,Î¸n)=12mâˆ‘i=1m(hÎ¸(x1(i),x2(i),...,xn(i))âˆ’yi)2J(\\theta_0,\\theta_1,...,\\theta_n) = \\frac{1}{2m}\\sum_{i=1}^m(h_\\theta(x_1^{(i)},x_2^{(i)},...,x_n^{(i)})-y_i)^2 J(Î¸0â€‹,Î¸1â€‹,...,Î¸nâ€‹)=2m1â€‹i=1âˆ‘mâ€‹(hÎ¸â€‹(x1(i)â€‹,x2(i)â€‹,...,xn(i)â€‹)âˆ’yiâ€‹)2 1/2m is a new factor we added. 1/m means average. 1/2 is mainly to facilitate the calculation of later partial derivatives. We know that m is a constant greater than zero, so it has no effect on the nature of the function gradient. It does not change the Î¸\\thetaÎ¸ when we get the minimum value of J(Î¸)J(\\theta)J(Î¸). After all, what we need is only the Î¸\\thetaÎ¸, not the minimum value of J(Î¸)J(\\theta)J(Î¸). 2. Initialize some algorithm parameters: Initialize all (Î¸0,Î¸1,...,Î¸n)(\\theta_0,\\theta_1,...,\\theta_n)(Î¸0â€‹,Î¸1â€‹,...,Î¸nâ€‹). Learning Rate Î±\\alphaÎ±. (Step Size) Algorithm termination distance Îµ\\varepsilonÎµ. If the distance of gradient descent is less than Îµ\\varepsilonÎµ, algorithm stoppes. For example, in the absence of any prior knowledge, we can simply intialize all Î¸\\thetaÎ¸ to 0 and Î±\\alphaÎ± to 1. Then Optimize them again when tuning is needed. 3. Algorithm Process: Step 1: Calculate the gradient of current position. For Î¸j\\theta_jÎ¸jâ€‹, its gradient expression is:âˆ‚âˆ‚Î¸jJ(Î¸0,Î¸1,...,Î¸n)\\frac{\\partial}{\\partial\\theta_j} J(\\theta_0,\\theta_1,...,\\theta_n) âˆ‚Î¸jâ€‹âˆ‚â€‹J(Î¸0â€‹,Î¸1â€‹,...,Î¸nâ€‹) j is (0,1,2,...,n), represents the j-th parameter. Step 2: Multiply Gradient by Learning Rate Î±\\alphaÎ± (step size) to get the distance of gradient descent at current position. That is, Î±âˆ‚âˆ‚Î¸jJ(Î¸0,Î¸1,...,Î¸n)\\alpha\\frac{\\partial}{\\partial\\theta_j} J(\\theta_0,\\theta_1,...,\\theta_n)Î±âˆ‚Î¸jâ€‹âˆ‚â€‹J(Î¸0â€‹,Î¸1â€‹,...,Î¸nâ€‹) Step 3: If all Î¸j\\theta_jÎ¸jâ€‹'s distance of gradient descent is less than Îµ\\varepsilonÎµ, algorithm stopped. And current (Î¸0,Î¸1,...,Î¸n)(\\theta_0,\\theta_1,...,\\theta_n)(Î¸0â€‹,Î¸1â€‹,...,Î¸nâ€‹) is returned as the final result. Step 4: Update all Î¸j\\theta_jÎ¸jâ€‹ and jump to Step 1 for a new loop. The update expression is as follows: Î¸j=Î¸jâˆ’Î±âˆ‚âˆ‚Î¸jJ(Î¸0,Î¸1,...,Î¸n)\\theta_j = \\theta_j - \\alpha\\frac{\\partial}{\\partial\\theta_j} J(\\theta_0,\\theta_1,...,\\theta_n) Î¸jâ€‹=Î¸jâ€‹âˆ’Î±âˆ‚Î¸jâ€‹âˆ‚â€‹J(Î¸0â€‹,Î¸1â€‹,...,Î¸nâ€‹) The algorithm is very simple and elegant, the key point is how to calculate âˆ‚âˆ‚Î¸jJ(Î¸0,Î¸1,...,Î¸n)\\frac{\\partial}{\\partial\\theta_j} J(\\theta_0,\\theta_1,...,\\theta_n)âˆ‚Î¸jâ€‹âˆ‚â€‹J(Î¸0â€‹,Î¸1â€‹,...,Î¸nâ€‹): J(Î¸0,Î¸1,...,Î¸n)=12mâˆ‘i=1m(hÎ¸(x1(i),x2(i),...,xn(i))âˆ’yi)2J(\\theta_0,\\theta_1,...,\\theta_n) = \\frac{1}{2m}\\sum_{i=1}^m(h_\\theta(x_1^{(i)},x_2^{(i)},...,x_n^{(i)})-y_i)^2 J(Î¸0â€‹,Î¸1â€‹,...,Î¸nâ€‹)=2m1â€‹i=1âˆ‘mâ€‹(hÎ¸â€‹(x1(i)â€‹,x2(i)â€‹,...,xn(i)â€‹)âˆ’yiâ€‹)2 âˆ‚âˆ‚Î¸jJ(Î¸0,Î¸1,...,Î¸n)=1mâˆ‘i=1m(hÎ¸(x1(i),x2(i),...,xn(i))âˆ’yi)xj(i)\\frac{\\partial}{\\partial\\theta_j} J(\\theta_0,\\theta_1,...,\\theta_n) = \\frac{1}{m}\\sum_{i=1}^m(h_\\theta(x_1^{(i)},x_2^{(i)},...,x_n^{(i)})-y_i)x_j^{(i)} âˆ‚Î¸jâ€‹âˆ‚â€‹J(Î¸0â€‹,Î¸1â€‹,...,Î¸nâ€‹)=m1â€‹i=1âˆ‘mâ€‹(hÎ¸â€‹(x1(i)â€‹,x2(i)â€‹,...,xn(i)â€‹)âˆ’yiâ€‹)xj(i)â€‹ Î¸j=Î¸jâˆ’Î±âˆ‘i=1m(hÎ¸(x1(i),x2(i),...,xn(i))âˆ’yi)xj(i)\\theta_j = \\theta_j - \\alpha\\sum_{i=1}^m(h_\\theta(x_1^{(i)},x_2^{(i)},...,x_n^{(i)})-y_i)x_j^{(i)} Î¸jâ€‹=Î¸jâ€‹âˆ’Î±i=1âˆ‘mâ€‹(hÎ¸â€‹(x1(i)â€‹,x2(i)â€‹,...,xn(i)â€‹)âˆ’yiâ€‹)xj(i)â€‹ 4.2 Matrix Expression Algebraic Expression and Matrix Expression are essentially the same, but the representation of Matrix will be more concise. Suppose we have m sample data: (x1(1),x2(1),...,xn(1),y1),(x1(2),x2(2),...,xn(2),y2),...,(x1(m),x2(m),...,xn(m),ym)(x_1^{(1)},x_2^{(1)},...,x_n^{(1)},y_1),(x_1^{(2)},x_2^{(2)},...,x_n^{(2)},y_2),...,(x_1^{(m)},x_2^{(m)},...,x_n^{(m)},y_m)(x1(1)â€‹,x2(1)â€‹,...,xn(1)â€‹,y1â€‹),(x1(2)â€‹,x2(2)â€‹,...,xn(2)â€‹,y2â€‹),...,(x1(m)â€‹,x2(m)â€‹,...,xn(m)â€‹,ymâ€‹) 1. Prerequite: Set Hypothesis Function and Loss Function of the optimization model. Assume Hypothesis Function is the linear regression model: hÎ¸(X)=XÎ¸h_\\theta(X) = X\\theta hÎ¸â€‹(X)=XÎ¸ J(Î¸)=12(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y)J(\\theta) = \\frac{1}{2}(X\\theta-Y)^T(X\\theta-Y) J(Î¸)=21â€‹(XÎ¸âˆ’Y)T(XÎ¸âˆ’Y) X is a mÃ—nm \\times nmÃ—n matrix (m records and n features). Î¸\\thetaÎ¸ is a nÃ—1n \\times 1nÃ—1 vector (n coefficients of n features). hÎ¸(X)h_\\theta(X)hÎ¸â€‹(X) is a mÃ—1m\\times 1mÃ—1 vector (m prediction y value of m sample records) Y is a mÃ—1m\\times 1mÃ—1 vector (m actual y value of m sample records) 2. Initialize some algorithm parameters: Same as 4.1 section. 3. Algorithm Process: Same as 4.1 section. âˆ‚âˆ‚Î¸J(Î¸)=XT(XÎ¸âˆ’Y)\\frac{\\partial}{\\partial\\theta}J(\\theta) = X^T(X\\theta-Y) âˆ‚Î¸âˆ‚â€‹J(Î¸)=XT(XÎ¸âˆ’Y) Î¸=Î¸âˆ’Î±âˆ‚âˆ‚Î¸J(Î¸)=Î¸âˆ’Î±XT(XÎ¸âˆ’Y)\\begin{aligned} \\theta &amp;= \\theta - \\alpha\\frac{\\partial}{\\partial\\theta}J(\\theta)\\\\ &amp;= \\theta - \\alpha X^T(X\\theta-Y) \\end{aligned} Î¸â€‹=Î¸âˆ’Î±âˆ‚Î¸âˆ‚â€‹J(Î¸)=Î¸âˆ’Î±XT(XÎ¸âˆ’Y)â€‹ Matrix derivative chain rule: Formula 1: âˆ‚âˆ‚X(XTX)=2X\\frac{\\partial}{\\partial X}(X^TX) = 2Xâˆ‚Xâˆ‚â€‹(XTX)=2X Formula 2: $ \\nabla_xf(AX+B) = A^T $ 5. Tuning of gradient descent algorithm Learning Rate: If the step size is too large, the iteration will be too fast, and it may even miss the optimal solution. The step size is too small, the iteration speed is too slow, and the algorithm cannot end for a long time. So the step size of the algorithm needs to be run multiple times to get a better value. Î¸\\thetaÎ¸ initialization: different intial parameter value may lead to different minimum value. Hence, the gradient descent only finds the local minimum. if the loss function is a convex function, it must be the global optimal solution. It is necessary to run the algorithm with different initial values multiple times, which can increase the possibility that we skip the local minimum to reach the global minimum. Normalized: The data range of different features is different, if some features' data value are very high, and some others' are very low, it may lead to a very slow iteration. In order to reduce the influence of the feature value, the feature data can be normalized. For each xj feature's data, we transform it to:xj=xjâˆ’xjâ€¾std(xj)x_j = \\frac{x_j - \\overline{x_j}}{std(x_j)} xjâ€‹=std(xjâ€‹)xjâ€‹âˆ’xjâ€‹â€‹â€‹ xjx_jxjâ€‹ becomes a new feature with new expectation 0 and new variance 1, the iteration speed can be greatly accelerated. 6. Gradient Descent Family (BGD, SGD, MBGD) 6.1 BGD (Batch Gradient Descent) Batch Gradient Descent is the most commonly used form. It always uses all m sample data when we update parameter Î¸\\thetaÎ¸ once. As discuss above: Î¸j=Î¸jâˆ’Î±âˆ‘i=1m(hÎ¸(x1(i),x2(i),...,xn(i))âˆ’yi)xj(i)\\theta_j = \\theta_j - \\alpha\\sum_{i=1}^m(h_\\theta(x_1^{(i)},x_2^{(i)},...,x_n^{(i)})-y_i)x_j^{(i)} Î¸jâ€‹=Î¸jâ€‹âˆ’Î±i=1âˆ‘mâ€‹(hÎ¸â€‹(x1(i)â€‹,x2(i)â€‹,...,xn(i)â€‹)âˆ’yiâ€‹)xj(i)â€‹ For each iteration of one of Î¸\\thetaÎ¸, we use all m samples to caculate gradient. 6.2 SGD (Stochastic Gradient Descent) Stochastic Gradient Descent is similar to the BGD, the difference is that SGD use only one random sample to calculate gradient: Î¸j=Î¸jâˆ’Î±(hÎ¸(x1(i),x2(i),...,xn(i))âˆ’yi)xj(i)\\theta_j = \\theta_j - \\alpha(h_\\theta(x_1^{(i)},x_2^{(i)},...,x_n^{(i)})-y_i)x_j^{(i)} Î¸jâ€‹=Î¸jâ€‹âˆ’Î±(hÎ¸â€‹(x1(i)â€‹,x2(i)â€‹,...,xn(i)â€‹)âˆ’yiâ€‹)xj(i)â€‹ BGD and SGD are two extremes. One uses all data for gradient descent, and one uses only one sample data for gradient descent. Advantages and disadvantages are very prominent. Traning Speed: SGD is very fast, since it uses only one sample to iterate each time. While the BGD cannot satisfy the training speed when the sample size is large. Accuracy: SGD uses only one sample, most likely resulting in a not optimal solution. convergence Speed: SGD uses one sample at a interation, the iteration direction changes greatly, and it cannot quickly converge to the local optimal solution. Is there a moderate method to neutralize the advantages and disadvantages of BGD and SGD? Yes, MBGD 6.3 MBGD (Mini-batch Gradient Descent) The Mini-batch Gradient Descent is a compromise between the BGD and the SGD, that is, for all m samples, we use k samples to iterate, 0&lt;k&lt;m0&lt;k&lt;m0&lt;k&lt;m. Of course, the value of k can be adjusted according to the sample data. The iteration formula is: Î¸j=Î¸jâˆ’Î±âˆ‘i=tt+kâˆ’1(hÎ¸(x1(i),x2(i),...,xn(i))âˆ’yi)xj(i)\\theta_j = \\theta_j - \\alpha\\sum_{i=t}^{t+k-1}(h_\\theta(x_1^{(i)},x_2^{(i)},...,x_n^{(i)})-y_i)x_j^{(i)} Î¸jâ€‹=Î¸jâ€‹âˆ’Î±i=tâˆ‘t+kâˆ’1â€‹(hÎ¸â€‹(x1(i)â€‹,x2(i)â€‹,...,xn(i)â€‹)âˆ’yiâ€‹)xj(i)â€‹ 7. Comparison of gradient descent method and other optimization algorithms In machine learning, there are generally these optimization algorithms: Gradient Descent Least Square Newton's method and Quasi-Newton's method Gradient Descent and Lease Square: Gradient Descent needs step size, Lease Square doesn't. Gradient Descent is an iterative solution, and the Least Square is an analytical solution. If the sample size is not very large, and there is an analytical solution, the Least Square has an advantage over the Gradient Descent, and the LS calculation speed is fast. However, if the sample size is large, Least Square requires a super large inverse matrix, which is difficult or slow to solve the analytical solution. Then iterative Gradient Descent is better. Gradient Descent and Newton's method/Quasi-Newton's method: Both of them are iterative solution. Gradient Descent is gradient solution. Newton's method is solved by using the inverse or pseudo-inverse matrix of the second-order Hessian matrix. Newton method / Quasi-Newton's method converges faster. But each iteration takes longer than gradient descent Python implementation Example f(x)=x2+1f(x)=x^2+1f(x)=x2+1 &quot;&quot;&quot; One Dimensional Gradient Descent Example -- One feature &quot;&quot;&quot; def func_1d(x): &quot;&quot;&quot; Objective Function :param x: independent variable, scalar :return: dependent variable, scalar &quot;&quot;&quot; return x ** 2 + 1 def grad_1d(x): &quot;&quot;&quot; Gradient of Objective Function :param x: independent variable, scalar :return: dependent variable, scalar &quot;&quot;&quot; return x * 2 def gradient_descent_1d(grad, cur_x=0.1, learning_rate=0.01, precision=0.0001, max_iters=10000): &quot;&quot;&quot; One-dimensional gradient descent algorithm :param grad: Gradient Fuction of Objective Function :param cur_x: Current x value :param learning_rate: step size :param precision: Set convergence accuracy (stop condition) :param max_iters: max number of iterations :return: local minumum x* &quot;&quot;&quot; for i in range(max_iters): grad_cur = grad(cur_x) if abs(grad_cur) &lt; precision: # when the gradient approaches 0, it is regarded as convergence break cur_x = cur_x - grad_cur * learning_rate print(&quot;The&quot;, i, &quot;-th iteration's x value: &quot;, cur_x) print(&quot;Local Minumum x =&quot;, cur_x) return cur_x if __name__ == '__main__': gradient_descent_1d(grad_1d, cur_x=10, learning_rate=0.2, precision=0.000001, max_iters=10000) f(x,y)=âˆ’eâˆ’(x2+y2)f(x,y) = -e^{-(x^2+y^2)}f(x,y)=âˆ’eâˆ’(x2+y2) &quot;&quot;&quot; 2-Dimensional Gradient Descent example -- 2 features &quot;&quot;&quot; import math import numpy as np def func_2d(x): &quot;&quot;&quot; Objective Function :param x: independent variable, 2d vector :return: dependent variable, scalar &quot;&quot;&quot; return - math.exp(-(x[0] ** 2 + x[1] ** 2)) def grad_2d(x): &quot;&quot;&quot; Gradient of the Objective Function :param x: independent variable, 2d vector :return: dependent variable, 2d vector &quot;&quot;&quot; deriv0 = 2 * x[0] * math.exp(-(x[0] ** 2 + x[1] ** 2)) deriv1 = 2 * x[1] * math.exp(-(x[0] ** 2 + x[1] ** 2)) return np.array([deriv0, deriv1]) def gradient_descent_2d(grad, cur_x=np.array([0.1, 0.1]), learning_rate=0.01, precision=0.0001, max_iters=10000): &quot;&quot;&quot; 2D gradient descent algorithm :param grad: Gradient Fuction of Objective Function :param cur_x: Current x value (Parameter Initialization) :param learning_rate: step size :param precision: Set convergence accuracy (stop condition) :param max_iters: max number of iterations :return: Local minimum x* &quot;&quot;&quot; print(f&quot;{cur_x} as the Initialization...&quot;) for i in range(max_iters): grad_cur = grad(cur_x) if np.linalg.norm(grad_cur, ord=2) &lt; precision: # when the gradient approaches 0, it is regarded as convergence break cur_x = cur_x - grad_cur * learning_rate print(&quot;The&quot;, i, &quot;-th iteration's x value: &quot;, cur_x) print(&quot;Local minimum x =&quot;, cur_x) return cur_x if __name__ == '__main__': gradient_descent_2d(grad_2d, cur_x=np.array([1, -1]), learning_rate=0.2, precision=0.000001, max_iters=10000) f(x1,x2,x3)=3x1+4x2+5x3+6f(x_1,x_2,x_3) = 3x_1+4x_2+5x_3+6f(x1â€‹,x2â€‹,x3â€‹)=3x1â€‹+4x2â€‹+5x3â€‹+6 &quot;&quot;&quot; Parameter Estimation Multiple linear regression gradient descent example (Matrix Method) Dataset(4 points on the function): x1, x2, x3, b, y 1, 1, 2, 1, 23 2, 4, 3, 1, 43 3, 2, 4, 1, 43 4, 3, 1, 1, 35 &quot;&quot;&quot; import numpy as np def gradient_descent(theta, X, Y, lr=0.01, precision=0.0001, max_iters=10000): &quot;&quot;&quot; matrix gradient descent algorithm :param theta: parameter estimation of the objective function :param X: sample data, independent data, mxn matrix :param Y: sample data, dependent data, mx1 matrix :param lr: step size :param precision: Set convergence accuracy (stop condition) :param max_iters: max number of iterations :return: Local minimum theta* &quot;&quot;&quot; print(f&quot;{theta} as the Initialization...&quot;) for i in range(max_iters): distance = lr*X.T*(X*theta-Y) if np.linalg.norm(distance, ord=2) &lt; precision: # when the gradient approaches 0, it is regarded as convergence print(&quot;total iterations:&quot;, i) break theta = theta-distance print(&quot;Local minimum theta =\\n&quot;, theta) return theta x = np.mat([[1,1,2,1],[2,4,3,1],[3,2,4,1],[4,3,1,1]]) y = np.mat([[23],[43],[43],[35]]) theta = np.mat([[0],[0],[0],[0]]) gradient_descent(theta, x, y) ##### [[0] [0] [0] [0]] as the Initialization... total iterations: 1852 Local minimum theta = [[3.00521152] [4.00294095] [5.00623515] [5.96159285]] &quot;&quot;&quot; Additional code -- np.linalg.norm linalg = linear algebra &quot;&quot;&quot; x_norm=np.linalg.norm(x, ord=None, axis=None, keepdims=False) import numpy as np x = np.array([ [0, 3, 4], [1, 6, 4]]) # np.sqrt(0+9+16+1+36+16) print(&quot;Default(sqrt of square sum of all elements, does not return matrix), keepdims=False:\\n&quot;,np.linalg.norm(x)) print(&quot;Sqrt of square sum of all elements, return matrix, keepdims=True:\\n&quot;,np.linalg.norm(x,keepdims=True)) print(&quot;***********************&quot;) # np.sqrt(0+9+16), np.sqrt(1+36+16) print(&quot;Matrix's row vector, l2 norm, axis=1:\\n&quot;,np.linalg.norm(x,axis=1,keepdims=True)) # np.sqrt(0+1), np.sqrt(9+36), np.sqrt(16+16) print(&quot;Matrix's column vector, l2 norm, axis=0:\\n&quot;,np.linalg.norm(x,axis=0,keepdims=True)) print(&quot;***********************&quot;) # max(0+1, 3+6, 4+4) print(&quot;Matrix's l1 norm, ord=1:&quot;,np.linalg.norm(x,ord=1,keepdims=True)) print(&quot;Matrix's l2 norm, ord=2:&quot;,np.linalg.norm(x,ord=2,keepdims=True)) # max(0+3+4, 1+6+4) print(&quot;Matrix's âˆ norm, ord=np.inf:&quot;,np.linalg.norm(x,ord=np.inf,keepdims=True)) print(&quot;***********************&quot;) print(&quot;Matrix's row vector, l1 norm, ord=1, axis=1:\\n&quot;,np.linalg.norm(x,ord=1,axis=1,keepdims=True)) print(&quot;Matrix's row vector, l1 norm, ord=1, axis=1, keepdims=False:\\n&quot;,np.linalg.norm(x,ord=1,axis=1,keepdims=False)) ######### Output ######### &quot;&quot;&quot; Default(sqrt of square sum of all elements, does not return matrix), keepdims=False: 8.831760866327848 Sqrt of square sum of all elements, return matrix, keepdims=True: [[8.83176087]] *********************** Matrix's row vector, l2 norm, axis=1: [[5. ] [7.28010989]] Matrix's column vector, l2 norm, axis=0: [[1. 6.70820393 5.65685425]] *********************** Matrix's l1 norm, ord=1: [[9.]] Matrix's l2 norm, ord=2: [[8.70457079]] Matrix's âˆ norm, ord=np.inf: [[11.]] *********************** Matrix's row vector, l1 norm, ord=1, axis=1: [[ 7.] [11.]] Matrix's row vector, l1 norm, ord=1, axis=1, keepdims=False: [ 7. 11.] &quot;&quot;&quot; parameter description computation ord=1 l1l_1l1â€‹ norm |x1x_1x1â€‹|+|x2x_2x2â€‹|+...+|xnx_nxnâ€‹| Default l2l_2l2â€‹ norm x12+x22+...+xn2\\sqrt{x_1^2+x_2^2+...+x_n^2}x12â€‹+x22â€‹+...+xn2â€‹â€‹ ord=âˆ lâˆl_âˆlâˆâ€‹ norm max( |xix_ixiâ€‹| ) ord=1: Maximum of each column's sum ord=âˆ: Maximum of each row's sum ord=2: Find the eigenvalue, then find the maximum square of the eigenvalue. ans = np.mat(x).T*np.mat(x) [x,y] = np.linalg.eig(ans)) max(np.sqrt(x)) axis: process rule axis=0: processing by column vectors and finds the norm of multiple column vectors axis=1: processing by row vectors and finds the norm of multiple row vectors axis=None: Matrix's norm keepdims: whether to maintain the two-dimensional characteristics of the matrix ","link":"https://zl-wu.github.io/post/mla-gradient-descent-method/"},{"title":"MLA -- Naive Bayes theory","content":"&quot;Priori Probability + data = Posterior probability&quot; æ¡ä»¶æ¦‚ç‡ï¼š P(X|Y) or P(Y|X) è”åˆæ¦‚ç‡ï¼š P(X,Y), P(XY) or P(XnY) è¾¹ç¼˜æ¦‚ç‡ï¼š P(X) or P(Y) Let's look at the conditional independence formula first. If X and Y are independent of each other, there are: P(X,Y)=P(X)Ã—P(Y)P(X, Y) = P(X) \\times P(Y) P(X,Y)=P(X)Ã—P(Y) P(Xâˆ£Y)=P(X);P(Yâˆ£X)=P(Y);P(X|Y) = P(X) ; P(Y|X) = P(Y) ; P(Xâˆ£Y)=P(X);P(Yâˆ£X)=P(Y); Usually P(X|Y) != P(X) unless X and Y are independent of each other. And standard conditional probability formula: P(Xâˆ£Y)=P(X,Y)/P(Y)P(X|Y) = P(X, Y) / P(Y) P(Xâˆ£Y)=P(X,Y)/P(Y) P(Yâˆ£X)=P(X,Y)/P(X)P(Y|X) = P(X, Y) / P(X) P(Yâˆ£X)=P(X,Y)/P(X) or =&gt; P(Yâˆ£X)=P(Xâˆ£Y)Ã—P(Y)P(X)P(Y|X) = \\frac {P(X|Y) \\times P(Y)}{P(X)} P(Yâˆ£X)=P(X)P(Xâˆ£Y)Ã—P(Y)â€‹ Then the total probability formula: P(X)=âˆ‘kP(Xâˆ£Y=Yk)P(Yk)P(X) = \\sum_kP(X|Y = Y_k)P(Y_k) P(X)=kâˆ‘â€‹P(Xâˆ£Y=Ykâ€‹)P(Ykâ€‹) âˆ‘kP(Yk)=1\\sum_kP(Y_k) = 1 kâˆ‘â€‹P(Ykâ€‹)=1 Therefore, The Bayesian formula is easily derived from the above formulas: P(Ykâˆ£X)=P(Xâˆ£Yk)Ã—P(Yk)âˆ‘kP(Xâˆ£Y=Yk)P(Yk)P(Y_k|X) = \\frac {P(X|Y_k) \\times P(Y_k)} {\\sum_k P(X|Y=Y_k)P(Y_k)} P(Ykâ€‹âˆ£X)=âˆ‘kâ€‹P(Xâˆ£Y=Ykâ€‹)P(Ykâ€‹)P(Xâˆ£Ykâ€‹)Ã—P(Ykâ€‹)â€‹ Question: Suppose there is a latent disease among the people. P(disease) = 0.01 P(well) = 0.99 Doctor can detect this disease by some kinds of kit. The test result is &gt;positive(not healthy) and negtive(healthy). However, detection result &gt;may also be wrong. The conditional probability is : P(positive | well) = 0.01 (healthy people detected with positive) P(negtive | well) = 0.99 P(positive | disease) = 0.99 (unhealthy people detected with positive) P(negtive | disease) = 0.01 So, What is probability of P(disease | postive)? that is, if the detection is positive(bad), what is the probabiliy of true diseaseï¼Ÿ (Answer: P(disease | postive) = 0.5 ) (We can conclude P(X|Y) and P(Y|X) are totally different. P(X|Y) = P(Y|X)&gt;*P(X)/P(Y)) Bayesian interpretation In the Bayesian (or epistemological) interpretation, probability measures a â€œdegree of belief.â€ Bayesâ€™ theorem then links the degree of belief in a proposition before and after accounting for evidence. For example, suppose it is believed with 50% certainty that a coin is twice as likely to land heads than tails. If the coin is flipped a number of times and the outcomes observed, that degree of belief may rise, fall or remain the same depending on the results. P(Aâˆ£B)=P(Bâˆ£A)Ã—P(A)P(B)P(A|B) = \\frac {P(B|A) \\times P(A)}{P(B)} P(Aâˆ£B)=P(B)P(Bâˆ£A)Ã—P(A)â€‹ For proposition A and evidence B, P (A), the prior, is the initial degree of belief in A. P (A | B), the posterior is the degree of belief having accounted for B. the quotient P(B | A)/P(B) represents the support B provides for A. In theory, the probabilistic model classifier is a conditional probability model: P( C|F1,...,Fn ) Based on the Bayes Formula: P(Câˆ£F1,...,Fn)=P(F1,...,Fnâˆ£C)âˆ—P(C)P(F1,...,Fn)P(C|F1,...,Fn) = \\frac {P(F1,...,Fn|C) * P(C)} {P(F1,...,Fn)} P(Câˆ£F1,...,Fn)=P(F1,...,Fn)P(F1,...,Fnâˆ£C)âˆ—P(C)â€‹ P(ç±»åˆ«âˆ£ç‰¹å¾)=P(ç‰¹å¾âˆ£ç±»åˆ«)âˆ—P(ç±»åˆ«)P(ç‰¹å¾)P(ç±»åˆ«|ç‰¹å¾) = \\frac {P(ç‰¹å¾|ç±»åˆ«) * P(ç±»åˆ«)} {P(ç‰¹å¾)} P(ç±»åˆ«âˆ£ç‰¹å¾)=P(ç‰¹å¾)P(ç‰¹å¾âˆ£ç±»åˆ«)âˆ—P(ç±»åˆ«)â€‹ P(C) is the prior probability P(C|F1,...,Fn) is the posterior probability C represents any Group of the classifier. (F1,...,Fn) represents features of data that we need to predict. We can understand it this way, when we donâ€™t know any features of the sample (predict database) that we need to predict, first determine the probability that the sample is a certain category is P(C), then, after knowing the features of the sample, multiply $ \\frac {P(F1,...,Fn|C)} {P(F1,...,Fn)} $ to get the sample's classification prediction. Denominator is P(F1,...,Fn), we can view it as a constant, since it does not depend on C, and value is same for each group probability prediction. Therefore, what we need to concern is the numerator P(F1,...,Fn|C) * P(C), which is equivalent to the joint distribution model P(C,F1,...,Fn) The Naive Bayes model makes a bold assumption here that ALL FEATURES (F1,...,Fn) are independent of each other, so that we can draw: P(F1,...,Fnâˆ£C)=P(F1âˆ£C)âˆ—P(F2âˆ£C)âˆ—...âˆ—P(Fnâˆ£C)P(F1,...,Fn|C) = P(F1|C)*P(F2|C)*...*P(Fn|C) P(F1,...,Fnâˆ£C)=P(F1âˆ£C)âˆ—P(F2âˆ£C)âˆ—...âˆ—P(Fnâˆ£C) Then the numerator P(F1,...,Fn|C) * P(C) is equivalent to: P(C)âˆ—âˆi=1nP(Fiâˆ£C)P(C)* \\prod_{i=1}^n P(F_i|C) P(C)âˆ—i=1âˆnâ€‹P(Fiâ€‹âˆ£C) Suppose there are k groups for classification: C1, C2, ... Ck. Then the prediction result formula of Naive Bayes Classifier is: Cresult=arg maxâ¡C1,C2,...CkP(Ck)âˆ—âˆi=1nP(Fiâˆ£Ck)C_{result} = \\argmax_{C1, C2, ... Ck} P(C_k)* \\prod_{i=1}^n P(F_i|C_k) Cresultâ€‹=C1,C2,...Ckargmaxâ€‹P(Ckâ€‹)âˆ—i=1âˆnâ€‹P(Fiâ€‹âˆ£Ckâ€‹) classify(f1,...fn)=arg maxâ¡C1,C2,...CkP(C=c)âˆ—âˆi=1nP(Fi=fiâˆ£C=c)classify(f1,...fn) = \\argmax_{C1, C2, ... Ck} P(C = c)* \\prod_{i=1}^n P(F_i=f_i|C=c) classify(f1,...fn)=C1,C2,...Ckargmaxâ€‹P(C=c)âˆ—i=1âˆnâ€‹P(Fiâ€‹=fiâ€‹âˆ£C=c) We calculate all the probabilities that the predicted data belong to each group, and then, by comparison, classify the data into the group with the highest probability (the most probable group). Naive Bayes parameter estimation In the previous section, we knew the formula, as long as we compare which group has largest $ P(C = c)* \\prod_{i=1}^n P(F_i=f_i|C=c) $. In this section, we discuss how to calculate this two kinds of probability. P(C=Ck) is easy, by maximum likelihood estimation we can easily get the frequency of occurrence of Ck. If the total number of sample is M, number of occurrences of Ck is Mk. Then P(C=Ck) = Mk/M. Therefore, the prior probability P(C=Ck) is very dependent on the selection of the overall sample. If the size of dataset is not big enough, or the propotion of count of each category is uneven, it will greatly affect the prediction of Naive Bayes Classification. P(Fi=fi | C=Ck) is a bit complicated, it depends on the data type of Fi. If the Fi is the Discrete Value: Polynomial distributionP(Fi=fiâˆ£C=Ck)=MkfiMkP(Fi=fi | C=Ck) = \\frac{M_{kfi}}{M_k} P(Fi=fiâˆ£C=Ck)=Mkâ€‹Mkfiâ€‹â€‹ Mkfi is the number of occurrences of fi in Mk. Somtime, Mkfi may be 0, which will affect he estimation of posterior probability. The solution is to import Laplace smoothing:P(Fi=fiâˆ£C=Ck)=Mkfi+Î»Mk+MfiÎ»P(Fi=fi | C=Ck) = \\frac{M_{kfi} + \\lambda}{M_k + M_{fi}\\lambda} P(Fi=fiâˆ£C=Ck)=Mkâ€‹+Mfiâ€‹Î»Mkfiâ€‹+Î»â€‹ Î» is a constant larger than 0, usually 1. Mfi is number of fi value. If the Fi is the Very Sparse discrete values: Bernoulli distributionP(Fi=fiâˆ£C=Ck)=P(Fi=1âˆ£C=Ck)âˆ—fi+(1âˆ’P(Fi=1âˆ£C=Ck))âˆ—(1âˆ’fi)P(Fi=fi | C=Ck) = P(Fi=1|C=Ck)*fi + (1-P(Fi=1|C=Ck))*(1-fi) P(Fi=fiâˆ£C=Ck)=P(Fi=1âˆ£C=Ck)âˆ—fi+(1âˆ’P(Fi=1âˆ£C=Ck))âˆ—(1âˆ’fi) fi is 0 or 1. if fi appears in the subset Mk, fi is 1, otherwise 0. If the Fi is a very sparse discrete value, that is, the occurrence probability of each feature is very low, then we can assume Fi in line with Bernoulli distribution. Feature fi appears as 1, does not appear as 0. We only pay attention to whether fi appears, not the number of occurrences. If the Fi is the Continuous Value, we usually take Fi's prior probability as normally distributed: P(Fi=fiâˆ£C=Ck)=12Ï€Ïƒk2âˆ—eâˆ’(fiâˆ’Î¼k)22Ïƒk2P(Fi=fi | C=C_k) = \\frac{1}{\\sqrt{2\\pi\\sigma_k^2}} * e^{-\\frac{(fi - \\mu_k)^2}{2\\sigma_k^2}} P(Fi=fiâˆ£C=Ckâ€‹)=2Ï€Ïƒk2â€‹â€‹1â€‹âˆ—eâˆ’2Ïƒk2â€‹(fiâˆ’Î¼kâ€‹)2â€‹ # Continuous Data Code import math pi = math.pi e = math.e def probabilityDensity(mu, sig2, v): res = 1/math.sqrt(2*pi*sig2) * e ** (-(v-mu)**2/(2*sig2)) return format(res,'.4e') Naive Bayes algorithm process Step one: Input the prior probability P(C=Ck), if the P(C=Ck) is Null, P(C=Ck) = (Mk + Î») / (M + KÎ») Step two: Calculate the conditional probability of each feature of the k-th category. Condition 1: Feature i is the Discrete Value:P(Fi=fiâˆ£C=Ck)=Mkfi+Î»Mk+MfiÎ»P(Fi=fi | C=Ck) = \\frac{M_{kfi} + \\lambda}{M_k + M_{fi}\\lambda} P(Fi=fiâˆ£C=Ck)=Mkâ€‹+Mfiâ€‹Î»Mkfiâ€‹+Î»â€‹ Condition 2: Feature i is the Sparse Discrete Value:P(Fi=fiâˆ£C=Ck)=P(Fi=1âˆ£C=Ck)âˆ—fi+(1âˆ’P(Fi=1âˆ£C=Ck))âˆ—(1âˆ’fi)P(Fi=fi | C=Ck) = P(Fi=1|C=Ck)*fi + (1-P(Fi=1|C=Ck))*(1-fi) P(Fi=fiâˆ£C=Ck)=P(Fi=1âˆ£C=Ck)âˆ—fi+(1âˆ’P(Fi=1âˆ£C=Ck))âˆ—(1âˆ’fi) Condition 1: Feature i is the Continuous Value:P(Fi=fiâˆ£C=Ck)=12Ï€Ïƒk2âˆ—eâˆ’(fiâˆ’Î¼k)22Ïƒk2P(Fi=fi | C=C_k) = \\frac{1}{\\sqrt{2\\pi\\sigma_k^2}} * e^{-\\frac{(fi - \\mu_k)^2}{2\\sigma_k^2}} P(Fi=fiâˆ£C=Ckâ€‹)=2Ï€Ïƒk2â€‹â€‹1â€‹âˆ—eâˆ’2Ïƒk2â€‹(fiâˆ’Î¼kâ€‹)2â€‹ Step three: For the instance prediction features (pf1,...pfn), Calculate posterior probability separately: P(C=Ck)âˆ—âˆi=1nP(Fi=pfiâˆ£Ck)P(C=C_k) * \\prod_{i=1}^n P(F_i = pf_i | C_k) P(C=Ckâ€‹)âˆ—i=1âˆnâ€‹P(Fiâ€‹=pfiâ€‹âˆ£Ckâ€‹) Determine the classification of prediction data (pf1,...pfn): Cresult=arg maxâ¡C1,C2,...CkP(Ck)âˆi=1nP(Fi=pfiâˆ£Ck)C_{result} = \\argmax_{C_1, C_2,...C_k} P(C_k) \\prod_{i=1}^n P(F_i = pf_i | C_k) Cresultâ€‹=C1â€‹,C2â€‹,...Ckâ€‹argmaxâ€‹P(Ckâ€‹)i=1âˆnâ€‹P(Fiâ€‹=pfiâ€‹âˆ£Ckâ€‹) Pros and cons Conclusion Advantages of Naive Bayes: The naive Bayesian model originates from classical mathematical theory and has a stable classification efficiency. Performs well on small-scale data, can handle multi-classification tasks, suitable for incremental training, especially when the amount of data exceeds the memory, we can batch-by-batch incremental training. Less sensitive to missing data, and the algorithm is relatively simple, often used for text classification. Disadvantages of Naive Bayes: In theory, the Naive Bayes model has the smallest error rate compared with other classification methods. However, this is not always the case, because the naive Bayes model gives an output category, and assumes that the attributes are mutually independent. This assumption is often not true in practical applications. When the correlation between them is large, the classification effect is not good. When the attribute correlation is small, Naive Bayes has the best performance. For this, there are algorithms such as semi-Naive Bayes that are moderately improved by considering partial relevance. Need to know the a priori probability, and the priori probability often depends on the hypothesis, there can be many models of hypothesis, so in some cases, due to the hypothesis of the prior model, the prediction effect is not good. Since we decide the classification by prior and data to determine the posterior probability, the classification decision has a certain error rate. Very sensitive to the type of input data: discrete, sparse discrete or contiuous data. ","link":"https://zl-wu.github.io/post/mla-naive-bayes-theory/"},{"title":"Python code of binomial distribution","content":"&quot;python code to play with binomial distribution&quot; Binomial Distribution import numpy as np import matplotlib.pyplot as plt def C_nk (n, k): # get C(n,k) res = 1 for i in range(n, n-k,-1): res *= i for i in range(k,0,-1): res /= i return res def binomProb(n, k, p): return C_nk(n,k) * p**k * (1-p)**(n-k) # n = 10, P(yes) = 0.3; P(no) = 0.7 n = 10 p = 0.3 x = np.arange(n+1) y = [] for k in x: y.append(binomProb(n,k,p)) # Draw the Binomial probability distribution plt.bar(x,y) plt.show() import scipy.stats as sps # all k&gt;2 probability n = 10 p = 0.3 k = np.arange(n + 1) PX = sps.binom.pmf(k, n, p) # äºŒé¡¹åˆ†å¸ƒç´¯è®¡åˆ†å¸ƒ print(sum(PX[2:])) Bernoulli Distribution X~B(n,p), when n=1, Binomial distribution becomes Bernoulli Distribution. ä¼¯åŠªåˆ©åˆ†å¸ƒã€ä¸¤ç‚¹åˆ†å¸ƒã€0-1åˆ†å¸ƒè¿™ä¸‰ç§åˆ†å¸ƒæ˜¯åŒä¸€ä¸ªåˆ†å¸ƒçš„ä¸åŒåç§°ï¼Œåˆéƒ½æ˜¯äºŒé¡¹åˆ†å¸ƒåœ¨n=1æ—¶çš„ç‰¹ä¾‹ã€‚ æ¦‚ç‡è´¨é‡å‡½æ•°(probability mass functionï¼Œç®€ç§°PMF) ç´¯ç§¯åˆ†å¸ƒå‡½æ•°(cumulative distribution function, ç®€ç§°CDF) ç¦»æ•£æ¦‚ç‡åˆ†å¸ƒ(Discrete probability distribution) ","link":"https://zl-wu.github.io/post/python-code-of-binomial-distribution/"},{"title":"Markdown syntax note (Continuously updating)","content":"LaTex Greek Alphabet correspondence table: Alphabet LaTex Code Î±\\alphaÎ± $\\alpha$ Î²\\betaÎ² $\\beta$ Î³\\gammaÎ³ $\\gamma$ Î“\\GammaÎ“ $\\Gamma$ Î´\\deltaÎ´ $\\delta$ Î”\\DeltaÎ” $\\Delta$ Ïµ\\epsilonÏµ $\\epsilon$ Îµ\\varepsilonÎµ $\\varepsilon$ Î¶\\zetaÎ¶ $\\zeta$ Î·\\etaÎ· $\\eta$ Î¸\\thetaÎ¸ $\\theta$ Î˜\\ThetaÎ˜ $\\Theta$ Ï‘\\varthetaÏ‘ $\\vartheta$ Î¹\\iotaÎ¹ $\\iota$ Îº\\kappaÎº $\\kappa$ Î»\\lambdaÎ» $\\lambda$ Î›\\LambdaÎ› $\\Lambda$ Î¼\\muÎ¼ $\\mu$ Î½\\nuÎ½ $\\nu$ Î¾\\xiÎ¾ $\\xi$ Î\\XiÎ $\\Xi$ Ï€\\piÏ€ $\\pi$ Î \\PiÎ  $\\Pi$ Ï–\\varpiÏ– $\\varpi$ Ï\\rhoÏ $\\rho$ Ï±\\varrhoÏ± $\\varrho$ Ïƒ\\sigmaÏƒ $\\sigma$ Î£\\SigmaÎ£ $\\Sigma$ Ï‚\\varsigmaÏ‚ $\\varsigma$ Ï„\\tauÏ„ $\\tau$ Ï…\\upsilonÏ… $\\upsilon$ Î¥\\UpsilonÎ¥ $\\Upsilon$ Ï•\\phiÏ• $\\phi$ Î¦\\PhiÎ¦ $\\Phi$ Ï†\\varphiÏ† $\\varphi$ Ï‡\\chiÏ‡ $\\chi$ Ïˆ\\psiÏˆ $\\psi$ Î¨\\PsiÎ¨ $\\Psi$ Î©\\OmegaÎ© $\\Omega$ Ï‰\\omegaÏ‰ $\\omega$ â‰¡\\equivâ‰¡ $\\equiv$ ","link":"https://zl-wu.github.io/post/markdown-syntax-note-continuously-updating/"},{"title":"Topic modeling in Gensim","content":"&quot;Research the source code of Topic Modeling in gensim&quot; A Simple Example Code from nltk.tokenize import regexp_tokenize from nltk.corpus import stopwords from nltk.stem import WordNetLemmatizer lemmatizer = WordNetLemmatizer() tokens = [] for doc in my_docs: words = regexp_tokenize(doc.lower(), r'[A-Za-z]+') words = [w for w in words if w not in stopwords.words('english')] words = [lemmatizer.lemmatize(w) for w in words] tokens.append(words) # Gensim tf-idf from gensim.corpora import Dictionary from gensim.models import TfidfModel my_dict = Dictionary(tokens) my_dict.filter_extremes(no_below=5, no_above=0.90) dtm = [my_dict.doc2bow(doc) for doc in tokens] tfidf = TfidfModel(dtm) for doc in tfidf[dtm]: print([[my_dict[i], np.around(freq, decimals=2)] for i, freq in doc]) ''' output: [['advertising', 0.16], ['bbc', 0.04], ['bill', 0.05], ['book', 0.05], ....] [['book', 0.19], ['company', 0.05], ['firm', 0.11], ['month', 0.04], ['telecom', 0.26], ....] [['bbc', 0.09], ['moment', 0.11], ['month', 0.05], ['bos', 0.12], ['cross', 0.15], ....] [['home', 0.06], ['play', 0.07], ['face', 0.31], ['game', 0.11], ['league', 0.1], ....] ... ''' # Gensim: LSI from gensim.models import LsiModel, CoherenceModel lsi_model = LsiModel(corpus=dtm, id2word=my_dict, num_topics=5) # lsi_model.print_topics(-1) lsi_model.print_topics(num_topics=5, num_words=5) # Determining optimum number of topics using coherence values coherence_values = [] lsi_model_list = [] min_topics, max_topics, step = 1, 5, 1 for i in range(min_topics, max_topics, step): lsi_model = LsiModel(dtm, id2word=my_dict, num_topics=i) lsi_model_list.append(lsi_model) coherencemodel = CoherenceModel(model=lsi_model, texts=tokens, \\ dictionary=my_dict, coherence='c_v') coherence_values.append(coherencemodel.get_coherence()) # Gensim: LDA from gensim.models import LdaModel, LdaMulticore lda_model = LdaModel(dtm, num_topics=3, id2word=my_dict, passes=10) # lda_model.print_topics(-1) lda_model.print_topics(num_topics=3, num_words=3) lda_model_mc = LdaMulticore(dtm, num_topics=3, id2word=my_dict, passes=10, workers=4) lda_model_mc.print_topics(-1) lda_model.save('my_lda_model.lda') # Save LDA model # Evaluating LDA models: Topic coherence goodLdaModel = LdaModel(corpus=dtm, id2word=my_dict, iterations=50, num_topics=2) badLdaModel = LdaModel(corpus=dtm, id2word=my_dict, iterations=1, num_topics=2) goodcm = CoherenceModel(model=goodLdaModel, corpus=dtm, dictionary=my_dict, coherence='u_mass') badcm = CoherenceModel(model=badLdaModel, corpus=dtm, dictionary=my_dict, coherence='u_mass') goodcm.get_coherence() badcm.get_coherence() goodcm = CoherenceModel(model=goodLdaModel, texts=dtm, dictionary=my_dict, coherence='c_v') badcm = CoherenceModel(model=badLdaModel, texts=dtm, dictionary=my_dict, coherence='c_v') # Display LDA outputs (runs only on HTML platforms like Jupyter) import pyLDAvis.gensim pyLDAvis.enable_notebook() vis = pyLDAvis.gensim.prepare(lda_model, dtm, my_dict) pyLDAvis.display(vis) 1. Dictionary (source) &gt;&gt;&gt; from gensim.corpora import Dictionary &gt;&gt;&gt; &gt;&gt;&gt; texts = [['human', 'interface', 'computer']] &gt;&gt;&gt; dct = Dictionary(texts) # initialize a Dictionary &gt;&gt;&gt; dct.add_documents([[&quot;cat&quot;, &quot;say&quot;, &quot;meow&quot;], [&quot;dog&quot;]]) # add more document (extend the vocabulary) &gt;&gt;&gt; dct.doc2bow([&quot;dog&quot;, &quot;computer&quot;, &quot;non_existent_word&quot;]) [(0, 1), (6, 1)] The most important methods is doc2bow(['..','..',...]) def doc2bow(self, document, allow_update=False, return_missing=False): &quot;&quot;&quot;Convert `document` into the bag-of-words (BoW) format = list of `(token_id, token_count)` tuples.&quot;&quot;&quot; ... # Construct (word, frequency) mapping. counter = defaultdict(int) for w in document: counter[w if isinstance(w, unicode) else unicode(w, 'utf-8')] += 1 token2id = self.token2id result = {token2id[w]: freq for w, freq in iteritems(counter) if w in token2id} ... result = sorted(iteritems(result)) ... return result doc2bow() is very similar with nltk.FreqDist(). The result returned is [(worid_id, freq),(worid_id, freq),...]. 2. TfidfModel (source) from gensim.models import TfidfModel dtm = [my_dict.doc2bow(doc) for doc in tokens] tfidf_vectorizer = TfidfModel(dtm) tfidf = tfidf_vectorizer[dtm] # idf: self.idfs = precompute_idfs(self.wglobal, self.dfs, self.num_docs) print(self.wglobal) # &lt;function gensim.models.tfidfmodel.df2idf(docfreq, totaldocs, log_base=2.0, add=0.0)&gt; def precompute_idfs(wglobal, dfs, total_docs): return {termid: wglobal(df, total_docs) for termid, df in iteritems(dfs)} def df2idf(docfreq, totaldocs, log_base=2.0, add=0.0): return add + np.log(float(totaldocs) / docfreq) / np.log(log_base) idf=0+logâ¡(totalDocsdocFreq)logâ¡2=logâ¡2(totalDocsdocFreq)=logâ¡2(Nnk)idf = 0 + \\frac{\\log(\\frac{totalDocs}{docFreq})} {\\log2} = \\log_2(\\frac{totalDocs}{docFreq}) = \\log_2(\\frac{N}{n_k}) idf=0+log2log(docFreqtotalDocsâ€‹)â€‹=log2â€‹(docFreqtotalDocsâ€‹)=log2â€‹(nkâ€‹Nâ€‹) # tf: dtm # tf-idf: as example of dtm[0] from gensim.models import TfidfModel termid_array, tf_array = [], [] for termid, tf in dtm[0]: termid_array.append(termid) tf_array.append(tf) model = TfidfModel(dtm) print(model.idfs) # it is the idf of each token in dictionary print(model.eps) # 1e-12 # if a word almost appears in all documents, which makes idf of this word is very close to 0, then we remove it in tfidf. vector = [(termid, tf * model.idfs.get(termid)) for termid, tf in zip(termid_array, tf_array) if abs(model.idfs.get(termid, 0.0)) &gt; model.eps] # next we use l2 normalize this vector (default normalize) length = 1.0 * math.sqrt(sum(val ** 2 for _, val in vector)) tfidf = [(termid, val/length) for termid, val in vector] # This is what happend behind the code &quot;model[dtm[0]]&quot; # l1 : length = float(sum(abs(val) for _, val in vector)) # l2 : length = 1.0 * math.sqrt(sum(val ** 2 for _, val in vector)) # unique: length = 1.0 * len(vector) After obtaining the product of tf and idf of the current word, Cosine normalization is performed. length=1.0Ã—âˆ‘val2âˆˆvector=âˆ‘k=1twik2length = 1.0 \\times \\sqrt{\\sum{val^2 \\in vector}} = \\sqrt{\\sum^{t}_{k=1}w^2_{i_k}} length=1.0Ã—âˆ‘val2âˆˆvectorâ€‹=k=1âˆ‘tâ€‹wikâ€‹2â€‹â€‹ tfidf=valâˆˆvectorlengthtfidf = \\frac{val \\in vector} {length} tfidf=lengthvalâˆˆvectorâ€‹ In fact, the above tfidf calculation methods are all default, that is, we can specify the calculation method according to requirements. # We can modify this attribute when we create an instance of TfidfModel class TfidfModel(interfaces.TransformationABC): def __init__(self, corpus=None, id2word=None, dictionary=None, wlocal=utils.identity, wglobal=df2idf, normalize=True, smartirs=None, pivot=None, slope=0.25): .... &quot;&quot;&quot; smartirs : str, optional SMART (System for the Mechanical Analysis and Retrieval of Text) Information Retrieval System, a mnemonic scheme for denoting tf-idf weighting variants in the vector space model. The mnemonic for representing a combination of weights takes the form XYZ, for example 'ntc', 'bpn' and so on, where the letters represents the term weighting of the document vector. Term frequency weighing: * `b` - binary, * `t` or `n` - raw, * `a` - augmented, * `l` - logarithm, * `d` - double logarithm, * `L` - log average. Document frequency weighting: * `x` or `n` - none, * `f` - idf, * `t` - zero-corrected idf, * `p` - probabilistic idf. Document normalization: * `x` or `n` - none, * `c` - cosine, * `u` - pivoted unique, * `b` - pivoted character length. Default is 'nfc'. For more information visit `SMART Information Retrieval System &lt;https://en.wikipedia.org/wiki/SMART_Information_Retrieval_System&gt;`_. &quot;&quot;&quot; SMART Information Retrieval System 3. LsiModel (source) Model for Latent Semantic Indexing https://en.wikipedia.org/wiki/Latent_semantic_analysis#Latent_semantic_indexing # Gensim: LSI from gensim.models import LsiModel, CoherenceModel lsi_model = LsiModel(corpus=dtm, id2word=my_dict, num_topics=5) # lsi_model.print_topics(-1) lsi_model.print_topics(num_topics=5, num_words=5) def __init__(self, m, k, docs=None, use_svdlibc=False, power_iters=P2_EXTRA_ITERS, extra_dims=P2_EXTRA_DIMS, dtype=np.float64): ## __init__() self.projection = Projection( self.num_terms, self.num_topics, power_iters=self.power_iters, extra_dims=self.extra_samples, dtype=dtype ) ## add_document() update = Projection( self.num_terms, self.num_topics, job, extra_dims=self.extra_samples, power_iters=self.power_iters, dtype=self.dtype ) def stochastic_svd(corpus, rank, num_terms, chunksize=20000, extra_dims=None, power_iters=0, dtype=np.float64, eps=1e-6): pass u, s = stochastic_svd( docs, k, chunksize=sys.maxsize, num_terms=m, power_iters=self.power_iters, extra_dims=self.extra_dims, dtype=dtype) self.show_topics(num_topics=num_topics, num_words=num_words, log=True) def show_topics(self, num_topics=-1, num_words=10, log=False, formatted=True): &quot;&quot;&quot;Get the most significant topics. log : bool, optional If True - log topics with logger. formatted : bool, optional If True - each topic represented as string, otherwise - in BoW format. Returns ------- list of (int, str) If `formatted=True`, return sequence with (topic_id, string representation of topics) **OR** list of (int, list of (str, float)) Otherwise, return sequence with (topic_id, [(word, value), ... ]). &quot;&quot;&quot; shown = [] if num_topics &lt; 0: num_topics = self.num_topics for i in range(min(num_topics, self.num_topics)): if i &lt; len(self.projection.s): if formatted: topic = self.print_topic(i, topn=num_words) else: topic = self.show_topic(i, topn=num_words) shown.append((i, topic)) if log: logger.info(&quot;topic #%i(%.3f): %s&quot;, i, self.projection.s[i], topic) return shown 4. LdaModel 5. LdaMulticore 6. CoherenceModel Example of sklearn topic modeling https://cloud.tencent.com/developer/article/1530432 docs = [&quot;In the middle of the night&quot;, &quot;When our hopes and fears collide&quot;, &quot;In the midst of all goodbyes&quot;, &quot;Where all human beings lie&quot;, &quot;Against another lie&quot;] vectorizer = TfidfVectorizer() X = vectorizer.fit_transform(docs) terms = vectorizer.get_feature_names() print(terms) n_pick_topics = 3 # è®¾å®šä¸»é¢˜æ•°ä¸º3 lsa = TruncatedSVD(n_pick_topics) X2 = lsa.fit_transform(X) X2 n_pick_docs= 2 topic_docs_id = [X2[:,t].argsort()[:-(n_pick_docs+1):-1] for t in range(n_pick_topics)] topic_docs_id n_pick_keywords = 4 topic_keywords_id = [lsa.components_[t].argsort()[:-(n_pick_keywords+1):-1] for t in range(n_pick_topics)] topic_keywords_id for t in range(n_pick_topics): print(&quot;topic %d:&quot; % t) print(&quot; keywords: %s&quot; % &quot;, &quot;.join(terms[topic_keywords_id[t][j]] for j in range(n_pick_keywords))) for i in range(n_pick_docs): print(&quot; doc %d&quot; % i) print(&quot;\\t&quot;+docs[topic_docs_id[t][i]]) ","link":"https://zl-wu.github.io/post/topic-modeling-in-gensim/"},{"title":"Compare nltk and textblob''''''''''''''''s sentiment analysis","content":"&quot;This is a comparison report between nltk and textblob in sentiment analysis.&quot; Overview lexicon 1. NLTK's vader_lexicon.txt : NLTK's default lexicon file (online source) # Part of vader_lexicon.txt .... # emoticon (-* 1.3 1.26886 [4, 1, 2, 0, 2, -1, 1, 2, 1, 1] (-: 1.6 0.8 [2, 2, 1, 3, 1, 1, 1, 3, 1, 1] (-:0 2.8 0.87178 [3, 2, 3, 4, 3, 2, 3, 1, 4, 3] (-:&lt; -0.4 2.15407 [-3, 3, -1, -1, 2, -1, -2, 3, -3, -1] (-:o 1.5 0.67082 [3, 1, 1, 2, 2, 2, 1, 1, 1, 1] (-:O 1.5 0.67082 [3, 1, 1, 2, 2, 2, 1, 1, 1, 1] (-:{ -0.1 1.57797 [-2, -3, 1, -2, 1, 1, 0, 0, 2, 1] (-:|&gt;* 1.9 0.83066 [3, 2, 2, 1, 0, 2, 3, 2, 2, 2] (-; 1.3 1.18743 [3, 2, 3, 0, 1, -1, 1, 2, 1, 1] (-;| 2.1 1.13578 [3, 2, 2, 4, 1, 1, 1, 4, 2, 1] (8 2.6 1.0198 [4, 2, 1, 3, 3, 3, 3, 1, 2, 4] .... # word cheer 2.3 0.64031 [2, 1, 2, 2, 2, 3, 3, 3, 2, 3] cheered 2.3 0.78102 [2, 3, 3, 4, 2, 1, 2, 2, 2, 2] cheerer 1.7 0.45826 [1, 2, 2, 2, 1, 1, 2, 2, 2, 2] cheerers 1.8 0.87178 [2, 2, 3, 2, 1, 2, 0, 1, 3, 2] cheerful 2.5 0.67082 [3, 2, 3, 2, 2, 2, 4, 2, 3, 2] cheerfuller 1.9 0.83066 [3, 3, 2, 3, 2, 1, 1, 2, 1, 1] cheerfullest 3.2 0.87178 [4, 4, 4, 4, 3, 2, 2, 3, 2, 4] cheerfully 2.1 0.83066 [3, 2, 2, 2, 1, 3, 1, 3, 1, 3] cheerfulness 2.1 0.9434 [3, 2, 1, 2, 3, 4, 1, 2, 1, 2] cheerier 2.6 0.4899 [2, 2, 3, 3, 2, 3, 3, 2, 3, 3] cheeriest 2.2 0.6 [3, 2, 3, 1, 2, 2, 3, 2, 2, 2] .... # load lexicon in Python from nltk.sentiment.vader import SentimentIntensityAnalyzer analyzer = SentimentIntensityAnalyzer() type(analyzer.lexicon) # dict len(analyzer.lexicon) # 7502 analyzer.lexicon ''' output: { ... '(-*': 1.3, '(-:': 1.6, '(-:0': 2.8, '(-:&lt;': -0.4, '(-:o': 1.5, '(-:O': 1.5, '(-:{': -0.1, '(-:|&gt;*': 1.9, '(-;': 1.3, '(-;|': 2.1, '(8': 2.6, ... } ''' 2. TextBlob's en-sentiment.xml : TextBlob's default lexicon file (online source) &lt;sentiment language=&quot;en&quot; version=&quot;1.3&quot; author=&quot;Tom De Smedt, Walter Daelemans&quot; license=&quot;PDDL&quot;&gt; &lt;word form=&quot;13th&quot; wordnet_id=&quot;a-02203763&quot; pos=&quot;JJ&quot; sense=&quot;coming next after the twelfth in position&quot; polarity=&quot;0.0&quot; subjectivity=&quot;0.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;20th&quot; cornetto_synset_id=&quot;n_a-531612&quot; wordnet_id=&quot;a-02204716&quot; pos=&quot;JJ&quot; sense=&quot;coming next after the nineteenth in position&quot; polarity=&quot;0.0&quot; subjectivity=&quot;0.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;21st&quot; wordnet_id=&quot;a-02204823&quot; pos=&quot;JJ&quot; sense=&quot;coming next after the twentieth in position&quot; polarity=&quot;0.0&quot; subjectivity=&quot;0.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;2nd&quot; wordnet_id=&quot;a-02202146&quot; pos=&quot;JJ&quot; sense=&quot;coming next after the first in position in space or time or degree or magnitude&quot; polarity=&quot;0.0&quot; subjectivity=&quot;0.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;3rd&quot; cornetto_synset_id=&quot;n_a-530634&quot; wordnet_id=&quot;a-02202307&quot; pos=&quot;JJ&quot; sense=&quot;coming next after the second and just before the fourth in position&quot; polarity=&quot;0.0&quot; subjectivity=&quot;0.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;abhorrent&quot; wordnet_id=&quot;a-1625063&quot; pos=&quot;JJ&quot; sense=&quot;offensive to the mind&quot; polarity=&quot;-0.7&quot; subjectivity=&quot;0.8&quot; intensity=&quot;1.0&quot; reliability=&quot;0.9&quot; /&gt; &lt;word form=&quot;able&quot; cornetto_synset_id=&quot;n_a-534450&quot; wordnet_id=&quot;a-01017439&quot; pos=&quot;JJ&quot; sense=&quot;having a strong healthy body&quot; polarity=&quot;0.5&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;able&quot; wordnet_id=&quot;a-00001740&quot; pos=&quot;JJ&quot; sense=&quot;(usually followed by 'to') having the necessary means or skill or know-how or authority to do something&quot; polarity=&quot;0.5&quot; subjectivity=&quot;0.5&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; .... &lt;word form=&quot;implicit in&quot; cornetto_synset_id=&quot;n_a-520863&quot; wordnet_id=&quot;a-00941940&quot; pos=&quot;JJ&quot; sense=&quot;in the nature of something though not readily apparent&quot; polarity=&quot;0.0&quot; subjectivity=&quot;0.1&quot; intensity=&quot;1.0&quot; confidence=&quot;0.8&quot; /&gt; &lt;word form=&quot;important&quot; cornetto_synset_id=&quot;d_a-9178&quot; wordnet_id=&quot;a-01830403&quot; pos=&quot;JJ&quot; sense=&quot;having authority or ascendancy or influence&quot; polarity=&quot;0.5&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;important&quot; cornetto_synset_id=&quot;n_a-527688&quot; wordnet_id=&quot;a-02161432&quot; pos=&quot;JJ&quot; sense=&quot;important in effect or meaning&quot; polarity=&quot;0.5&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;important&quot; wordnet_id=&quot;a-00655779&quot; pos=&quot;JJ&quot; sense=&quot;of extreme importance&quot; polarity=&quot;0.0&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;important&quot; wordnet_id=&quot;a-01275562&quot; pos=&quot;JJ&quot; sense=&quot;of great significance or value&quot; polarity=&quot;0.5&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;important&quot; wordnet_id=&quot;a-01539887&quot; pos=&quot;JJ&quot; sense=&quot;having or suggesting a consciousness of high position&quot; polarity=&quot;0.5&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;impossible&quot; cornetto_synset_id=&quot;n_a-511166&quot; wordnet_id=&quot;a-02418692&quot; pos=&quot;JJ&quot; sense=&quot;totally unlikely&quot; polarity=&quot;-0.5&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;impossible&quot; cornetto_synset_id=&quot;n_a-521243&quot; wordnet_id=&quot;a-02436025&quot; pos=&quot;JJ&quot; sense=&quot;used of persons or their behavior&quot; polarity=&quot;-1.0&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;impossible&quot; wordnet_id=&quot;a-01823092&quot; pos=&quot;JJ&quot; sense=&quot;not capable of occurring or being accomplished or dealt with&quot; polarity=&quot;-0.5&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;impressed&quot; cornetto_synset_id=&quot;n_a-509653&quot; wordnet_id=&quot;a-00071142&quot; pos=&quot;JJ&quot; sense=&quot;deeply or markedly affected or influenced&quot; polarity=&quot;1.0&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;impressive&quot; cornetto_synset_id=&quot;n_a-524894&quot; wordnet_id=&quot;a-00835292&quot; pos=&quot;JJ&quot; sense=&quot;producing a strong effect&quot; polarity=&quot;1.0&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;impressive&quot; wordnet_id=&quot;a-01282014&quot; pos=&quot;JJ&quot; sense=&quot;making a strong or vivid impression&quot; polarity=&quot;1.0&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.9&quot; /&gt; &lt;word form=&quot;in good taste&quot; cornetto_synset_id=&quot;n_a-528044&quot; wordnet_id=&quot;a-00689215&quot; pos=&quot;JJ&quot; sense=&quot;satisfying generally accepted social or esthetic standards&quot; polarity=&quot;0.9&quot; subjectivity=&quot;1.0&quot; intensity=&quot;1.0&quot; confidence=&quot;0.8&quot; /&gt; &lt;word form=&quot;in stock&quot; cornetto_synset_id=&quot;n_a-533683&quot; wordnet_id=&quot;a-00184543&quot; pos=&quot;JJ&quot; sense=&quot;available for use or sale&quot; polarity=&quot;0.1&quot; subjectivity=&quot;0.4&quot; intensity=&quot;1.0&quot; confidence=&quot;0.8&quot; /&gt; .... &lt;/sentiment&gt; # load lexicon in Python from textblob.en import sentiment as pattern_sentiment type(pattern_sentiment) # textblob.en.Sentiment len(pattern_sentiment) # 2860 pattern_sentiment['great'] # {'JJ': [0.8, 0.75, 1.0], None: [0.8, 0.75, 1.0]} pattern_sentiment('great') # (0.8, 0.75) for k,v in pattern_sentiment.items(): print(k,v) ''' output: 13th {'JJ': [0.0, 0.0, 1.0], None: [0.0, 0.0, 1.0]} 20th {'JJ': [0.0, 0.0, 1.0], None: [0.0, 0.0, 1.0]} 21st {'JJ': [0.0, 0.0, 1.0], None: [0.0, 0.0, 1.0]} 2nd {'JJ': [0.0, 0.0, 1.0], None: [0.0, 0.0, 1.0]} 3rd {'JJ': [0.0, 0.0, 1.0], None: [0.0, 0.0, 1.0]} abhorrent {'JJ': [-0.7, 0.8, 1.0], None: [-0.7, 0.8, 1.0]} able {'JJ': [0.5, 0.625, 1.0], None: [0.5, 0.625, 1.0]} above {'JJ': [0.0, 0.1, 1.0], None: [0.0, 0.1, 1.0]} .... 13th {'JJ': [0.0, 0.0, 1.0], None: [0.0, 0.0, 1.0]} 20th {'JJ': [0.0, 0.0, 1.0], None: [0.0, 0.0, 1.0]} 21st {'JJ': [0.0, 0.0, 1.0], None: [0.0, 0.0, 1.0]} 2nd {'JJ': [0.0, 0.0, 1.0], None: [0.0, 0.0, 1.0]} 3rd {'JJ': [0.0, 0.0, 1.0], None: [0.0, 0.0, 1.0]} abhorrent {'JJ': [-0.7, 0.8, 1.0], None: [-0.7, 0.8, 1.0]} able {'JJ': [0.5, 0.625, 1.0], None: [0.5, 0.625, 1.0]} above {'JJ': [0.0, 0.1, 1.0], None: [0.0, 0.1, 1.0]} .... ''' Summary Main Algorithm 1. NLTK's methods score_valence(self, sentiments, text) def score_valence(self, sentiments, text): if sentiments: ''' calculate compound value ''' sum_s = float(sum(sentiments)) # compute and add emphasis from punctuation in text punct_emph_amplifier = self._punctuation_emphasis(sum_s, text) if sum_s &gt; 0: sum_s += punct_emph_amplifier elif sum_s &lt; 0: sum_s -= punct_emph_amplifier compound = self.constants.normalize(sum_s) ''' calculate positive, negative and neutral values respectively ''' pos_sum, neg_sum, neu_count = self._sift_sentiment_scores(sentiments) if pos_sum &gt; math.fabs(neg_sum): pos_sum += punct_emph_amplifier elif pos_sum &lt; math.fabs(neg_sum): neg_sum -= punct_emph_amplifier total = pos_sum + math.fabs(neg_sum) + neu_count pos = math.fabs(pos_sum / total) neg = math.fabs(neg_sum / total) neu = math.fabs(neu_count / total) else: compound = 0.0 pos = 0.0 neg = 0.0 neu = 0.0 sentiment_dict = { &quot;neg&quot;: round(neg, 3), &quot;neu&quot;: round(neu, 3), &quot;pos&quot;: round(pos, 3), &quot;compound&quot;: round(compound, 4), } return sentiment_dict Parameter sentiments is a list of sentiment values corresponding to each token in the text. In brief, NLTK first sums up all individual words' sentiment values (positive real numbers and negative real numbers), then performs a text puctuation statistical emphasis operation, and finally normalizes the final result to obtain the &quot;Compound&quot; value. And NLTK uses the _sift_sentiment_scores method to get three values of pos, neg, and neu. We will look at this method later. Pos, neg, and neu have also undergone puctuation statistical emphasis. sentiment_valence(self, valence, sentitext, item, i, sentiments) def sentiment_valence(self, valence, sentitext, item, i, sentiments): is_cap_diff = sentitext.is_cap_diff words_and_emoticons = sentitext.words_and_emoticons item_lowercase = item.lower() if item_lowercase in self.lexicon: # get the sentiment valence valence = self.lexicon[item_lowercase] # Rule 1 : check if sentiment laden word is in ALL CAPS (while others aren't) if item.isupper() and is_cap_diff: if valence &gt; 0: valence += self.constants.C_INCR else: valence -= self.constants.C_INCR # Context Rules for start_i in range(0, 3): if ( i &gt; start_i and words_and_emoticons[i - (start_i + 1)].lower() not in self.lexicon ): # dampen the scalar modifier of preceding words and emoticons # (excluding the ones that immediately preceed the item) based # on their distance from the current item. # Rule 2 : preceding booster word s = self.constants.scalar_inc_dec( words_and_emoticons[i - (start_i + 1)], valence, is_cap_diff ) if start_i == 1 and s != 0: s = s * 0.95 if start_i == 2 and s != 0: s = s * 0.9 valence = valence + s # Rule 3 : preceding &quot;never&quot; word valence = self._never_check( valence, words_and_emoticons, start_i, i ) # Rule 4 : idioms check if start_i == 2: valence = self._idioms_check(valence, words_and_emoticons, i) # Rule 5 : check for negation case using &quot;least&quot; valence = self._least_check(valence, words_and_emoticons, i) sentiments.append(valence) return sentiments sentiment_valence is a method of calculating and adjusting the sentiment value of a single word. It is based on multiple rules. First the word has to be in the lexicon databse. After obtaining the basic sentiment value of the word, adjust the sentiment value of the current word again according to the ALL CAPS emphasis, the preceding booster word, &quot;never&quot;, idioms, and &quot;least&quot;. polarity_scores(self, text) def polarity_scores(self, text): &quot;&quot;&quot; Return a float for sentiment strength based on the input text. Positive values are positive valence, negative value are negative valence. &quot;&quot;&quot; # text, words_and_emoticons, is_cap_diff = self.preprocess(text) sentitext = SentiText(text, self.constants.PUNC_LIST, self.constants.REGEX_REMOVE_PUNCTUATION) sentiments = [] words_and_emoticons = sentitext.words_and_emoticons for item in words_and_emoticons: valence = 0 i = words_and_emoticons.index(item) if ( i &lt; len(words_and_emoticons) - 1 and item.lower() == &quot;kind&quot; and words_and_emoticons[i + 1].lower() == &quot;of&quot; ) or item.lower() in self.constants.BOOSTER_DICT: sentiments.append(valence) continue sentiments = self.sentiment_valence(valence, sentitext, item, i, sentiments) sentiments = self._but_check(words_and_emoticons, sentiments) return self.score_valence(sentiments, text) After obtaining the list of sentiment values, &quot;but check&quot; rule is also performed. 2. TextBlob's methods ","link":"https://zl-wu.github.io/post/compare-nltk-and-textblobs-sentiment-analysis/"},{"title":"Text Analysis -- NLTK''''''''''''''''s vader library","content":"&quot;Topic: How does NLTK's vader library work to calculate sentiment value for text?&quot; Topic: How does NLTK's vader library work to calculate sentiment value for text? source code -- vader.py Overview NLTK's vader tool is mainly used to judge the sentiment polarity of a text: positive, negative or neutral. From its code design perspective, the vader is more suitable for analyzing short social media text sentiment analysis. The most important part of vader is class SentimentIntensityAnalyzer, and the core methods of this class are polarity_scores(), sentiment_valence() and score_valence(). One simple example of using vader from nltk.sentiment.vader import SentimentIntensityAnalyzer analyzer = SentimentIntensityAnalyzer() sentiment = analyzer.polarity_scores(text) As we all know, the first &quot;import&quot; statement imported â€œSentimentIntensityAnalyzerâ€ class, and then we can use the methods of this class to calculate the text sentiment value. Next, we initiate a new instance &quot;analyzer&quot; of class &quot;SentimentIntensityAnalyzer&quot;. Finally, we call the methods &quot;polarity_scores()&quot; in this instance &quot;analyzer&quot;. Therefore, we can easily find out that the most critical question is what algorithm is included in the last method &quot;polarity_scores()&quot;? At first what is the content of this class? Class &quot;SentimentIntensityAnalyzer&quot; class SentimentIntensityAnalyzer: &quot;&quot;&quot; Give a sentiment intensity score to sentences. &quot;&quot;&quot; def __init__( self, lexicon_file=&quot;sentiment/vader_lexicon.zip/vader_lexicon/vader_lexicon.txt&quot;, ): self.lexicon_file = nltk.data.load(lexicon_file) self.lexicon = self.make_lex_dict() self.constants = VaderConstants() def make_lex_dict(self): &quot;&quot;&quot; Convert lexicon file to a dictionary &quot;&quot;&quot; lex_dict = {} for line in lexicon.split(&quot;\\n&quot;): # Only get &quot;word&quot; and &quot;sentiment value&quot; two data # (word, measure) = line.strip().split(&quot;\\t&quot;)[0:2] lex_dict[word] = float(measure) return lex_dict def polarity_scores(self, text): &quot;&quot;&quot; Return a float for sentiment strength based on the input text. Positive values are positive valence, negative value are negative valence. &quot;&quot;&quot; ... return self.score_valence(sentiments, text) def sentiment_valence(self, valence, sentitext, item, i, sentiments): ... return sentiments def _least_check(self, valence, words_and_emoticons, i): # check for negation case using &quot;least&quot; ... return valence def _but_check(self, words_and_emoticons, sentiments): ... return sentiments def _idioms_check(self, valence, words_and_emoticons, i): ... return valence def _never_check(self, valence, words_and_emoticons, start_i, i): ... return valence def _punctuation_emphasis(self, sum_s, text): # add emphasis from exclamation points and question marks ... return qm_amplifier def _sift_sentiment_scores(self, sentiments): # want separate positive versus negative sentiment scores ... return pos_sum, neg_sum, neu_count def score_valence(self, sentiments, text): ... return sentiment_dict This class needs one argument -- lexicon_file, which is a database of sentiment values for each word and emoticon. It uses nltk's own database by default, but we can also replace our database as needed. The database has at least two columns, the first column is the word and the second column is the sentiment value. We can see what the database -- vader_lexicon.txt looks like at the end of this article. This class also has 10 methods inside.The method starting with underscore _ is generally a method used internally by this class, and generally does not need to be called separately by the user. We can also roughly guess from their names &quot;_xxx_check&quot; that their meaning is the detection and corresponding scheme of the special grammar of text, such as but, never or adjective-est, etc. So we can currently focus our main attention on this four methods: polarity_scores() # main program, which is called mostly by users make_lex_dict() sentiment_valence() score_valence() Before starting to study the algorithm of this method, we must figure out what the two properties of this class generated in the constructor are. self.lexicon &amp; self.constants self.lexicon is generated by loading the word sentiment database and processing with the method make_lex_dict(). And self.lexicon is a dictionary, key and value pair is &quot;word or emoticon&quot; and &quot;sentiment value (a float number)&quot; self.constants is a instance of the class VaderConstants(), which defines some special values, and syntax, such as booster words, emphasize words and idioms. They are mainly used in the check method. The content of class VaderConstants() will be released later. 1. Method &quot;polarity_scores()&quot;: def polarity_scores(self, text): &quot;&quot;&quot; Return a float for sentiment strength based on the input text. Positive values are positive valence, negative value are negative valence. &quot;&quot;&quot; # text, words_and_emoticons, is_cap_diff = self.preprocess(text) sentitext = SentiText(text, self.constants.PUNC_LIST, self.constants.REGEX_REMOVE_PUNCTUATION) sentiments = [] words_and_emoticons = sentitext.words_and_emoticons for item in words_and_emoticons: # Traverse each takens as 'item' valence = 0 i = words_and_emoticons.index(item) # if we need index, why not &quot;for i, item in enumerate(words_and_emoticons):&quot; if ( i &lt; len(words_and_emoticons) - 1 and item.lower() == &quot;kind&quot; and words_and_emoticons[i + 1].lower() == &quot;of&quot; ) or item.lower() in self.constants.BOOSTER_DICT: # if exists &quot;kind of&quot; or current item is a &quot;booster word&quot; # current item (token) sentiment is 0 sentiments.append(valence) continue sentiments = self.sentiment_valence(valence, sentitext, item, i, sentiments) sentiments = self._but_check(words_and_emoticons, sentiments) return self.score_valence(sentiments, text) sentitext is a new instance of the class &quot;SentiText&quot;, which is a small class used to Identify sentiment-relevant string-level properties of input text and Clean the text. words_and_emoticons is a clean list of tokens without symbols, but emojis tokens are still retained. (This is also the significance of the existence of the _words_plus_punc() method when you call the _words_and_emoticons() in the SentiText class) Then we start to traverse the clean words_and_emoticons list, and then judge the sentiment value of each token in turn. If current word is &quot;kind&quot; and next word is &quot;of&quot; or the word is a booster word, the sentiment of the current word is 0. If the above special conditions do not exist, we continue to call another method sentiment_valence(valence, sentitext, item, i, sentiments). So far, the valence is 0; item is the current word; i is the index of current word in the text; sentiments is a list of sentiment values up to the previous word. When we get the list of sentiment values for all words, we call a but check method and update a new list of the sentiments. Finally, we return an answer generated by method score_valence(). So now we need to know what method sentiment_valence() and method score_valence() are Remember: we don't remove all stop words in this situation. And before calculating sentiment value, this method has already remove all puctuations in the text and all words with 1 letter. 2. Method &quot;sentiment_valence()&quot;: def sentiment_valence(self, valence, sentitext, item, i, sentiments): is_cap_diff = sentitext.is_cap_diff words_and_emoticons = sentitext.words_and_emoticons item_lowercase = item.lower() if item_lowercase in self.lexicon: # get the sentiment valence valence = self.lexicon[item_lowercase] # check if sentiment laden word is in ALL CAPS (while others aren't) if item.isupper() and is_cap_diff: if valence &gt; 0: valence += self.constants.C_INCR else: valence -= self.constants.C_INCR for start_i in range(0, 3): if ( i &gt; start_i and words_and_emoticons[i - (start_i + 1)].lower() not in self.lexicon ): # dampen the scalar modifier of preceding words and emoticons # (excluding the ones that immediately preceed the item) based # on their distance from the current item. s = self.constants.scalar_inc_dec( words_and_emoticons[i - (start_i + 1)], valence, is_cap_diff ) if start_i == 1 and s != 0: s = s * 0.95 if start_i == 2 and s != 0: s = s * 0.9 valence = valence + s valence = self._never_check( valence, words_and_emoticons, start_i, i ) if start_i == 2: valence = self._idioms_check(valence, words_and_emoticons, i) # future work: consider other sentiment-laden idioms # other_idioms = # {&quot;back handed&quot;: -2, &quot;blow smoke&quot;: -2, &quot;blowing smoke&quot;: -2, # &quot;upper hand&quot;: 1, &quot;break a leg&quot;: 2, # &quot;cooking with gas&quot;: 2, &quot;in the black&quot;: 2, &quot;in the red&quot;: -2, # &quot;on the ball&quot;: 2,&quot;under the weather&quot;: -2} valence = self._least_check(valence, words_and_emoticons, i) sentiments.append(valence) return sentiments Let's review the code when we are calling this method in the polarity_scores(). sentiments = self.sentiment_valence(valence, sentitext, item, i, sentiments) &quot;valence&quot; is 0; &quot;item&quot; is the current word; &quot;i&quot; is the index of current word in the text; &quot;sentiments&quot; is a list of sentiment values up to the previous word. Keep going on... is_cap_diff is a booling value. If it is True, the word list is a mixture of all uppercase words and ordinary words, such as ['HELLO','world']. However, if there is &quot;no total-uppercase words in the list&quot; or &quot;all words are total-uppercase, which leads to no emphasis on some individual words&quot;, it'll be False, such as ['Hello','World] or ['HELLO','WORLD']. words_and_emoticons is the clean token list of the text without puctuations. item_lowercase is the lowercase form of the current word. If the item_lowercase is not in lexicon (database), the valence of the current word is 0. If it is in our lexicon, then we can get the valence from our lexicon database. Then depending on the context, we will also slightly adjust its value. If the current word is total-uppercase and is_cap_diff is True, current word is a emphasis in the text, we need to add or substract a constant value C_INCR based on its valence. Next &quot;For&quot; loop is interesting, it updates the valence of the current word again based on the previous three words! Loop three times to see if the three words in front of the current word are in the lexicon database. Because all booster words are not in lexicon database, but in BOOSTER_DICT variable. scalar_inc_dec() method is to check if the preceding words increase, decrease, or negate/nullify the valence. (Check booster word, uppercase emphasis and currenr word's valence) _never_check(): Detection and corresponding schema, if &quot;never&quot; exists on previous three words. _idioms_check(): Detection and corresponding schema, if context 3 words make up an idiom. _least_check() Summary Step: Get basic valence of the current word from the lexicon database 1st update on valence (uppercase emphsis): if the current word is uppercased compared with other words, it is an emphsis word. Add or substract an scalar value C_INCR based on positive or negtive current valence. 2nd update on valence (context booster): if the previous three words exists booster words, which are included in BOOSTER_DICT, it is also an emphsis to current word. Calculate a scalar value and add or substract to current valence. Rule 1: The booster word also applies to uppercase emphsis rule. Rule 2: Neighboring word has 100% influence. Booster word that is two words distance away from the current has 95% influence. Similarly, three words distance has 90% influence. 3rd update on valence (context never) 4th update on valence (context idioms) 5th update on valence (context least) Append lastest current word's valence to the sentiments list. Remember: There are only 7502 token in the lexicon database.If the word in the text is not included in the lexicon database, it doesn't have valence (or sentiment / it is a nerual word). But these words may affect subsequent words' valence. 3. Method &quot;score_valence()&quot;: def score_valence(self, sentiments, text): if sentiments: sum_s = float(sum(sentiments)) # compute and add emphasis from punctuation in text punct_emph_amplifier = self._punctuation_emphasis(sum_s, text) if sum_s &gt; 0: sum_s += punct_emph_amplifier elif sum_s &lt; 0: sum_s -= punct_emph_amplifier compound = self.constants.normalize(sum_s) # discriminate between positive, negative and neutral sentiment scores pos_sum, neg_sum, neu_count = self._sift_sentiment_scores(sentiments) if pos_sum &gt; math.fabs(neg_sum): pos_sum += punct_emph_amplifier elif pos_sum &lt; math.fabs(neg_sum): neg_sum -= punct_emph_amplifier total = pos_sum + math.fabs(neg_sum) + neu_count pos = math.fabs(pos_sum / total) neg = math.fabs(neg_sum / total) neu = math.fabs(neu_count / total) else: compound = 0.0 pos = 0.0 neg = 0.0 neu = 0.0 sentiment_dict = { &quot;neg&quot;: round(neg, 3), &quot;neu&quot;: round(neu, 3), &quot;pos&quot;: round(pos, 3), &quot;compound&quot;: round(compound, 4), } return sentiment_dict If sentiments is not None: sum_s is the sum of all word valence in the sentiments list. punct_emph_amplifier is also a scalar that used to update sum_s value. It is based on counts of &quot;!&quot; and &quot;?&quot;. According to the overall sentiment value, add or substract punct_emph_amplifier value to the sum_s. compound is the normalize of sum_s. compound = sum_s/sqrt(sum_s^2+15) def normalize(self, score, alpha=15): &quot;&quot;&quot; Normalize the score to be between -1 and 1 using an alpha that approximates the max expected value &quot;&quot;&quot; norm_score = score / math.sqrt((score * score) + alpha) return norm_score _sift_sentiment_scores() def _sift_sentiment_scores(self, sentiments): # want separate positive versus negative sentiment scores pos_sum = 0.0 neg_sum = 0.0 neu_count = 0 for sentiment_score in sentiments: if sentiment_score &gt; 0: pos_sum += ( float(sentiment_score) + 1 ) # compensates for neutral words that are counted as 1 if sentiment_score &lt; 0: neg_sum += ( float(sentiment_score) - 1 ) # when used with math.fabs(), compensates for neutrals if sentiment_score == 0: neu_count += 1 return pos_sum, neg_sum, neu_count _sift_sentiment_scores() counts the number of pos, neg and neu words. And for pos words and neg words, their latest valences are also added into pos_sum and neg_sum. pos_sum, neg_sum and neu_count also need to be update based on punct_emph_amplifier. The sum of pos, neg and neu is one. Class &quot;SentiText&quot; class SentiText: &quot;&quot;&quot; Identify sentiment-relevant string-level properties of input text. &quot;&quot;&quot; def __init__(self, text, punc_list, regex_remove_punctuation): if not isinstance(text, str): text = str(text.encode(&quot;utf-8&quot;)) self.text = text self.PUNC_LIST = punc_list self.REGEX_REMOVE_PUNCTUATION = regex_remove_punctuation self.words_and_emoticons = self._words_and_emoticons() # doesn't separate words from # adjacent punctuation (keeps emoticons &amp; contractions) self.is_cap_diff = self.allcap_differential(self.words_and_emoticons) def _words_plus_punc(self): &quot;&quot;&quot; Returns mapping of form: { 'cat,': 'cat', ',cat': 'cat', } &quot;&quot;&quot; no_punc_text = self.REGEX_REMOVE_PUNCTUATION.sub(&quot;&quot;, self.text) # removes punctuation (but loses emoticons &amp; contractions) words_only = no_punc_text.split() # remove singletons words_only = set(w for w in words_only if len(w) &gt; 1) # the product gives ('cat', ',') and (',', 'cat') punc_before = {&quot;&quot;.join(p): p[1] for p in product(self.PUNC_LIST, words_only)} punc_after = {&quot;&quot;.join(p): p[0] for p in product(words_only, self.PUNC_LIST)} words_punc_dict = punc_before words_punc_dict.update(punc_after) return words_punc_dict def _words_and_emoticons(self): &quot;&quot;&quot; Removes leading and trailing puncutation Leaves contractions and most emoticons Does not preserve punc-plus-letter emoticons (e.g. :D) &quot;&quot;&quot; wes = self.text.split() words_punc_dict = self._words_plus_punc() wes = [we for we in wes if len(we) &gt; 1] for i, we in enumerate(wes): if we in words_punc_dict: wes[i] = words_punc_dict[we] return wes def allcap_differential(self, words): &quot;&quot;&quot; Check whether just some words in the input are ALL CAPS :param list words: The words to inspect :returns: `True` if some but not all items in `words` are ALL CAPS &quot;&quot;&quot; is_different = False allcap_words = 0 for word in words: if word.isupper(): allcap_words += 1 cap_differential = len(words) - allcap_words if 0 &lt; cap_differential &lt; len(words): is_different = True return is_different Class &quot;VaderConstants&quot; class VaderConstants: &quot;&quot;&quot; A class to keep the Vader lists and constants. &quot;&quot;&quot; ##Constants## # (empirically derived mean sentiment intensity rating increase for booster words) B_INCR = 0.293 B_DECR = -0.293 # (empirically derived mean sentiment intensity rating increase for using # ALLCAPs to emphasize a word) C_INCR = 0.733 N_SCALAR = -0.74 NEGATE = { &quot;aint&quot;, &quot;arent&quot;, &quot;cannot&quot;, &quot;cant&quot;, &quot;couldnt&quot;, &quot;darent&quot;, ..., } # booster/dampener 'intensifiers' or 'degree adverbs' # http://en.wiktionary.org/wiki/Category:English_degree_adverbs BOOSTER_DICT = { &quot;absolutely&quot;: B_INCR, &quot;amazingly&quot;: B_INCR, &quot;awfully&quot;: B_INCR, &quot;completely&quot;: B_INCR, &quot;considerably&quot;: B_INCR, &quot;decidedly&quot;: B_INCR, ... &quot;very&quot;: B_INCR, &quot;almost&quot;: B_DECR, &quot;barely&quot;: B_DECR, &quot;kind of&quot;: B_DECR, ... &quot;sort of&quot;: B_DECR, &quot;sorta&quot;: B_DECR, &quot;sortof&quot;: B_DECR, &quot;sort-of&quot;: B_DECR, } # check for special case idioms using a sentiment-laden keyword known to SAGE SPECIAL_CASE_IDIOMS = { &quot;the shit&quot;: 3, &quot;the bomb&quot;: 3, &quot;bad ass&quot;: 1.5, &quot;yeah right&quot;: -2, &quot;cut the mustard&quot;: 2, &quot;kiss of death&quot;: -1.5, &quot;hand to mouth&quot;: -2, } # for removing punctuation REGEX_REMOVE_PUNCTUATION = re.compile(&quot;[{0}]&quot;.format(re.escape(string.punctuation))) PUNC_LIST = [ &quot;.&quot;, &quot;!&quot;, &quot;?&quot;, &quot;,&quot;, &quot;;&quot;, &quot;:&quot;, &quot;-&quot;, &quot;'&quot;, '&quot;', &quot;!!&quot;, &quot;!!!&quot;, &quot;??&quot;, &quot;???&quot;, &quot;?!?&quot;, &quot;!?!&quot;, &quot;?!?!&quot;, &quot;!?!?&quot;, ] def __init__(self): pass def negated(self, input_words, include_nt=True): &quot;&quot;&quot; Determine if input contains negation words &quot;&quot;&quot; neg_words = self.NEGATE if any(word.lower() in neg_words for word in input_words): return True if include_nt: if any(&quot;n't&quot; in word.lower() for word in input_words): return True for first, second in pairwise(input_words): if second.lower() == &quot;least&quot; and first.lower() != &quot;at&quot;: return True return False def normalize(self, score, alpha=15): &quot;&quot;&quot; Normalize the score to be between -1 and 1 using an alpha that approximates the max expected value &quot;&quot;&quot; norm_score = score / math.sqrt((score * score) + alpha) return norm_score def scalar_inc_dec(self, word, valence, is_cap_diff): &quot;&quot;&quot; Check if the preceding words increase, decrease, or negate/nullify the valence &quot;&quot;&quot; scalar = 0.0 word_lower = word.lower() if word_lower in self.BOOSTER_DICT: scalar = self.BOOSTER_DICT[word_lower] if valence &lt; 0: scalar *= -1 # check if booster/dampener word is in ALLCAPS (while others aren't) if word.isupper() and is_cap_diff: if valence &gt; 0: scalar += self.C_INCR else: scalar -= self.C_INCR return scalar Database &quot;vader_lexicon.txt&quot; We can take a quick look at the contents of the file &quot;vader_lexicon.txt&quot;: $: -1.5 0.80623 [-1, -1, -1, -1, -3, -1, -3, -1, -2, -1] %) -0.4 1.0198 [-1, 0, -1, 0, 0, -2, -1, 2, -1, 0] %-) -1.5 1.43178 [-2, 0, -2, -2, -1, 2, -2, -3, -2, -3] &amp;-: -0.4 1.42829 [-3, -1, 0, 0, -1, -1, -1, 2, -1, 2] ... adorableness 2.5 0.67082 [2, 3, 3, 2, 3, 2, 1, 3, 3, 3] adorably 2.1 0.7 [3, 1, 2, 3, 2, 2, 1, 3, 2, 2] adoration 2.9 0.7 [3, 3, 3, 2, 3, 3, 4, 2, 4, 2] adorations 2.2 0.87178 [2, 2, 3, 1, 3, 1, 3, 3, 1, 3] ... The first column is words and emoticons, the second column is sentiment value. In class SentimentIntensityAnalyzer, method &quot;make_lex_dict()&quot; only uses the first two columns: word name and sentiment value. What does 3rd column and 4th column represent? How does these valence value come out? ","link":"https://zl-wu.github.io/post/text-analysis-nltks-vader-library/"},{"title":"Text Analysis -- TextBlob sentiment","content":"&quot;Topic: How to calculate sentiment value in TextBlob library?&quot; Topic: How to calculate sentiment value in TextBlob library? A Simple Example Code from textblob import TextBlob TextBlob(text).sentiment[0] Class TextBlob(BaseBlob) source code # textblob/blob.py class TextBlob(BaseBlob): &quot;&quot;&quot;A general text block, meant for larger bodies of text (esp. those containing sentences). Inherits from :class:`BaseBlob &lt;BaseBlob&gt;`. :param str text: A string. :param tokenizer: (optional) A tokenizer instance. If ``None``, defaults to :class:`WordTokenizer() &lt;textblob.tokenizers.WordTokenizer&gt;`. :param np_extractor: (optional) An NPExtractor instance. If ``None``, defaults to :class:`FastNPExtractor() &lt;textblob.en.np_extractors.FastNPExtractor&gt;`. :param pos_tagger: (optional) A Tagger instance. If ``None``, defaults to :class:`NLTKTagger &lt;textblob.en.taggers.NLTKTagger&gt;`. :param analyzer: (optional) A sentiment analyzer. If ``None``, defaults to :class:`PatternAnalyzer &lt;textblob.en.sentiments.PatternAnalyzer&gt;`. :param classifier: (optional) A classifier. &quot;&quot;&quot; @cached_property def sentences(self): &quot;&quot;&quot;Return list of :class:`Sentence &lt;Sentence&gt;` objects.&quot;&quot;&quot; return self._create_sentence_objects() @cached_property def words(self): &quot;&quot;&quot;Return a list of word tokens. This excludes punctuation characters. If you want to include punctuation characters, access the ``tokens`` property. :returns: A :class:`WordList &lt;WordList&gt;` of word tokens. &quot;&quot;&quot; return WordList(word_tokenize(self.raw, include_punc=False)) @property def raw_sentences(self): &quot;&quot;&quot;List of strings, the raw sentences in the blob.&quot;&quot;&quot; return [sentence.raw for sentence in self.sentences] @property def serialized(self): &quot;&quot;&quot;Returns a list of each sentence's dict representation.&quot;&quot;&quot; return [sentence.dict for sentence in self.sentences] def to_json(self, *args, **kwargs): '''Return a json representation (str) of this blob. Takes the same arguments as json.dumps. .. versionadded:: 0.5.1 ''' return json.dumps(self.serialized, *args, **kwargs) @property def json(self): '''The json representation of this blob. .. versionchanged:: 0.5.1 Made ``json`` a property instead of a method to restore backwards compatibility that was broken after version 0.4.0. ''' return self.to_json() def _create_sentence_objects(self): '''Returns a list of Sentence objects from the raw text. ''' sentence_objects = [] sentences = sent_tokenize(self.raw) char_index = 0 # Keeps track of character index within the blob for sent in sentences: # Compute the start and end indices of the sentence # within the blob start_index = self.raw.index(sent, char_index) char_index += len(sent) end_index = start_index + len(sent) # Sentences share the same models as their parent blob s = Sentence(sent, start_index=start_index, end_index=end_index, tokenizer=self.tokenizer, np_extractor=self.np_extractor, pos_tagger=self.pos_tagger, analyzer=self.analyzer, parser=self.parser, classifier=self.classifier) sentence_objects.append(s) return sentence_objects There is not attribute or method named &quot;sentiment&quot; in the class TextBlob, but we can see that it inherits class &quot;BaseBlob&quot; and has all the properties and methods of class BaseBlob. Therefore, we need to continue to search for BaseBlob content. Fortunately, we quickly found traces of sentiment. Class BaseBlob(StringlikeMixin, BlobComparableMixin) source code # textblob/blob.py class BaseBlob(StringlikeMixin, BlobComparableMixin): &quot;&quot;&quot;An abstract base class that all textblob classes will inherit from. Includes words, POS tag, NP, and word count properties. Also includes basic dunder and string methods for making objects like Python strings. .... &quot;&quot;&quot; np_extractor = FastNPExtractor() pos_tagger = NLTKTagger() tokenizer = WordTokenizer() translator = Translator() analyzer = PatternAnalyzer() parser = PatternParser() def __init__(self, text, tokenizer=None, ... ... @cached_property def sentiment(self): &quot;&quot;&quot;Return a tuple of form (polarity, subjectivity ) where polarity is a float within the range [-1.0, 1.0] and subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective. :rtype: namedtuple of the form ``Sentiment(polarity, subjectivity)`` &quot;&quot;&quot; return self.analyzer.analyze(self.raw) ... It declares the method sentiment as a property, which is convenient for users to call. And this method returns self.analyzer.analyze(self.raw), which is PatternAnalyzer().analyze(self.raw). Now what is PatternAnalyzer class? Look at the statement at the beginning of the document &quot;from textblob.sentiments import PatternAnalyzer&quot;, let's keep track of this class Class PatternAnalyzer(BaseSentimentAnalyzer) source code The path of this file: textblob/en/sentiments.py # textblob/en/sentiments.py class PatternAnalyzer(BaseSentimentAnalyzer): &quot;&quot;&quot;Sentiment analyzer that uses the same implementation as the pattern library. Returns results as a named tuple of the form: ``Sentiment(polarity, subjectivity, [assessments])`` where [assessments] is a list of the assessed tokens and their polarity and subjectivity scores &quot;&quot;&quot; kind = CONTINUOUS # This is only here for backwards-compatibility. # The return type is actually determined upon calling analyze() RETURN_TYPE = namedtuple('Sentiment', ['polarity', 'subjectivity']) def analyze(self, text, keep_assessments=False): &quot;&quot;&quot;Return the sentiment as a named tuple of the form: ``Sentiment(polarity, subjectivity, [assessments])``. &quot;&quot;&quot; #: Return type declaration if keep_assessments: Sentiment = namedtuple('Sentiment', ['polarity', 'subjectivity', 'assessments']) assessments = pattern_sentiment(text).assessments polarity, subjectivity = pattern_sentiment(text) return Sentiment(polarity, subjectivity, assessments) else: Sentiment = namedtuple('Sentiment', ['polarity', 'subjectivity']) return Sentiment(*pattern_sentiment(text)) Therefore, what is algorithm behind this two final commands? from collections import namedtuple from textblob.en import sentiment as pattern_sentiment Sentiment = namedtuple('Sentiment', ['polarity', 'subjectivity']) return Sentiment(*pattern_sentiment(text)) Google what is namedtuple if you don't know about it. So far, Sentiment is a empty tuple, and it is this statement &quot;Sentiment(*pattern_sentiment(text))&quot; that gives this tuple the correct value. pattern_sentiment is the alias of sentiment, which is in textblob.en.__init__.py type(pattern_sentiment) # textblob.en.Sentiment len(pattern_sentiment) # 2860 for k,v in pattern_sentiment.items(): print(k, v) ''' Output: ... absolute {'JJ': [0.2, 0.9, 1.0], None: [0.2, 0.9, 1.0]} absorbed {'JJ': [0.3, 0.9, 1.0], None: [0.3, 0.9, 1.0]} absorbing {'JJ': [0.2, 0.95, 1.0], None: [0.2, 0.95, 1.0]} absurd {'JJ': [-0.5, 1.0, 1.0], None: [-0.5, 1.0, 1.0]} ... ''' # textblob.en.__init__.py sentiment = Sentiment( path = os.path.join(MODULE, &quot;en-sentiment.xml&quot;), synset = &quot;wordnet_id&quot;, negations = (&quot;no&quot;, &quot;not&quot;, &quot;n't&quot;, &quot;never&quot;), modifiers = (&quot;RB&quot;,), modifier = lambda w: w.endswith(&quot;ly&quot;), tokenizer = parser.find_tokens, language = &quot;en&quot; ) Class Sentiment(lazydict) source code This class is in textblob/_text.py # textblob/_text.py ### SENTIMENT POLARITY LEXICON ##################################################################### # A sentiment lexicon can be used to discern objective facts from subjective opinions in text. # Each word in the lexicon has scores for: # 1) polarity: negative vs. positive (-1.0 =&gt; +1.0) # 2) subjectivity: objective vs. subjective (+0.0 =&gt; +1.0) # 3) intensity: modifies next word? (x0.5 =&gt; x2.0) # For English, adverbs are used as modifiers (e.g., &quot;very good&quot;). # For Dutch, adverbial adjectives are used as modifiers # (&quot;hopeloos voorspelbaar&quot;, &quot;ontzettend spannend&quot;, &quot;verschrikkelijk goed&quot;). # Negation words (e.g., &quot;not&quot;) reverse the polarity of the following word. # Sentiment()(txt) returns an averaged (polarity, subjectivity)-tuple. # Sentiment().assessments(txt) returns a list of (chunk, polarity, subjectivity, label)-tuples. # Semantic labels are useful for fine-grained analysis, e.g., # negative words + positive emoticons could indicate cynicism. class Sentiment(lazydict): def __init__(self, path=&quot;&quot;, language=None, synset=None, confidence=None, **kwargs): &quot;&quot;&quot; A dictionary of words (adjectives) and polarity scores (positive/negative). The value for each word is a dictionary of part-of-speech tags. The value for each word POS-tag is a tuple with values for polarity (-1.0-1.0), subjectivity (0.0-1.0) and intensity (0.5-2.0). &quot;&quot;&quot; .... ... def __call__(self, s, negation=True, **kwargs): &quot;&quot;&quot; Returns a (polarity, subjectivity)-tuple for the given sentence, with polarity between -1.0 and 1.0 and subjectivity between 0.0 and 1.0. The sentence can be a string, Synset, Text, Sentence, Chunk, Word, Document, Vector. An optional weight parameter can be given, as a function that takes a list of words and returns a weight. &quot;&quot;&quot; def avg(assessments, weighted=lambda w: 1): s, n = 0, 0 for words, score in assessments: w = weighted(words) s += w * score n += w return s / float(n or 1) # A pattern.en.wordnet.Synset. # Sentiment(synsets(&quot;horrible&quot;, &quot;JJ&quot;)[0]) =&gt; (-0.6, 1.0) if hasattr(s, &quot;gloss&quot;): a = [(s.synonyms[0],) + self.synset(s.id, pos=s.pos) + (None,)] # A synset id. # Sentiment(&quot;a-00193480&quot;) =&gt; horrible =&gt; (-0.6, 1.0) (English WordNet) # Sentiment(&quot;c_267&quot;) =&gt; verschrikkelijk =&gt; (-0.9, 1.0) (Dutch Cornetto) elif isinstance(s, basestring) and RE_SYNSET.match(s) and hasattr(s, &quot;synonyms&quot;): a = [(s.synonyms[0],) + self.synset(s.id, pos=s.pos) + (None,)] # A string of words. # Sentiment(&quot;a horrible movie&quot;) =&gt; (-0.6, 1.0) elif isinstance(s, basestring): a = self.assessments(((w.lower(), None) for w in &quot; &quot;.join(self.tokenizer(s)).split()), negation) # A pattern.en.Text. elif hasattr(s, &quot;sentences&quot;): a = self.assessments(((w.lemma or w.string.lower(), w.pos[:2]) for w in chain(*s)), negation) # A pattern.en.Sentence or pattern.en.Chunk. elif hasattr(s, &quot;lemmata&quot;): a = self.assessments(((w.lemma or w.string.lower(), w.pos[:2]) for w in s.words), negation) # A pattern.en.Word. elif hasattr(s, &quot;lemma&quot;): a = self.assessments(((s.lemma or s.string.lower(), s.pos[:2]),), negation) # A pattern.vector.Document. # Average score = weighted average using feature weights. # Bag-of words is unordered: inject None between each two words # to stop assessments() from scanning for preceding negation &amp; modifiers. elif hasattr(s, &quot;terms&quot;): a = self.assessments(chain(*(((w, None), (None, None)) for w in s)), negation) kwargs.setdefault(&quot;weight&quot;, lambda w: s.terms[w[0]]) # A dict of (word, weight)-items. elif isinstance(s, dict): a = self.assessments(chain(*(((w, None), (None, None)) for w in s)), negation) kwargs.setdefault(&quot;weight&quot;, lambda w: s[w[0]]) # A list of words. elif isinstance(s, list): a = self.assessments(((w, None) for w in s), negation) else: a = [] weight = kwargs.get(&quot;weight&quot;, lambda w: 1) # [(w, p) for w, p, s, x in a] return Score(polarity = avg( [(w, p) for w, p, s, x in a], weight ), subjectivity = avg([(w, s) for w, p, s, x in a], weight), assessments = a) def assessments(self, words=[], negation=True): &quot;&quot;&quot; Returns a list of (chunk, polarity, subjectivity, label)-tuples for the given list of words: where chunk is a list of successive words: a known word optionally preceded by a modifier (&quot;very good&quot;) or a negation (&quot;not good&quot;). &quot;&quot;&quot; a = [] m = None # Preceding modifier (i.e., adverb or adjective). n = None # Preceding negation (e.g., &quot;not beautiful&quot;). for w, pos in words: # Only assess known words, preferably by part-of-speech tag. # Including unknown words (polarity 0.0 and subjectivity 0.0) lowers the average. if w is None: continue if w in self and pos in self[w]: p, s, i = self[w][pos] # Known word not preceded by a modifier (&quot;good&quot;). if m is None: a.append(dict(w=[w], p=p, s=s, i=i, n=1, x=self.labeler.get(w))) # Known word preceded by a modifier (&quot;really good&quot;). if m is not None: a[-1][&quot;w&quot;].append(w) a[-1][&quot;p&quot;] = max(-1.0, min(p * a[-1][&quot;i&quot;], +1.0)) a[-1][&quot;s&quot;] = max(-1.0, min(s * a[-1][&quot;i&quot;], +1.0)) a[-1][&quot;i&quot;] = i a[-1][&quot;x&quot;] = self.labeler.get(w) # Known word preceded by a negation (&quot;not really good&quot;). if n is not None: a[-1][&quot;w&quot;].insert(0, n) a[-1][&quot;i&quot;] = 1.0 / a[-1][&quot;i&quot;] a[-1][&quot;n&quot;] = -1 # Known word may be a negation. # Known word may be modifying the next word (i.e., it is a known adverb). m = None n = None if pos and pos in self.modifiers or any(map(self[w].__contains__, self.modifiers)): m = (w, pos) if negation and w in self.negations: n = w else: # Unknown word may be a negation (&quot;not good&quot;). if negation and w in self.negations: n = w # Unknown word. Retain negation across small words (&quot;not a good&quot;). elif n and len(w.strip(&quot;'&quot;)) &gt; 1: n = None # Unknown word may be a negation preceded by a modifier (&quot;really not good&quot;). if n is not None and m is not None and (pos in self.modifiers or self.modifier(m[0])): a[-1][&quot;w&quot;].append(n) a[-1][&quot;n&quot;] = -1 n = None # Unknown word. Retain modifier across small words (&quot;really is a good&quot;). elif m and len(w) &gt; 2: m = None # Exclamation marks boost previous word. if w == &quot;!&quot; and len(a) &gt; 0: a[-1][&quot;w&quot;].append(&quot;!&quot;) a[-1][&quot;p&quot;] = max(-1.0, min(a[-1][&quot;p&quot;] * 1.25, +1.0)) # Exclamation marks in parentheses indicate sarcasm. if w == &quot;(!)&quot;: a.append(dict(w=[w], p=0.0, s=1.0, i=1.0, n=1, x=IRONY)) # EMOTICONS: {(&quot;grin&quot;, +1.0): set((&quot;:-D&quot;, &quot;:D&quot;))} if w.isalpha() is False and len(w) &lt;= 5 and w not in PUNCTUATION: # speedup for (type, p), e in EMOTICONS.items(): if w in imap(lambda e: e.lower(), e): a.append(dict(w=[w], p=p, s=1.0, i=1.0, n=1, x=MOOD)) break for i in range(len(a)): w = a[i][&quot;w&quot;] p = a[i][&quot;p&quot;] s = a[i][&quot;s&quot;] n = a[i][&quot;n&quot;] x = a[i][&quot;x&quot;] # &quot;not good&quot; = slightly bad, &quot;not bad&quot; = slightly good. a[i] = (w, p * -0.5 if n &lt; 0 else p, s, x) return a def annotate(self, word, pos=None, polarity=0.0, subjectivity=0.0, intensity=1.0, label=None): ... To be simply, the results returned from assessments method looks like: from textblob.en import sentiment as pattern_sentiment pattern_sentiment(text).assessments ''' Output: [(['accomplished'], 0.2, 0.5, None), (['internal'], 0.0, 0.0, None), (['internal'], 0.0, 0.0, None), (['particular'], 0.16666666666666666, 0.3333333333333333, None), (['useful'], 0.3, 0.0, None), (['other'], -0.125, 0.375, None), (['not', 'great'], -0.4, 0.75, None)] # The fist column is chunk word. (w) # The second column is polarity. (p) # The third column is subjectivity. (s) # The fourth column is label of the word. (x) ''' Then we know how __call__ methods works: def __call__(self, s, negation=True, **kwargs): def avg(assessments, weighted=lambda w: 1): s, n = 0, 0 for words, score in assessments: w = weighted(words) s += w * score n += w return s / float(n or 1) .... a = self.assessments(...) # the format of &quot;a&quot; is looks like the output above weight = kwargs.get(&quot;weight&quot;, lambda w: 1) # [(w, p) for w, p, s, x in a] return Score(polarity = avg( [(w, p) for w, p, s, x in a], weight ), subjectivity = avg([(w, s) for w, p, s, x in a], weight), assessments = a) We can easily find out that the whole text polarity and subjectivity are the weight average of polarity and subjectivity for each word. In fact, there are two main contributors that can make textblob's sentiment analysis accurate: Various rules in method assessments() of Sentiment class, which defines how to update the Polarity and Subjectivity values of the current word according to context. lexicon corpus building: en-sentiment.xml (textblob/en/en-sentiment.xml) online source Let's check out some interesting rules of textblob sentiment analysis First, the lexicon corpus contains 2860 words, and they are almost all adjective. But en-sentiment.xml has more records than 2860. Because some words have different polarities and subjectivities in different contexts. For example, there are 12 records belong to &quot;rich&quot;, and when textblob load this corpus, textblob average 12 polarities and 12 subjectivities to be the final polarity and subjectivity value of &quot;rich&quot;. The rules of textblob analysis are mainly in two aspects: modifier (i.e., adverb or adjective). negation (e.g., &quot;not beautiful&quot;) self.negations = kwargs.get(&quot;negations&quot;, (&quot;no&quot;, &quot;not&quot;, &quot;n't&quot;, &quot;never&quot;)) self.modifiers = kwargs.get(&quot;modifiers&quot;, (&quot;RB&quot;,)) self.modifier = kwargs.get(&quot;modifier&quot; , lambda w: w.endswith(&quot;ly&quot;)) If current word is a negation (&quot;no&quot;, &quot;not&quot;, &quot;n't&quot;, &quot;never&quot;): a = [] # result list m = None # Preceding modifier (i.e., adverb or adjective). n = None # Preceding negation (e.g., &quot;not beautiful&quot;). negation = True # default argument ########### Current Word is Known ########### ########### Rule 1 ########### # current Known word not preceded by a modifier (&quot;good&quot;). if m is None: a.append(dict(w=[w], p=p, s=s, i=i, n=1, x=self.labeler.get(w))) # normal append a dictionary ########### Rule 2 ########### # current Known word preceded by a modifier (&quot;really good&quot;). if m is not None: a[-1][&quot;w&quot;].append(w) # append modifier word to the latest word to become one new chunck token a[-1][&quot;p&quot;] = max(-1.0, min(p * a[-1][&quot;i&quot;], +1.0)) # new chunk token's original intensity times current word's polarity (control it between(-1.0, 1.0)) a[-1][&quot;s&quot;] = max(-1.0, min(s * a[-1][&quot;i&quot;], +1.0)) # same operation on the subjectivity a[-1][&quot;i&quot;] = i # i update to the current known word's intensity a[-1][&quot;x&quot;] = self.labeler.get(w) # x update to the current known word's label ########### Rule 3 ############ # current Known word preceded by a negation (&quot;not really good&quot;). if n is not None: a[-1][&quot;w&quot;].insert(0, n) # insert negation word to the latest word to be one chunck token a[-1][&quot;i&quot;] = 1.0 / a[-1][&quot;i&quot;] # the latest word's intensity becomes the original countdown a[-1][&quot;n&quot;] = -1 # set n is -1 ########### Rule 4 ########### # current Known word may be a negation. # current Known word may be modifying the next word (i.e., it is a known adverb). m = None # remove the influence from previous modifier (known or unknown word) n = None # remove the influence from previous negation (known or unknown word) if pos and pos in self.modifiers or any(map(self[w].__contains__, self.modifiers)): # if current known word is a modifier m = (w, pos) # assign (w, pos) tuple to m if negation and w in self.negations: # if current known word is a negation n = w # assign current word to n ########### Current Word is Unknown ########### ########### Rule 5 ############ # current Unknown word may be a negation (&quot;not good&quot;). if negation and w in self.negations: # if current unknown word is a negation n = w # assign current word to n # current Unknown word. Retain negation across small words (&quot;not a good&quot;). elif n and len(w.strip(&quot;'&quot;)) &gt; 1: # if previous word is a negation, and current word is more than on letter n = None # Reset n ########### Rule 6 ############ # Unknown word may be a negation preceded by a modifier (&quot;really not good&quot;). if n is not None and m is not None and (pos in self.modifiers or self.modifier(m[0])): # if modifier + negation a[-1][&quot;w&quot;].append(n) # append negation word to the latest word to become one new chunck token a[-1][&quot;n&quot;] = -1 n = None # reset n # Unknown word. Retain modifier across small words (&quot;really is a good&quot;). elif m and len(w) &gt; 2: m = None # Reset m ########### Rule 7 ############ # Exclamation marks boost previous word. if w == &quot;!&quot; and len(a) &gt; 0: a[-1][&quot;w&quot;].append(&quot;!&quot;) a[-1][&quot;p&quot;] = max(-1.0, min(a[-1][&quot;p&quot;] * 1.25, +1.0)) ########### Rule 8 ############ # Exclamation marks in parentheses indicate sarcasm. if w == &quot;(!)&quot;: a.append(dict(w=[w], p=0.0, s=1.0, i=1.0, n=1, x=IRONY)) ########### Rule 9 ############ # EMOTICONS: {(&quot;grin&quot;, +1.0): set((&quot;:-D&quot;, &quot;:D&quot;))} if w.isalpha() is False and len(w) &lt;= 5 and w not in PUNCTUATION: # speedup for (type, p), e in EMOTICONS.items(): if w in imap(lambda e: e.lower(), e): a.append(dict(w=[w], p=p, s=1.0, i=1.0, n=1, x=MOOD)) break st=&gt;start: Assessment:&gt;https://github.com/sloria/TextBlob/blob/e6cd9791ae42e37b5a2132676f9ca69340e8d8c0/textblob/_text.py#L854 e=&gt;end: Return a :&gt;http://www.google.com io1=&gt;inputoutput: Initialize a=[ ], m=None, n=None cond=&gt;condition: word in lexicon? &lt;!-- op1=&gt;operation: Initialize a, m, n --&gt; &lt;!-- sub1=&gt;subroutine: My Subroutine --&gt; op1=&gt;operation: Get word's p,s,i rule1=&gt;condition: m == None? r1yop=&gt;operation: append word dict to &quot;a&quot; r1nop=&gt;operation: a[-1][&quot;w&quot;].append(word), update p,s,i rule2=&gt;condition: n == None? r2nop=&gt;operation: a[-1][&quot;w&quot;].insert(0,n), update i, n op4=&gt;operation: reset m,n = None,None rule3=&gt;condition: word is modifier? r3yop=&gt;operation: m = w rule4=&gt;condition: word is negation? r4yop=&gt;operation: n = w io=&gt;inputoutput: catch something... para=&gt;parallel: parallel tasks st-&gt;io1-&gt;cond cond(yes)-&gt;op1-&gt;rule1 rule1(yes)-&gt;r1yop-&gt;rule2 rule1(no)-&gt;r1nop-&gt;rule2 rule2(yes)-&gt;op4 rule2(no)-&gt;r2nop-&gt;op4 op4-&gt;rule3 rule3(yes)-&gt;r3yop-&gt;rule4 rule3(no)-&gt;rule4 rule4(yes)-&gt;r4yop-&gt;e rule4(no)-&gt;e &lt;!-- cond(no)-&gt;para --&gt; &lt;!-- para(path1, bottom)-&gt;sub1(right)-&gt;op1 --&gt; &lt;!-- para(path2, top)-&gt;op1 --&gt; 'abc'.isalpha() ==&gt; True 'abc1'.isalpha() ==&gt; False 'abc:'.isalpha() ==&gt; False Sentiment.call() support lots of format ","link":"https://zl-wu.github.io/post/text-analysis-textblob-sentiment/"},{"title":"Git å¹¼å„¿å›­å…¥é—¨","content":"&quot;è¿™åªæ˜¯ä¸€ä¸ª Git æ–°æ‰‹åŸºç¡€å…¥é—¨ï¼ˆå¹¼å„¿å›­çº§åˆ«ï¼‰&quot; Git Mind map: VCSï¼ˆç‰ˆæœ¬ç®¡ç†ç³»ç»Ÿï¼‰å‘å±• æœåŠ¡å™¨æ–‡æ¡£å¼ï¼ˆVCSå‡ºç°ä¹‹å‰ï¼‰ é›†ä¸­å¼VCS åˆ†å¸ƒå¼VCS ï¼ˆGit [Linuxæ”¯ä»˜åˆ›é€ ] ï¼‰ Git çš„ç‰¹ç‚¹ æœ€ä¼˜çš„å‚¨å­˜èƒ½åŠ› éå‡¡çš„æ€§èƒ½ å¼€æº å¾ˆå®¹æ˜“åšå¤‡ä»½ æ”¯æŒç¦»çº¿æ“ä½œ å¾ˆå®¹æ˜“å®šåˆ¶å·¥ä½œæµç¨‹ DevOps å·¥å…·[å…¨æµç¨‹ç”Ÿå‘½å‘¨æœŸ] DevOps:æŒç»­äº¤ä»˜å®è·µ Git GitHub GitLab [ç¤¾åŒºç‰ˆæœ¬] å®‰è£…Git https://git-scm.com/download/mac https://git-scm.com/book/zh/v2 [ä¹¦] é…ç½®USER é…ç½® user.name å’Œ user.email $ git config --global user.name 'your_name' $ git config --global user.email 'your_email@domain.com' Why git need these? ä»£ç çš„æ¯ä¸€æ¬¡å˜æ›´æ—¶ï¼Œæ—¶é—´ç‚¹ä¸å˜æ›´äºº éƒ½æ˜¯ä¸å˜æ›´ä¿¡æ¯æ†ç»‘åœ¨ä¸€èµ·çš„ã€‚åœ¨Code Reviewæ—¶ï¼Œæ¯ä¸€æ¬¡å˜æ›´ä¿¡æ¯éƒ½å¸¦ä¸Šäº†ç”¨æˆ·çš„Emailåœ°å€ï¼Œè¯„å®¡äººå‘˜æŒ‡å‡ºè¯¥ç”¨æˆ·çš„å“ªä¸ªæ–‡ä»¶æœ‰é—®é¢˜æ—¶ï¼ŒGitç®¡æ§çš„Webç³»ç»Ÿä¼šå–å‡ºå˜æ›´è€…çš„Emailå¹¶å‘é€é‚®ä»¶ã€‚å¿…é¡»é…ç½®ï¼ï¼ --globalæœ‰ä»€ä¹ˆç”¨å‘¢ï¼Ÿ æ˜¯ä»€ä¹ˆæ„æ€å‘¢ï¼Ÿ configçš„ä¸‰ä¸ªä½œç”¨åŸŸ config å¯ä»¥é…ç½®è®¸å¤šä»“åº“å±æ€§ $ git config --local $ git config --global $ git config --system --local : åªå¯¹æŸä¸ªä»“åº“æœ‰æ•ˆ [ç™»å½•åˆ°æŸä¸€ä¸ªä»“åº“ å†è®¾ç½®è¯¥ä»“åº“] --global: å¯¹å½“å‰ç”¨æˆ·çš„æ‰€æœ‰ä»“åº“æœ‰æ•ˆ [å¦‚ç™»å½•Macç³»ç»Ÿçš„ç”¨æˆ·Wuçš„æ‰€æœ‰10ä¸ªä»“åº“ï¼Œå› æ­¤å˜æ›´äººä¿¡æ¯è®¾ç½®å¸¸ç”¨global] --system: å¯¹ç³»ç»Ÿçš„æ‰€æœ‰ç™»å½•ç”¨æˆ·æœ‰æ•ˆ [ä¸å¸¸ç”¨] æ˜¾ç¤ºconfigçš„é…ç½®ï¼ŒåŠ list $ git config --list --local fatal: --local can only be used inside a git repository $ git config --list --global filter.lfs.clean=git-lfs clean -- %f filter.lfs.smudge=git-lfs smudge -- %f filter.lfs.process=git-lfs filter-process filter.lfs.required=true user.email=wzhenglong@yahoo.com user.name=zhenglong $ git config --list --system fatal: unable to read config file '/etc/gitconfig': No such file or directory æ³¨æ„ï¼š--global å’Œ --listçš„ä½ç½®å¯ä»¥å¯¹è°ƒï¼Œæ— å½±å“ã€‚ å»ºç«‹Gitä»“åº“ ä¸¤ç§åœºæ™¯ï¼š æŠŠå·²æœ‰é¡¹ç›®ä»£ç çº³å…¥Gitç®¡ç† $ cd é¡¹ç›®ä»£ç æ‰€åœ¨çš„æ–‡ä»¶å¤¹ $ git init æ–°å»ºçš„é¡¹ç›®ç›´æ¥ç”¨Gitç®¡ç† $ cd æŸä¸ªæ–‡ä»¶å¤¹ $ git init your_project #åœ¨å½“å‰è·¯åŠ²ä¸‹åˆ›å»ºå’Œé¡¹ç›®åç§°åŒåçš„æ–‡ä»¶å¤¹ # è¯¥æ–‡ä»¶å¤¹å†…ä¼šå»ºç«‹ä¸€ä¸ªè£¸ä»“åº“ï¼Œä»¥.gitåç¼€ $ cd your_project æ¼”ç¤º $ git init git_learning Initialized empty Git repository in /Users/zhenglongwu/Desktop/Programming/Git/git_learning/.git/ $ cd git_learning $ ls -al total 0 drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 16:02 . drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 16:02 .. drwxr-xr-x 9 zhenglongwu staff 288 Sep 12 16:02 .git $ cd .git $ ls -al total 24 drwxr-xr-x 9 zhenglongwu staff 288 Sep 12 16:02 . drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 16:02 .. -rw-r--r-- 1 zhenglongwu staff 23 Sep 12 16:02 HEAD -rw-r--r-- 1 zhenglongwu staff 137 Sep 12 16:02 config -rw-r--r-- 1 zhenglongwu staff 73 Sep 12 16:02 description drwxr-xr-x 13 zhenglongwu staff 416 Sep 12 16:02 hooks drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 16:02 info drwxr-xr-x 4 zhenglongwu staff 128 Sep 12 16:02 objects drwxr-xr-x 4 zhenglongwu staff 128 Sep 12 16:02 refs æ¯”è¾ƒå±€éƒ¨é…ç½®ä¸å…¨å±€é…ç½® $ git config --list --global user.email=wzhenglong@yahoo.com user.name=zhenglong # å±€éƒ¨é…ç½® $ git config --local user.name 'user1' $ git config --local user.email '670362192@qq.com' $ git config --local --list user.name=user1 user.email=670362192@qq.com # åŸºæœ¬Gitæ“ä½œ # cp cp [-R [-H | -L | -P]] [-fi | -n] [-apvXc] source_file ... target_directory # cp [-R [-H | -L | -P]] [-fi | -n] [-apvXc] source_file target_file $ cp ../readme.txt . $ git commit -m'Add readme' On branch master Initial commit Untracked files: readme.txt nothing added to commit but untracked files present ## git commitæŠ¥é”™ å› ä¸ºæ²¡æœ‰è·Ÿè¸ªè¯¥æ–‡ä»¶ã€‚æˆ‘ä»¬éœ€è¦å…ˆè·Ÿè¸ªè¯¥æ–‡ä»¶ $ git add readme.txt $ git status On branch master No commits yet Changes to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: readme.txt $ git commit -m'Add readme' [master (root-commit) 61841ea] Add readme 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 readme.txt $ git log commit 61841eab81f0c26cfb9a884f4617169c0741c1fd (HEAD -&gt; master) Author: user1 &lt;670362192@qq.com&gt; Date: Thu Sep 12 19:14:42 2019 -0400 Add readme git add filename ==&gt; è¡¨ç¤ºæ–‡ä»¶æ·»åŠ åˆ°Gitçš„æš‚å­˜åŒºä¸­ï¼ŒGitå·²ç»å¯ä»¥å¼€å§‹ç®¡ç†è¿™ä¸ªæ–‡ä»¶äº†ï¼ˆåœ¨stageçš„çŠ¶æ€ï¼‰ã€‚åŒç†ï¼Œ (use &quot;git rm --cached ...&quot; to unstage) git commit git log ==&gt; æ‰“å°gitçš„æ—¥å¿—ï¼Œçœ‹commitæ˜¯å¦è¢«åˆ›å»ºå‡ºæ¥äº†ï¼ˆåŒ…æ‹¬å®Œæˆæäº¤çš„ä½œè€…ï¼Œé‚®ç®±[éƒ½æ˜¯localé…ç½®ä¼˜å…ˆ] å’Œæ—¶é—´ï¼‰ Gitçš„æš‚å­˜åŒºæ¦‚å¿µ æš‚å­˜åŒºåº”ç”¨åœºæ™¯ä¸¾ä¾‹ï¼š ä»£ç å†™å¥½åå…ˆå­˜å…¥æš‚å­˜åŒºå†…ï¼Œæ­¤æ—¶æœ‰ä¸€ç§é‡æ„çš„æƒ³æ³•å¹¶åœ¨å·¥ä½œç›®å½•æºä»£ç ä¸Šé‡æ„ï¼Œè‹¥é‡æ„å¤±è´¥ï¼Œå¯ä»æš‚å­˜åŒºä¸­å†è°ƒå›ä¹‹å‰çš„ç‰ˆæœ¬ã€‚[æš‚å­˜ï¼šæš‚æ—¶å­˜æ”¾ï¼Œä¸æ˜¯æ­£å¼æäº¤ã€‚å¯ä»¥è®©æˆ‘ä»¬å®éªŒä»£ç çš„å¤šç§å¯èƒ½æ€§ï¼Œä¿®æ­£åˆ°æœ€ä½³åå†æäº¤] æš‚å­˜ï¼šgit add files æ­£å¼æäº¤ï¼šgit commit $ cp ../css3-windy-switch/index.html index.html $ git status On branch master Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) index.html nothing added to commit but untracked files present (use &quot;git add&quot; to track) $ cp -r ../css3-windy-switch/css . $ cp -r ../css3-windy-switch/css javascript $ rm -r javascript $ cp -r ../css3-windy-switch/js javascript $ git status On branch master Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) css/ index.html javascript/ git status æ˜¯æœ€å¸¸ç”¨çš„ä¸€ä¸ªå‘½ä»¤ï¼Œæˆ‘ä»¬å¸¸å¸¸éƒ½éœ€è¦å»è¿è¡Œçœ‹çœ‹å½“å‰ç›®å½•çš„æƒ…å†µï¼Œä¸Šä¾‹å­ä¸­å‡ºç°äº†untracked files: index.htmlï¼Œæ˜¯åˆšå¤åˆ¶ç²˜è´´åˆ°æ–‡ä»¶å¤¹ï¼ˆGitçš„å½“å‰ä»“åº“ï¼‰ã€‚è‹¥è¦å°†è¿™ä¸ªindex.html çº³å…¥Gitç®¡ç†ï¼Œå…ˆè¦git add æ³¨æ„ï¼š git add å¯ä»¥æ·»åŠ å¤šä¸ªæ–‡ä»¶ï¼ˆåŒ…æ‹¬æ–‡ä»¶å¤¹ï¼‰ ä¸­é—´ç”¨ç©ºæ ¼éš”å¼€ git add è¦å†™æ–‡ä»¶åæˆ–è€…æ–‡ä»¶å¤¹å git commit åªè¦å†™æ­£å¼æäº¤çš„å¤‡æ³¨ï¼Œæ–¹ä¾¿åæœŸè¯»æ‡‚æäº¤ä»“åº“æ”¹åŠ¨çš„æ„ä¹‰ git add -u : åœ¨gitä»“åº“ä¸­æ‰€æœ‰è¢«Gitç®¡ç†äº†çš„æ–°ä¿®æ”¹æ–‡ä»¶ï¼ˆtrackedï¼‰ä¸€èµ·å†æäº¤åˆ°æš‚å­˜åŒºä¸­ Git æ–‡ä»¶é‡å‘½å # Method1: æ‰‹åŠ¨é‡å‘½åæ–¹æ³• $ mv readme.txt readme.md $ git status $ git add readme.md $ git rm readme.txt $ git status # Method2: ç”¨Gitçš„å¿«é€Ÿé‡å‘½åå‘½ä»¤ï¼ˆæ›´é«˜æ•ˆï¼‰ $ git mv readme.txt readme.md $ git status # æ­£å¼æäº¤ $ git commit -m'Move readme.txt to readme.md' $ git log Git logæŸ¥çœ‹ç‰ˆæœ¬æ¼”å˜å†å² # ä¾¿æ·æŸ¥çœ‹ï¼ˆå°†çœç•¥æäº¤äººä¿¡æ¯ï¼‰ $ git log --oneline # åªçœ‹æœ€è¿‘çš„4æ¬¡æˆ–æœ€è¿‘çš„2æ¬¡ $ git log -n4 --oneline $ git log -n2 --oneline # æŸ¥çœ‹å½“å‰çš„åˆ†æ”¯ $ git branch -v # åˆ›å»ºä¸€ä¸ªåˆ†æ”¯å«tempï¼Œåé¢çš„æ•°å­—æ˜¯éšæ„å¤åˆ¶æŸä¸€ä¸ªcommitçš„åœ°å€ï¼Œåœ¨è¿™ä¸ªåˆ†æ”¯ä¸­ï¼ŒåŒ…å«äº†åŒ…æ‹¬æ‰€å¤åˆ¶commitçš„æ‰€æœ‰ä¹‹å‰çš„commitæƒ…å†µã€‚ $ git checkout -b temp d4e1729be # å…¶ä¸­headå˜æˆäº†tempåˆ†æ”¯ã€‚ $ git log --oneline f9192c6 (HEAD -&gt; temp) Add test d4e1729 Add javasrcipt 7c13cfe Add index and css 61841ea Add readme # æŸ¥çœ‹masterçš„åˆ†æ”¯ $ git log master --oneline # --all æŸ¥çœ‹æ‰€æœ‰åˆ†æ”¯çš„æ¼”å˜ä¿¡æ¯(çˆ¶å­å…³ç³») $ git log --all --oneline # --graph å›¾å½¢åŒ–æŸ¥çœ‹ç‰ˆæœ¬æ¼”å˜ä¿¡æ¯ï¼Œä»å“ªä¸€æ­¥çš„ä»£ç æ›´æ–°å¼€å§‹äº§ç”Ÿåˆ†æ”¯ï¼Ÿ $ git log --all --oneline --graph Author &amp; Committer Author ä»£è¡¨ä½œè€… Committer ä»£è¡¨æäº¤äºº ä¸€èˆ¬æƒ…å†µä½œè€…å°±æ˜¯æäº¤äººã€‚ä½†æ˜¯å½“æŸäººéå¸¸å–œæ¬¢é¡¹ç›®ä¸­masteråˆ†æ”¯çš„ä¸€ä¸ªcommitï¼Œä»–æƒ³åŸºäºè¿™ä¸ªcommitåˆ›å»ºä¸€ä¸ªtempåˆ†æ”¯ç ”ç©¶ï¼Œæ­¤æ—¶ä¸ºäº†å°Šé‡ç‰ˆæƒã€‚æ­¤æ—¶åœ¨tempåˆ†æ”¯ä¸­å½“å‰Authorå°±æ˜¯åŸä½œè€…ï¼ŒCommiitterå°±æ˜¯ç ”ç©¶äººã€‚ # åˆ©ç”¨gltkå›¾å½¢åŒ–ç•Œé¢æŸ¥çœ‹gitç‰ˆæœ¬å†å² $ gitk # å¯ä»¥æŸ¥çœ‹æ¯ä¸€ä¸ªcommitçš„ï¼š # 1. Author # 2. Committer # 3. Parent ï¼š æœ€æ—©çš„commitæ²¡æœ‰parent # 4. Child ï¼š æœ€åçš„commitæ²¡æœ‰child # 5. Branches ï¼š æ‹¥æœ‰è¿™æ¡commitçš„æ‰€æœ‰åˆ†æ”¯ # 6. Follows # 7. Precedes # è®¾ç½®View: view ==&gt; New view ==&gt; All refs # ==&gt; Okåå¯ä»¥æŸ¥çœ‹æ‰€æœ‰åˆ†æ”¯ç‰ˆæœ¬æ¼”è¿›å†å² æ¢ç©¶ .git ç›®å½• $ cd .git $ ls -al total 56 drwxr-xr-x 14 zhenglongwu staff 448 Sep 14 20:57 . drwxr-xr-x 9 zhenglongwu staff 288 Sep 12 21:29 .. -rw-r--r-- 1 zhenglongwu staff 9 Sep 12 21:09 COMMIT_EDITMSG -rw-r--r-- 1 zhenglongwu staff 21 Sep 12 21:06 HEAD -rw-r--r-- 1 zhenglongwu staff 41 Sep 12 20:49 ORIG_HEAD -rw-r--r-- 1 zhenglongwu staff 184 Sep 12 16:10 config -rw-r--r-- 1 zhenglongwu staff 73 Sep 12 16:02 description -rw-r--r-- 1 zhenglongwu staff 461 Sep 14 20:57 gitk.cache drwxr-xr-x 13 zhenglongwu staff 416 Sep 12 16:02 hooks -rw-r--r-- 1 zhenglongwu staff 792 Sep 12 21:09 index drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 16:02 info drwxr-xr-x 4 zhenglongwu staff 128 Sep 12 19:14 logs drwxr-xr-x 28 zhenglongwu staff 896 Sep 12 21:09 objects drwxr-xr-x 4 zhenglongwu staff 128 Sep 12 16:02 refs # .git/HEADæ–‡ä»¶ï¼š $ cat head ref: refs/heads/temp # refä»£è¡¨ä¸€ä¸ªå¼•ç”¨ï¼Œå¼•ç”¨åˆ°tempåˆ†æ”¯,ç»§ç»­æ£€æŸ¥ $ git branch -av master 4ba1df1 Move readme.txt to readme.md * temp f9192c6 Add test ## *å·ä»£è¡¨å½“å‰çš„å·¥ä½œåŒºåœ¨å“ªä¸€ä¸ªåˆ†æ”¯ä¸Š ## å› æ­¤HEADçš„å†…å®¹å«ä¹‰ä»£è¡¨ æˆ‘ä»¬å½“å‰æ­£åœ¨å·¥ä½œçš„Gitåˆ†æ”¯æ˜¯temp ## å®éªŒï¼š åˆ‡æ¢åˆ°masteråˆ†æ”¯å†æŸ¥çœ‹HEADæ–‡ä»¶ $ git checkout master fatal: this operation must be run in a work tree $ cd .. $ git checkout master Switched to branch 'master' $ cd - /Users/zhenglongwu/Desktop/Programming/Git/git_learning/.git $ cat head ref: refs/heads/master ## å¤‡æ³¨ï¼š git checkout å‘½ä»¤å°±æ˜¯åˆ‡æ¢åˆ†æ”¯ ## ç»“è®ºï¼š HEADçš„æ–‡ä»¶å†…å®¹ä¼šæ ¹æ®åˆ‡æ¢åˆ†æ”¯è€Œæ”¹å˜ï¼Œå®ƒå‘Šè¯‰æˆ‘ä»¬å½“å‰æ­£åœ¨å·¥ä½œçš„æ˜¯å“ªä¸ªåˆ†æ”¯ã€‚ # .git/config æ–‡ä»¶ $ cat config [core] repositoryformatversion = 0 filemode = true bare = false logallrefupdates = true ignorecase = true precomposeunicode = true [user] name = user1 email = 670362192@qq.com ## Gitçš„localç”¨æˆ·åè®¾ç½®å°±è®°å½•åœ¨ä»“åº“çš„configæ–‡ä»¶ä¸­ã€‚ ## å®éªŒï¼Œä¿®æ”¹username $ vi config $ cat config ... [user] name = userlong email = 670362192@qq.com $ git config --local --list core.repositoryformatversion=0 core.filemode=true core.bare=false core.logallrefupdates=true core.ignorecase=true core.precomposeunicode=true user.name=userlong user.email=670362192@qq.com $ git config --local user.name userlong # åå‘æ›´æ”¹ $ git config --local user.name 'long' $ git config --local user.name long $ cat config ... [user] name = long email = 670362192@qq.com ## ç»“è®ºï¼šconfigæ–‡ä»¶å°±æ˜¯å‚¨å­˜æ‰€æœ‰ä¸æœ¬åœ°ä»“åº“ç›¸å…³çš„é…ç½®ä¿¡æ¯ã€‚ # .git/refs/ æ–‡ä»¶å¤¹æ¢ç©¶ $ cd refs $ ls -al total 0 drwxr-xr-x 4 zhenglongwu staff 128 Sep 12 16:02 . drwxr-xr-x 14 zhenglongwu staff 448 Sep 14 21:35 .. drwxr-xr-x 4 zhenglongwu staff 128 Sep 12 21:09 heads drwxr-xr-x 2 zhenglongwu staff 64 Sep 12 16:02 tags ## tagsä¹Ÿè¢«ç§°ä½œé‡Œç¨‹ç¢‘ï¼Œæ¯”å¦‚å½“å‰é¡¹ç›®å¼€å‘åˆ°V1.0äº†ï¼Œå¯ä»¥åŠ ä¸€ä¸ªæ ‡ç­¾æ‰“ä¸€ä¸ªæ ‡è¯† ## headså¯¹åº”äºæ‰€æœ‰åˆ†æ”¯ï¼Œåˆ†æ”¯ä»£è¡¨çš„æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„å¼€å‘ç©ºé—´ã€‚æ¯”å¦‚å¼€å‘è½¯ä»¶æ—¶æœ‰å‰ç«¯å¼€å‘å’Œåç«¯å¼€å‘ï¼Œæ­¤æ—¶å‰ç«¯å¯ä»¥åˆ›å»ºä¸€ä¸ªåˆ†æ”¯ï¼Œåç«¯å»ºä¸€ä¸ªåˆ†æ”¯ã€‚ å½¼æ­¤åœ¨è‡ªå·±çš„ç©ºé—´é‡Œå·¥ä½œæ˜¯äº’ä¸å½±å“çš„ã€‚é›†æˆæ—¶åˆå¯ä»¥é›†æˆåˆ°ä¸€ä¸ªå…¬å…±çš„åˆ†æ”¯ä¸Šã€‚ ### å†æŒ– .git/refs/heads/æ–‡ä»¶å¤¹ $ cd heads $ ls -al total 16 drwxr-xr-x 4 zhenglongwu staff 128 Sep 12 21:09 . drwxr-xr-x 4 zhenglongwu staff 128 Sep 12 16:02 .. -rw-r--r-- 1 zhenglongwu staff 41 Sep 12 20:52 master -rw-r--r-- 1 zhenglongwu staff 41 Sep 12 21:09 temp $ cat master 4ba1df1b3b40dae8540c01b81f947a0b4b3d8c1c ## headsæ–‡ä»¶å¤¹é‡Œå­˜æ”¾æ‰€æœ‰çš„åˆ†æ”¯ï¼Œmasteræ–‡ä»¶å­˜çš„æ˜¯ä¸€ä¸ªHASHå€¼ä»£è¡¨è¿™ä¸ªmasteræœ€åä¸€æ¬¡commitçš„æŒ‡é’ˆ $ git cat-file -t 4ba1df1b3b40dae commit ## cat-file -t æŸ¥çœ‹å½“å‰å“ˆå¸Œå€¼çš„objectæ˜¯ä»€ä¹ˆç±»å‹ï¼Œæ˜¯ä¸€ä¸ªcommit ## æŸ¥çœ‹å½“å‰æ‰€æœ‰åˆ†æ”¯æœ€æ–°commitæƒ…å†µ $ git branch -av * master 4ba1df1 Move readme.txt to readme.md temp f9192c6 Add test ## 4ba1df1æ˜¯çŸ­hashå€¼ï¼Œä¸€èˆ¬å¤Ÿç”¨ï¼Œå½“çŸ­çš„ä¸å¤Ÿç”¨æ—¶ï¼ˆäº§ç”Ÿé‡å¤æ—¶ï¼‰å†ç”¨æ›´é•¿ä¸€ç‚¹çš„ã€‚ $ cat temp f9192c679da9f6ff44f20c81d1d8ba0fb381193a ## åŒç†å¯çœ‹å‡ºtempæ–‡ä»¶é‡Œå­˜çš„ä¹Ÿæ˜¯tempåˆ†æ”¯ä¸­æœ€åä¸€æ¬¡commitçš„å“ˆå¸Œå€¼ ### ç»§ç»­æŒ– .git/refs/tags/æ–‡ä»¶å¤¹ $ cd tags $ ls -al total 8 drwxr-xr-x 3 zhenglongwu staff 96 Sep 14 23:41 . drwxr-xr-x 4 zhenglongwu staff 128 Sep 12 16:02 .. -rw-r--r-- 1 zhenglongwu staff 41 Sep 14 23:41 js01 ## æœ‰ä¸€ä¸ªtagï¼šjs01ï¼Œ è¯»å®ƒ $ cat js01 b7e1bfaf5787edb14f14981df2d32530792d83fa $ git cat-file -t b7e1 tag ## å¤‡æ³¨ï¼šå¯ä»¥å°‘è¾“å…¥å‡ ä½hashå€¼ï¼Œåªè¦èƒ½è¯†åˆ«å‡ºå”¯ä¸€çš„å€¼ã€‚ ## åŠ -p æ·±æŒ–è¿™ä¸ªhashå€¼ä»£è¡¨çš„ä¸œè¥¿ $ git cat-file -p b7e1 object d4e1729be6ec1d96e1068171e5d355b09ae5e3e7 type commit tag js01 tagger long &lt;670362192@qq.com&gt; 1568518864 -0400 js demo ## ç»§ç»­æŒ–è¿™ä¸ªobject d4e1729be6ec1d96e1068171e5d355b09ae5e3e7æ˜¯ä»€ä¹ˆ? æ˜¯ä¸€ä¸ªcommit $ git cat-file -t d4e1 commit $ git cat-file -p d4e1 tree 9c640279d65a23da23454864b9f96adb59cb3bec parent 7c13cfe19f0c14585b0629c1095b58be53cdc7cc author user1 &lt;670362192@qq.com&gt; 1568334269 -0400 committer user1 &lt;670362192@qq.com&gt; 1568334269 -0400 Add javasrcipt ###å› æ­¤js01æ–‡ä»¶é‡Œå­˜æ”¾çš„hashå€¼ä»£è¡¨ä¸€ä¸ªtagï¼Œè¿™ä¸ªtagçš„hashå€¼é‡Œå­˜æ”¾äº†ä¸€ä¸ªå¯¹è±¡ï¼Œè¿™ä¸ªå¯¹è±¡çš„hashå€¼ä»£è¡¨ä¸€ä¸ªcommit git cat-file -t HASHå€¼ï¼š è¯»å–å½“å‰hashå€¼ä»£è¡¨çš„objectç±»å‹ git cat-file -p HASHå€¼ï¼š è¯»å–å½“å‰hashå€¼ä»£è¡¨çš„objecté‡Œé¢å­˜æ”¾çš„ä¸œè¥¿ï¼ˆåº”è¯¥æœ‰å„ç§å±æ€§å’Œä»£è¡¨å…¶å®ƒobjectçš„hashå€¼ï¼‰ .git/refs/headsï¼š å­˜æ”¾æ‰€æœ‰åˆ†æ”¯ .git/refs/heads/masterï¼šmasteråˆ†æ”¯æœ€åä¸€æ¬¡commitçš„hashå€¼ .git/refs/heads/tempï¼štempåˆ†æ”¯æœ€åä¸€æ¬¡commitçš„hashå€¼ .git/refs/tagsï¼š é‡Œç¨‹ç¢‘ï¼Œå­˜æ”¾å¯¹æŸä¸€æ¬¡ç‰¹æ®Šæ„ä¹‰commit çš„æ ‡è®° .git/refs/tags/js01ï¼š åå«js01çš„æ ‡è®°ï¼Œè¯¥æ–‡ä»¶è®°å½•çš„hashå€¼é‡Œå­˜æ”¾äº†å¦ä¸€ä¸ªcommitå¯¹è±¡çš„hashå€¼ï¼Œä¹Ÿå°±æ˜¯æ ‡è®°çš„commitã€‚ ## !!é‡ç‚¹: .git/objects/ æ–‡ä»¶å¤¹çš„æ¢ç©¶ $ cd objects $ ls -al total 0 drwxr-xr-x 29 zhenglongwu staff 928 Sep 14 23:41 . drwxr-xr-x 14 zhenglongwu staff 448 Sep 14 21:35 .. .... drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 19:14 77 drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 20:17 7c drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 20:24 7f drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 21:09 8c .... drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 20:29 fb drwxr-xr-x 2 zhenglongwu staff 64 Sep 12 16:02 info drwxr-xr-x 2 zhenglongwu staff 64 Sep 12 16:02 pack ## å¯ä»¥çœ‹å‡ºæœ‰ä¸¤ç§ç±»å‹çš„æ–‡ä»¶å¤¹ï¼Œ ## ä¸€ç§æ˜¯åªæœ‰2ä¸ªå­—æ¯çš„å¤§éƒ¨åˆ†æ–‡ä»¶å¤¹ ## å¦ä¸€ç§æ˜¯packæ–‡ä»¶å¤¹ï¼šGitä¼šåšè‡ªæˆ‘æ¢³ç†è¿‡ç¨‹ï¼Œå½“æ¾æ•£æ–‡ä»¶è¿‡å¤šæ—¶ä¼šæ‰“åŒ…åˆ°è¿™é‡Œ ### 1.å…ˆæ·±æŒ–ä¸¤å­—ç¬¦çš„æ–‡ä»¶å¤¹ .git/objects/77/ $ cd 77 $ ls -al total 8 drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 19:14 . drwxr-xr-x 29 zhenglongwu staff 928 Sep 14 23:41 .. -r--r--r-- 1 zhenglongwu staff 55 Sep 12 19:14 37016481fd9dbdf0ec0d9145d56358fd71feb2 ##è§£è¯»ï¼šæ–‡ä»¶å¤¹é‡Œæœ‰ä¸€å †ç±»ä¼¼hashå€¼å¾—ä¸œè¥¿ï¼š37016481fd9dbdf0ec0d9145d56358fd71feb2ã€‚ä½†æ˜¯å®ƒä¸æ˜¯å®Œæ•´çš„hashå€¼ï¼Œå®ƒè¿˜ç¼ºå°‘å¼€å¤´ä¸¤ä¸ªå­—ç¬¦--æ–‡ä»¶å¤¹çš„åå­—ï¼Œå› æ­¤è¿™ä¸²å®Œæ•´çš„hashå€¼è¦åœ¨å¼€å¤´åŠ ä¸Š77ï¼š 7737016481fd9dbdf0ec0d9145d56358fd71feb2 $ git cat-file -t 7737016481 tree $ git cat-file -p 773701 100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 readme.txt ## è§£è¯»ï¼šè¿™ä¸²hashå€¼ä»£è¡¨ä¸€ä¸ªtreeç±»å‹çš„objectï¼Œé‡Œé¢å­˜æ”¾äº†ä¸€ä¸ªæ–‡ä»¶ readme.txtã€‚æ–‡ä»¶çš„hashå€¼æ˜¯e69de29bb2d1d6....ï¼Œ è¿™ä¸ªæ–‡ä»¶åœ¨gité‡Œè¡¨ç¤ºçš„ç±»å‹æ˜¯blob--æ–‡ä»¶å¯¹è±¡ã€‚ ## æˆ‘ä»¬å†ä»¥æ–‡ä»¶å¤¹7fä¸ºä¾‹ï¼š $ ls -al 7f total 8 drwxr-xr-x 3 zhenglongwu staff 96 Sep 12 20:24 . drwxr-xr-x 29 zhenglongwu staff 928 Sep 14 23:41 .. -r--r--r-- 1 zhenglongwu staff 122 Sep 12 20:24 0153aaaa90651214e53926593e375803742ad5 $ git cat-file -t 7f0153aaaa tree $ git cat-file -p 7f0153aaaa 100644 blob c8984ae212db84b4a95e983e0af8e33215c41ec7 .DS_Store 100644 blob 230bfa8af0829fdffd7f78bf0dda6b851e482bd8 index.js 100644 blob 4d9b3a258759c53e7bc66b6fc554c51e2434437c jquery.min.js $ git cat-file -t 230bfa8a blob $ git cat-file -p 230bfa8a $(&quot;#switch&quot;).on('click', function () { if ($(&quot;body&quot;).hasClass(&quot;slow-wind&quot;)) { $(&quot;body&quot;).removeClass(&quot;slow-wind&quot;); $(&quot;#switch&quot;).removeClass(&quot;switched&quot;); } ## ç»“è®ºï¼šblobå°±æ˜¯gitçš„æ–‡ä»¶ç±»å‹ï¼Œå¹¶ä¸”ä½¿ç”¨git cat-file -p HASHå€¼ å¯ä»¥ç›´æ¥æ‰“å¼€æ–‡ä»¶å†…çš„è®°å½•å†…å®¹ã€‚ åˆ°ç°åœ¨ä¸ºæ­¢æ¥è§¦åˆ°çš„æ‰€æœ‰Gitçš„æ•°æ®ç±»å‹ï¼š(ä¹Ÿæ˜¯æ¥è§¦æœ€å¤šçš„æ ¸å¿ƒ4ç±»å‹) commit tag tree blob Gitç›®å½•æ€»ç»“ï¼šï¼ˆå¸¸ç”¨çš„ï¼‰ ./git/HEAD æ–‡ä»¶ï¼š å½“å‰å·¥ä½œçš„gitä»“åº“åˆ†æ”¯. ç›´æ¥ä¿®æ”¹å…¶å†…å®¹ä¸ git checkout å‘½ä»¤åŒæ ·æ•ˆæœã€‚ ./git/config æ–‡ä»¶ï¼š å½“å‰çš„localä»“åº“æ‰€æœ‰åˆ†æ”¯çš„é…ç½®ï¼Œç›´æ¥ä¿®æ”¹æ–‡ä»¶å†…å®¹ä¸ git config --local user.name '' ä¸€æ ·æ•ˆæœ ./git/refs æ–‡ä»¶å¤¹ï¼š å­˜æ”¾å„ä¸ªåˆ†æ”¯æœ€æ–°commit å’Œ tagé‡Œç¨‹ç¢‘ä¿¡æ¯ ./git/objects æ–‡ä»¶å¤¹ï¼šå­˜æ”¾gitä¸­æ‰€æœ‰çš„æ•°æ®å¯¹åº”çš„hashå€¼ã€‚ï¼ˆåªè¦ä»“åº“ä¸­ä¸¤æ–‡ä»¶çš„å†…å®¹ä¸€æ¨¡ä¸€æ ·ï¼Œåœ¨gitçœ¼é‡Œå®ƒå°±æ˜¯ä¸€ä¸ªæ–‡ä»¶ï¼Œç„¶ååªæœ‰ä¸€ä¸ªhashå€¼ä»£è¡¨è¿™ä¸ªæ–‡ä»¶ï¼Ÿï¼‰ commitã€treeã€blobä¸‰ä¸ªå¯¹è±¡ä¹‹é—´çš„å…³ç³» å­˜å‚¨æ˜¯gitçš„æ ¸å¿ƒæŠ€æœ¯ç‚¹ã€‚ç‰ˆæœ¬ç®¡ç†ç³»ç»Ÿä¸­ï¼Œæ–‡ä»¶çš„å˜æ›´æ˜¯éå¸¸é¢‘ç¹çš„ï¼Œæ‰€ä»¥è®¾è®¡ä¸€ä¸ªè‰¯å¥½æ–‡ä»¶å‚¨å­˜æœºåˆ¶å¯¹äºç‰ˆæœ¬ç®¡ç†ç³»ç»Ÿæ˜¯éå¸¸å…³é”®çš„ï¼Œå¦åˆ™ç‰ˆæœ¬ç®¡ç†ä¼šè¶Šæ¥è¶Šæ··ä¹±ã€‚ ä¸€ä¸ªcommitå¯¹åº”ä¸”ä»…å¯¹åº”ä¸€é¢—æ ‘ï¼Œ è¿™é¢—æ ‘ä»£è¡¨å½“å‰commitå¯¹åº”çš„ä¸€ä¸ªè§†å›¾å¿«ç…§ï¼Œå°±æ˜¯åœ¨å½“æ—¶é‚£ä¸ªæ—¶é—´ç‚¹æ—¶ï¼Œé¡¹ç›®æ‰€æœ‰çš„æ–‡ä»¶å¤¹å’Œæ–‡ä»¶çš„æ ·å­ã€‚ ä¸€ä¸ªcommité‡ŒåŒ…å«äº†ä¸€æ£µæ ‘ï¼ˆé¡¹ç›®æ–‡ä»¶å¤¹æ•´ä½“å¿«ç…§ï¼‰ï¼Œparentï¼ˆä¸Šä¸€ä¸ªcommitï¼‰ï¼Œauthorï¼ˆä½œè€…ï¼‰ï¼Œcommitterï¼ˆæäº¤äººï¼‰å››è€…çš„å¯¹åº”Hashå€¼ï¼Œç„¶ååŠ ä¸Šcommitæ—¶çš„messageä¿¡æ¯ã€‚ ä¸€æ£µæ ‘treeé‡ŒåŒ…å«äº†å…¶å®ƒæ ‘ï¼ˆæ–‡ä»¶å¤¹ï¼‰å’Œ blobï¼ˆæ–‡ä»¶ï¼‰çš„å¯¹åº”hashå€¼ å…¶å®ƒæ ‘treeé‡Œä¾ç„¶åŒ…å«äº†å…¶å®ƒæ ‘ï¼ˆå­æ–‡ä»¶å¤¹ï¼‰ å’Œ blobï¼ˆæ–‡ä»¶ï¼‰çš„å¯¹åº”hashå€¼ blobï¼ˆæ–‡ä»¶ï¼‰é‡Œä»…åŒ…å«æ–‡ä»¶çš„å†…å®¹ å› æ­¤ï¼š commitä»…å‚¨å­˜å¿«ç…§treeï¼Œparentï¼Œauthorï¼Œcommitterçš„hashå€¼ å’Œ commitæ—¶é™„åŠ çš„è§£é‡Šä¿¡æ¯ treeä¸­ä»…å‚¨å­˜ tree å’Œ blob çš„ hashå€¼ blobä¸­å°±å‚¨å­˜ æ–‡ä»¶çš„å†…å®¹ä¿¡æ¯ã€‚ï¼ˆé€šè¿‡blobçš„hashå€¼è¯»æ–‡ä»¶ï¼‰ï¼ˆæ³¨æ„ï¼Œblobå’Œæ–‡ä»¶åä¸€ç‚¹å…³ç³»éƒ½æ²¡æœ‰ï¼Œåªè¦æ–‡ä»¶çš„å†…å®¹ç›¸åŒï¼Œä¸ç®¡æ–‡ä»¶åå«ä»€ä¹ˆï¼Œéƒ½åªæ˜¯ä¸€ä¸ªä¸œè¥¿ï¼‰ # ä»£ç å®éªŒ $ git branch -av * master 4ba1df1 Move readme.txt to readme.md temp f9192c6 Add test $ git log ... commit d4e1729be6ec1d96e1068171e5d355b09ae5e3e7 (tag: js01) Author: user1 &lt;670362192@qq.com&gt; Date: Thu Sep 12 20:24:29 2019 -0400 Add javasrcipt ... # è¯»å–commitçš„hashå€¼ $ git cat-file -p d4e1729be6ec tree 9c640279d65a23da23454864b9f96adb59cb3bec parent 7c13cfe19f0c14585b0629c1095b58be53cdc7cc author user1 &lt;670362192@qq.com&gt; 1568334269 -0400 committer user1 &lt;670362192@qq.com&gt; 1568334269 -0400 Add javasrcipt $ ls .git/objects/d4 e1729be6ec1d96e1068171e5d355b09ae5e3e7 # è¯»å–treeçš„hashå€¼ $ git cat-file -p 9c640279d6 040000 tree e4addc26befad478e734cb7f6919cde05fe70aa6 css 100644 blob 726ecbd247e7b0156bf6a5e39dc9ce0b1048818c index.html 040000 tree 7f0153aaaa90651214e53926593e375803742ad5 javascript 100644 blob e69de29bb2d1d6434b8b29ae775ad8c2e48c5391 readme.txt $ ls .git/objects/9c 640279d65a23da23454864b9f96adb59cb3bec # è¯»å–blobçš„hashå€¼ $ git cat-file -p 726ecbd247 &lt;!DOCTYPE html&gt; &lt;html lang=&quot;en&quot; &gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; ... &lt;/body&gt; &lt;/html&gt; $ ls .git/objects/72 6ecbd247e7b0156bf6a5e39dc9ce0b1048818c Git å‘½ä»¤æ·±åº¦è§£æï¼ˆæ•°ä¸€æ•°treeçš„ä¸ªæ•°ï¼‰ # å»ºç«‹ä»“åº“ $ git init count_tree $ cd count_tree $ ls -al .git/objects total 0 drwxr-xr-x 4 zhenglongwu staff 128 Sep 18 23:22 . drwxr-xr-x 10 zhenglongwu staff 320 Sep 18 23:22 .. drwxr-xr-x 2 zhenglongwu staff 64 Sep 18 23:22 info drwxr-xr-x 2 zhenglongwu staff 64 Sep 18 23:22 pack ## ç©ºä»“åº“ï¼Œæ²¡æœ‰ä»»ä½•å¯¹è±¡ ## åˆ›å»ºä¸€ä¸ªæ–‡ä»¶å¤¹doc $ mkdir doc $ ls doc $ git status On branch master No commits yet nothing to commit (create/copy files and use &quot;git add&quot; to track) $ git add doc $ git status On branch master No commits yet nothing to commit (create/copy files and use &quot;git add&quot; to track) $ ls -al .git/objects total 0 drwxr-xr-x 4 zhenglongwu staff 128 Sep 18 23:22 . drwxr-xr-x 10 zhenglongwu staff 320 Sep 18 23:22 .. drwxr-xr-x 2 zhenglongwu staff 64 Sep 18 23:22 info drwxr-xr-x 2 zhenglongwu staff 64 Sep 18 23:22 pack ## ==&gt; ç©ºæ–‡ä»¶å¤¹ä¸æ˜¯å¯¹è±¡, addåä¹Ÿæ²¡æœ‰æ•ˆæœ ## åœ¨æ–‡ä»¶å¤¹docå†…åˆ›å»ºæ–‡ä»¶ $ cd doc $ echo 'hello world'&gt;readme.txt $ ls readme.txt $ cat readme.txt hello world $ cd .. $ git status On branch master No commits yet Untracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) doc/ nothing added to commit but untracked files present (use &quot;git add&quot; to track) $ ls -al .git/objects total 0 drwxr-xr-x 4 zhenglongwu staff 128 Sep 18 23:22 . drwxr-xr-x 10 zhenglongwu staff 320 Sep 18 23:37 .. drwxr-xr-x 2 zhenglongwu staff 64 Sep 18 23:22 info drwxr-xr-x 2 zhenglongwu staff 64 Sep 18 23:22 pack ## åœ¨docæ–‡ä»¶å†…åˆ›å»ºäº†æ–‡ä»¶readme.txtï¼Œgit statuså‡ºç°untrackedæ–‡ä»¶ï¼ŒGitç³»ç»Ÿä¾ç„¶æ²¡æœ‰åˆ›å»ºå¯¹è±¡ã€‚ ## pushç»™Gitç³»ç»Ÿ $ git add doc $ git status On branch master No commits yet Changes to be committed: (use &quot;git rm --cached &lt;file&gt;...&quot; to unstage) new file: doc/readme.txt $ ls -al .git/objects total 0 drwxr-xr-x 5 zhenglongwu staff 160 Sep 18 23:44 . drwxr-xr-x 11 zhenglongwu staff 352 Sep 18 23:44 .. drwxr-xr-x 3 zhenglongwu staff 96 Sep 18 23:44 a0 ... $ ls -al .git/objects/a0 total 8 drwxr-xr-x 3 zhenglongwu staff 96 Sep 18 23:44 . drwxr-xr-x 5 zhenglongwu staff 160 Sep 18 23:44 .. -r--r--r-- 1 zhenglongwu staff 29 Sep 18 23:44 423896973644771497bdc03eb99d5281615b51 $ git cat-file -t a0423896973 blob $ git cat-file -p a0423896973 hello world! #### ä¸­é€”å°ç»“ï¼š #### 1.åˆ›å»ºç©ºæ–‡ä»¶å¤¹ï¼ŒGitç³»ç»Ÿä¸ä¼šæœ‰ä»»ä½•å˜åŒ–æˆ–æç¤ºã€‚ #### 2.åœ¨ç©ºæ–‡ä»¶å¤¹å†…éƒ¨åˆ›å»ºæ–‡æœ¬æ–‡ä»¶åï¼ŒåŒ…æ‹¬æ–‡ä»¶å¤¹åœ¨å†…Gitç³»ç»Ÿå‡ºç°untracked fileæç¤º, .git/objectsä¸­æ²¡æœ‰åˆ›å»ºå¯¹è±¡ #### 3.å°†åŒ…å«æ–‡ä»¶çš„æ–‡ä»¶å¤¹ä¸€èµ·git addåï¼Œ.git/objectsä¸­å‡ºç°blobå¯¹è±¡ï¼Œå³åˆ›å»ºçš„æ–‡ä»¶ã€‚ #### 4.é—®ï¼šgit commitä¹‹åå‘¢ï¼Ÿä¼šæœ‰å¤šå°‘åˆ›å»ºå¯¹è±¡ï¼Ÿ ## å®éªŒgit commit $ git commit -m'Add readme' [master (root-commit) 4ce2739] Add readme 1 file changed, 1 insertion(+) create mode 100644 doc/readme.txt $ git status On branch master nothing to commit, working tree clean $ git log commit 4ce2739c6af63445b694ef10323fd9c5ece775c2 (HEAD -&gt; master) Author: zhenglong &lt;wzhenglong@yahoo.com&gt; Date: Wed Sep 18 23:55:02 2019 -0400 Add readme $ git log --oneline 4ce2739 (HEAD -&gt; master) Add readme $ ls -al .git/objects total 0 ... drwxr-xr-x 3 zhenglongwu staff 96 Sep 18 23:55 32 drwxr-xr-x 3 zhenglongwu staff 96 Sep 18 23:55 4c drwxr-xr-x 3 zhenglongwu staff 96 Sep 18 23:55 7e drwxr-xr-x 3 zhenglongwu staff 96 Sep 18 23:44 a0 ... ## æ¯”ä¹‹å‰çš„a0æ–‡ä»¶å¤¹å¤šäº†32ï¼Œ4cå’Œ7eä¸‰ä¸ªæ–‡ä»¶å¤¹ ## 32æ–‡ä»¶å¤¹æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ $ ls -al .git/objects/32 total 8 ... -r--r--r-- 1 zhenglongwu staff 45 Sep 18 23:55 dd8f7c4977eab3ac25d95abefbfa781e58abc7 $ git cat-file -t 32dd8 tree $ git cat-file -p 32dd8 040000 tree 7e007f7273ba9497e7595b1f84875163f9a8903d doc $ git cat-file -p 7e007 100644 blob a0423896973644771497bdc03eb99d5281615b51 readme.txt $ git cat-file -p a0423 hello world! ## 4cæ–‡ä»¶å¤¹æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ $ ls -al .git/objects/4c total 8 ... -r--r--r-- 1 zhenglongwu staff 126 Sep 18 23:55 e2739c6af63445b694ef10323fd9c5ece775c2 $ git cat-file -t 4ce27 commit $ git cat-file -p 4ce27 tree 32dd8f7c4977eab3ac25d95abefbfa781e58abc7 author zhenglong &lt;wzhenglong@yahoo.com&gt; 1568865302 -0400 committer zhenglong &lt;wzhenglong@yahoo.com&gt; 1568865302 -0400 Add readme ## 32dd8..å°±æ˜¯ä¸Šé¢docçš„çˆ¶æ–‡ä»¶å¤¹çš„hashå€¼ ## 7eæ–‡ä»¶å¤¹æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ $ ls -al .git/objects/7e total 8 ... -r--r--r-- 1 zhenglongwu staff 55 Sep 18 23:55 007f7273ba9497e7595b1f84875163f9a8903d $ git cat-file -t 7e007 tree $ git cat-file -p 7e007 100644 blob a0423896973644771497bdc03eb99d5281615b51 readme.txt $ git cat-file -p a0423 hello world! #### å°ç»“4 #### 1.ä»“åº“æ²¡æœ‰ä»»ä½•commitså‰ï¼Œgit statusï¼šNo commits yet. nothing to commit (create/copy files and use &quot;git add&quot; to track) #### 2.ä»“åº“æœ‰commitsåï¼Œgit statusï¼šnothing to commit, working tree clean #### 3.ä»“åº“commitså, gitåˆ›å»ºçš„objectsæœ‰ï¼š ##### a. 32dd8 tree =&gt; docçš„çˆ¶æ–‡ä»¶å¤¹ [count_tree] ï¼ˆå†…å®¹: ä¸€ä¸ª7e007çš„tree --&gt; docï¼‰ ##### b. 7e007 tree =&gt; readme.txtçš„çˆ¶æ–‡ä»¶å¤¹ [doc] (å†…å®¹ï¼šä¸€ä¸ªa0423çš„blob --&gt; readme.txt) ##### c. a0423 blob =&gt; (å†…å®¹ï¼šhello world) ##### d. 4ce27 commit =&gt; (å†…å®¹ï¼štree 32dd8 çš„commitè®°å½•) #### å®Œæ•´æ€»ç»“--Gitå†…éƒ¨è¡Œä¸ºåˆ†æ ç”¨æˆ·è¡Œä¸º Gitè¡Œä¸º 1. git init åˆ›å»ºç©ºä»“åº“ç¯å¢ƒ 2. åˆ›å»ºç©ºæ–‡ä»¶å¤¹doc æ— ååº” 3. å†™å…¥ä¸€ä¸ªæ–‡ä»¶ Gitå‡ºç°untracked fileæç¤º 4. git add æ–‡ä»¶ Gitåˆ›å»ºblobå¯¹è±¡a0423 (readme.txt) 5. git commit Gitåˆ›å»ºcommitå¯¹è±¡4ce27 (add readme) treeå¯¹è±¡32dd8 (count_tree) treeå¯¹è±¡7e007 (doc) åˆ†ç¦»å¤´æŒ‡é’ˆæ³¨æ„äº‹é¡¹ï¼Ÿ git checkout åˆ°ç©ºåˆ†æ”¯åï¼Œå³ä¸æŒ‡å®šä»å“ªä¸€ä¸ªcommitå¼€å§‹åˆ†æ”¯ åœ¨è¿™ä¸ªç©ºåˆ†æ”¯git addç”šè‡³git commitååˆ‡å›åŸmasteråˆ†æ”¯å°†ä¸¢å¤±åœ¨ç©ºåˆ†æ”¯çš„æ‰€æœ‰æ–°æ“ä½œã€‚ æ‰€æœ‰çš„æ–°æ“ä½œå¿…é¡»ç»‘å®šåœ¨ä¸€ä¸ªå½“å‰æŒ‡å®šçš„ä¸€ä¸ªåˆ†æ”¯ä¸Šæ‰è¡Œã€‚å¦åˆ™æ–‡ä»¶ä¸¢å¤±ã€‚ æ‰€æœ‰çš„hashå€¼éƒ½æ˜¯ä¸€ä¸ªæŒ‡é’ˆï¼ŒæŒ‡å‘å®ƒçš„å†…å­˜ç©ºé—´åœ°å€ã€‚é€šè¿‡Gitè§£è¯»hashå€¼å¯ä»¥é˜…è¯»å½“å‰çš„å¯¹è±¡çš„ä»»ä½•ä¿¡æ¯ã€‚ è¿›ä¸€æ­¥ç†è§£headå’Œbranch ","link":"https://zl-wu.github.io/post/git-you-er-yuan-ru-men/"}]}